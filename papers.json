[
  {
    "title": "Efficiently Estimating Data Efficiency for Language Model Fine-tuning",
    "authors": [
      "Gyung Hyun Je",
      "Colin Raffel"
    ],
    "summary": "While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is...",
    "published": "Dec 31",
    "pdf_url": "https://arxiv.org/pdf/2512.24991v1",
    "arxiv_url": "http://arxiv.org/abs/2512.24991v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "End-to-End Test-Time Training for Long Context",
    "authors": [
      "Arnuv Tandon",
      "Karan Dalal",
      "Xinhao Li",
      "Daniel Koceja",
      "Marcel R\u00f8d",
      "Sam Buchanan",
      "Xiaolong Wang",
      "Jure Leskovec",
      "Sanmi Koyejo",
      "Tatsunori Hashimoto",
      "Carlos Guestrin",
      "Jed McCaleb",
      "Yejin Choi",
      "Yu Sun"
    ],
    "summary": "We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on ...",
    "published": "Dec 29",
    "pdf_url": "https://arxiv.org/pdf/2512.23675v2",
    "arxiv_url": "http://arxiv.org/abs/2512.23675v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo",
      "Yejin Choi"
    ]
  },
  {
    "title": "DECEPTICON: How Dark Patterns Manipulate Web Agents",
    "authors": [
      "Phil Cuvin",
      "Hao Zhu",
      "Diyi Yang"
    ],
    "summary": "Deceptive UI designs, widely instantiated across the web and commonly known as dark patterns, manipulate users into performing actions misaligned with their goals. In this paper, we show that dark patterns are highly effective in steering agent trajectories, posing a significant risk to agent robust...",
    "published": "Dec 28",
    "pdf_url": "https://arxiv.org/pdf/2512.22894v1",
    "arxiv_url": "http://arxiv.org/abs/2512.22894v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "An Information Theoretic Perspective on Agentic System Design",
    "authors": [
      "Shizhe He",
      "Avanika Narayan",
      "Ishan S. Khare",
      "Scott W. Linderman",
      "Christopher R\u00e9",
      "Dan Biderman"
    ],
    "summary": "Agentic language model (LM) systems power modern applications like \"Deep Research\" and \"Claude Code,\" and leverage multi-LM architectures to overcome context limitations. Beneath their apparent diversity lies a recurring pattern: smaller \"compressor\" LMs (that can even run locally) distill raw conte...",
    "published": "Dec 25",
    "pdf_url": "https://arxiv.org/pdf/2512.21720v1",
    "arxiv_url": "http://arxiv.org/abs/2512.21720v1",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "NVIDIA Nemotron 3: Efficient and Open Intelligence",
    "authors": [
      "NVIDIA",
      ":",
      "Aaron Blakeman",
      "Aaron Grattafiori",
      "Aarti Basant",
      "Abhibha Gupta",
      "Abhinav Khattar",
      "Adi Renduchintala",
      "Aditya Vavre",
      "Akanksha Shukla",
      "Akhiad Bercovich",
      "Aleksander Ficek",
      "Aleksandr Shaposhnikov",
      "Alex Kondratenko",
      "Alexander Bukharin",
      "Alexandre Milesi",
      "Ali Taghibakhshi",
      "Alisa Liu",
      "Amelia Barton",
      "Ameya Sunil Mahabaleshwarkar",
      "Amir Klein",
      "Amit Zuker",
      "Amnon Geifman",
      "Amy Shen",
      "Anahita Bhiwandiwalla",
      "Andrew Tao",
      "Anjulie Agrusa",
      "Ankur Verma",
      "Ann Guan",
      "Anubhav Mandarwal",
      "Arham Mehta",
      "Ashwath Aithal",
      "Ashwin Poojary",
      "Asif Ahamed",
      "Asit Mishra",
      "Asma Kuriparambil Thekkumpate",
      "Ayush Dattagupta",
      "Banghua Zhu",
      "Bardiya Sadeghi",
      "Barnaby Simkin",
      "Ben Lanir",
      "Benedikt Schifferer",
      "Besmira Nushi",
      "Bilal Kartal",
      "Bita Darvish Rouhani",
      "Boris Ginsburg",
      "Brandon Norick",
      "Brandon Soubasis",
      "Branislav Kisacanin",
      "Brian Yu",
      "Bryan Catanzaro",
      "Carlo del Mundo",
      "Chantal Hwang",
      "Charles Wang",
      "Cheng-Ping Hsieh",
      "Chenghao Zhang",
      "Chenhan Yu",
      "Chetan Mungekar",
      "Chintan Patel",
      "Chris Alexiuk",
      "Christopher Parisien",
      "Collin Neale",
      "Cyril Meurillon",
      "Damon Mosk-Aoyama",
      "Dan Su",
      "Dane Corneil",
      "Daniel Afrimi",
      "Daniel Lo",
      "Daniel Rohrer",
      "Daniel Serebrenik",
      "Daria Gitman",
      "Daria Levy",
      "Darko Stosic",
      "David Mosallanezhad",
      "Deepak Narayanan",
      "Dhruv Nathawani",
      "Dima Rekesh",
      "Dina Yared",
      "Divyanshu Kakwani",
      "Dong Ahn",
      "Duncan Riach",
      "Dusan Stosic",
      "Edgar Minasyan",
      "Edward Lin",
      "Eileen Long",
      "Eileen Peters Long",
      "Elad Segal",
      "Elena Lantz",
      "Ellie Evans",
      "Elliott Ning",
      "Eric Chung",
      "Eric Harper",
      "Eric Tramel",
      "Erick Galinkin",
      "Erik Pounds",
      "Evan Briones",
      "Evelina Bakhturina",
      "Evgeny Tsykunov",
      "Faisal Ladhak",
      "Fay Wang",
      "Fei Jia",
      "Felipe Soares",
      "Feng Chen",
      "Ferenc Galko",
      "Frank Sun",
      "Frankie Siino",
      "Gal Hubara Agam",
      "Ganesh Ajjanagadde",
      "Gantavya Bhatt",
      "Gargi Prasad",
      "George Armstrong",
      "Gerald Shen",
      "Gorkem Batmaz",
      "Grigor Nalbandyan",
      "Haifeng Qian",
      "Harsh Sharma",
      "Hayley Ross",
      "Helen Ngo",
      "Herbert Hum",
      "Herman Sahota",
      "Hexin Wang",
      "Himanshu Soni",
      "Hiren Upadhyay",
      "Huizi Mao",
      "Huy C Nguyen",
      "Huy Q Nguyen",
      "Iain Cunningham",
      "Ido Galil",
      "Ido Shahaf",
      "Igor Gitman",
      "Ilya Loshchilov",
      "Itamar Schen",
      "Itay Levy",
      "Ivan Moshkov",
      "Izik Golan",
      "Izzy Putterman",
      "Jan Kautz",
      "Jane Polak Scowcroft",
      "Jared Casper",
      "Jatin Mitra",
      "Jeffrey Glick",
      "Jenny Chen",
      "Jesse Oliver",
      "Jian Zhang",
      "Jiaqi Zeng",
      "Jie Lou",
      "Jimmy Zhang",
      "Jinhang Choi",
      "Jining Huang",
      "Joey Conway",
      "Joey Guman",
      "John Kamalu",
      "Johnny Greco",
      "Jonathan Cohen",
      "Joseph Jennings",
      "Joyjit Daw",
      "Julien Veron Vialard",
      "Junkeun Yi",
      "Jupinder Parmar",
      "Kai Xu",
      "Kan Zhu",
      "Kari Briski",
      "Katherine Cheung",
      "Katherine Luna",
      "Keith Wyss",
      "Keshav Santhanam",
      "Kevin Shih",
      "Kezhi Kong",
      "Khushi Bhardwaj",
      "Kirthi Shankar",
      "Krishna C. Puvvada",
      "Krzysztof Pawelec",
      "Kumar Anik",
      "Lawrence McAfee",
      "Laya Sleiman",
      "Leon Derczynski",
      "Li Ding",
      "Lizzie Wei",
      "Lucas Liebenwein",
      "Luis Vega",
      "Maanu Grover",
      "Maarten Van Segbroeck",
      "Maer Rodrigues de Melo",
      "Mahdi Nazemi",
      "Makesh Narsimhan Sreedhar",
      "Manoj Kilaru",
      "Maor Ashkenazi",
      "Marc Romeijn",
      "Marcin Chochowski",
      "Mark Cai",
      "Markus Kliegl",
      "Maryam Moosaei",
      "Matt Kulka",
      "Matvei Novikov",
      "Mehrzad Samadi",
      "Melissa Corpuz",
      "Mengru Wang",
      "Meredith Price",
      "Michael Andersch",
      "Michael Boone",
      "Michael Evans",
      "Miguel Martinez",
      "Mikail Khona",
      "Mike Chrzanowski",
      "Minseok Lee",
      "Mohammad Dabbah",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Nabin Mulepati",
      "Najeeb Nabwani",
      "Natalie Hereth",
      "Nave Assaf",
      "Negar Habibi",
      "Neta Zmora",
      "Netanel Haber",
      "Nicola Sessions",
      "Nidhi Bhatia",
      "Nikhil Jukar",
      "Nikki Pope",
      "Nikolai Ludwig",
      "Nima Tajbakhsh",
      "Nir Ailon",
      "Nirmal Juluru",
      "Nishant Sharma",
      "Oleksii Hrinchuk",
      "Oleksii Kuchaiev",
      "Olivier Delalleau",
      "Oluwatobi Olabiyi",
      "Omer Ullman Argov",
      "Omri Puny",
      "Oren Tropp",
      "Ouye Xie",
      "Parth Chadha",
      "Pasha Shamis",
      "Paul Gibbons",
      "Pavlo Molchanov",
      "Pawel Morkisz",
      "Peter Dykas",
      "Peter Jin",
      "Pinky Xu",
      "Piotr Januszewski",
      "Pranav Prashant Thombre",
      "Prasoon Varshney",
      "Pritam Gundecha",
      "Przemek Tredak",
      "Qing Miao",
      "Qiyu Wan",
      "Rabeeh Karimi Mahabadi",
      "Rachit Garg",
      "Ran El-Yaniv",
      "Ran Zilberstein",
      "Rasoul Shafipour",
      "Rich Harang",
      "Rick Izzo",
      "Rima Shahbazyan",
      "Rishabh Garg",
      "Ritika Borkar",
      "Ritu Gala",
      "Riyad Islam",
      "Robert Hesse",
      "Roger Waleffe",
      "Rohit Watve",
      "Roi Koren",
      "Ruoxi Zhang",
      "Russell Hewett",
      "Russell J. Hewett",
      "Ryan Prenger",
      "Ryan Timbrook",
      "Sadegh Mahdavi",
      "Sahil Modi",
      "Samuel Kriman",
      "Sangkug Lim",
      "Sanjay Kariyappa",
      "Sanjeev Satheesh",
      "Saori Kaji",
      "Satish Pasumarthi",
      "Saurav Muralidharan",
      "Sean Narentharen",
      "Sean Narenthiran",
      "Seonmyeong Bak",
      "Sergey Kashirsky",
      "Seth Poulos",
      "Shahar Mor",
      "Shanmugam Ramasamy",
      "Shantanu Acharya",
      "Shaona Ghosh",
      "Sharath Turuvekere Sreenivas",
      "Shelby Thomas",
      "Shiqing Fan",
      "Shreya Gopal",
      "Shrimai Prabhumoye",
      "Shubham Pachori",
      "Shubham Toshniwal",
      "Shuoyang Ding",
      "Siddharth Singh",
      "Simeng Sun",
      "Smita Ithape",
      "Somshubra Majumdar",
      "Soumye Singhal",
      "Stas Sergienko",
      "Stefania Alborghetti",
      "Stephen Ge",
      "Sugam Dipak Devare",
      "Sumeet Kumar Barua",
      "Suseella Panguluri",
      "Suyog Gupta",
      "Sweta Priyadarshi",
      "Syeda Nahida Akter",
      "Tan Bui",
      "Teodor-Dumitru Ene",
      "Terry Kong",
      "Thanh Do",
      "Tijmen Blankevoort",
      "Tim Moon",
      "Tom Balough",
      "Tomer Asida",
      "Tomer Bar Natan",
      "Tomer Ronen",
      "Tugrul Konuk",
      "Twinkle Vashishth",
      "Udi Karpas",
      "Ushnish De",
      "Vahid Noorozi",
      "Vahid Noroozi",
      "Venkat Srinivasan",
      "Venmugil Elango",
      "Victor Cui",
      "Vijay Korthikanti",
      "Vinay Rao",
      "Vitaly Kurin",
      "Vitaly Lavrukhin",
      "Vladimir Anisimov",
      "Wanli Jiang",
      "Wasi Uddin Ahmad",
      "Wei Du",
      "Wei Ping",
      "Wenfei Zhou",
      "Will Jennings",
      "William Zhang",
      "Wojciech Prazuch",
      "Xiaowei Ren",
      "Yashaswi Karnati",
      "Yejin Choi",
      "Yev Meyer",
      "Yi-Fu Wu",
      "Yian Zhang",
      "Yigong Qin",
      "Ying Lin",
      "Yonatan Geifman",
      "Yonggan Fu",
      "Yoshi Subara",
      "Yoshi Suhara",
      "Yubo Gao",
      "Zach Moshe",
      "Zhen Dong",
      "Zhongbo Zhu",
      "Zihan Liu",
      "Zijia Chen",
      "Zijie Yan"
    ],
    "summary": "We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities. The Nemotron 3 family uses a Mixture-of-Experts hybrid Mamba-Transformer architecture to provide best-in-class throughput and context lengths of up ...",
    "published": "Dec 24",
    "pdf_url": "https://arxiv.org/pdf/2512.20856v1",
    "arxiv_url": "http://arxiv.org/abs/2512.20856v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning",
    "authors": [
      "NVIDIA",
      ":",
      "Aaron Blakeman",
      "Aaron Grattafiori",
      "Aarti Basant",
      "Abhibha Gupta",
      "Abhinav Khattar",
      "Adi Renduchintala",
      "Aditya Vavre",
      "Akanksha Shukla",
      "Akhiad Bercovich",
      "Aleksander Ficek",
      "Aleksandr Shaposhnikov",
      "Alex Kondratenko",
      "Alexander Bukharin",
      "Alexandre Milesi",
      "Ali Taghibakhshi",
      "Alisa Liu",
      "Amelia Barton",
      "Ameya Sunil Mahabaleshwarkar",
      "Amir Klein",
      "Amit Zuker",
      "Amnon Geifman",
      "Amy Shen",
      "Anahita Bhiwandiwalla",
      "Andrew Tao",
      "Ann Guan",
      "Anubhav Mandarwal",
      "Arham Mehta",
      "Ashwath Aithal",
      "Ashwin Poojary",
      "Asif Ahamed",
      "Asma Kuriparambil Thekkumpate",
      "Ayush Dattagupta",
      "Banghua Zhu",
      "Bardiya Sadeghi",
      "Barnaby Simkin",
      "Ben Lanir",
      "Benedikt Schifferer",
      "Besmira Nushi",
      "Bilal Kartal",
      "Bita Darvish Rouhani",
      "Boris Ginsburg",
      "Brandon Norick",
      "Brandon Soubasis",
      "Branislav Kisacanin",
      "Brian Yu",
      "Bryan Catanzaro",
      "Carlo del Mundo",
      "Chantal Hwang",
      "Charles Wang",
      "Cheng-Ping Hsieh",
      "Chenghao Zhang",
      "Chenhan Yu",
      "Chetan Mungekar",
      "Chintan Patel",
      "Chris Alexiuk",
      "Christopher Parisien",
      "Collin Neale",
      "Damon Mosk-Aoyama",
      "Dan Su",
      "Dane Corneil",
      "Daniel Afrimi",
      "Daniel Rohrer",
      "Daniel Serebrenik",
      "Daria Gitman",
      "Daria Levy",
      "Darko Stosic",
      "David Mosallanezhad",
      "Deepak Narayanan",
      "Dhruv Nathawani",
      "Dima Rekesh",
      "Dina Yared",
      "Divyanshu Kakwani",
      "Dong Ahn",
      "Duncan Riach",
      "Dusan Stosic",
      "Edgar Minasyan",
      "Edward Lin",
      "Eileen Long",
      "Eileen Peters Long",
      "Elena Lantz",
      "Ellie Evans",
      "Elliott Ning",
      "Eric Chung",
      "Eric Harper",
      "Eric Tramel",
      "Erick Galinkin",
      "Erik Pounds",
      "Evan Briones",
      "Evelina Bakhturina",
      "Faisal Ladhak",
      "Fay Wang",
      "Fei Jia",
      "Felipe Soares",
      "Feng Chen",
      "Ferenc Galko",
      "Frankie Siino",
      "Gal Hubara Agam",
      "Ganesh Ajjanagadde",
      "Gantavya Bhatt",
      "Gargi Prasad",
      "George Armstrong",
      "Gerald Shen",
      "Gorkem Batmaz",
      "Grigor Nalbandyan",
      "Haifeng Qian",
      "Harsh Sharma",
      "Hayley Ross",
      "Helen Ngo",
      "Herman Sahota",
      "Hexin Wang",
      "Himanshu Soni",
      "Hiren Upadhyay",
      "Huizi Mao",
      "Huy C Nguyen",
      "Huy Q Nguyen",
      "Iain Cunningham",
      "Ido Shahaf",
      "Igor Gitman",
      "Ilya Loshchilov",
      "Ivan Moshkov",
      "Izzy Putterman",
      "Jan Kautz",
      "Jane Polak Scowcroft",
      "Jared Casper",
      "Jatin Mitra",
      "Jeffrey Glick",
      "Jenny Chen",
      "Jesse Oliver",
      "Jian Zhang",
      "Jiaqi Zeng",
      "Jie Lou",
      "Jimmy Zhang",
      "Jining Huang",
      "Joey Conway",
      "Joey Guman",
      "John Kamalu",
      "Johnny Greco",
      "Jonathan Cohen",
      "Joseph Jennings",
      "Joyjit Daw",
      "Julien Veron Vialard",
      "Junkeun Yi",
      "Jupinder Parmar",
      "Kai Xu",
      "Kan Zhu",
      "Kari Briski",
      "Katherine Cheung",
      "Katherine Luna",
      "Keshav Santhanam",
      "Kevin Shih",
      "Kezhi Kong",
      "Khushi Bhardwaj",
      "Krishna C. Puvvada",
      "Krzysztof Pawelec",
      "Kumar Anik",
      "Lawrence McAfee",
      "Laya Sleiman",
      "Leon Derczynski",
      "Li Ding",
      "Lucas Liebenwein",
      "Luis Vega",
      "Maanu Grover",
      "Maarten Van Segbroeck",
      "Maer Rodrigues de Melo",
      "Makesh Narsimhan Sreedhar",
      "Manoj Kilaru",
      "Maor Ashkenazi",
      "Marc Romeijn",
      "Mark Cai",
      "Markus Kliegl",
      "Maryam Moosaei",
      "Matvei Novikov",
      "Mehrzad Samadi",
      "Melissa Corpuz",
      "Mengru Wang",
      "Meredith Price",
      "Michael Boone",
      "Michael Evans",
      "Miguel Martinez",
      "Mike Chrzanowski",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Nabin Mulepati",
      "Natalie Hereth",
      "Nave Assaf",
      "Negar Habibi",
      "Neta Zmora",
      "Netanel Haber",
      "Nicola Sessions",
      "Nidhi Bhatia",
      "Nikhil Jukar",
      "Nikki Pope",
      "Nikolai Ludwig",
      "Nima Tajbakhsh",
      "Nirmal Juluru",
      "Oleksii Hrinchuk",
      "Oleksii Kuchaiev",
      "Olivier Delalleau",
      "Oluwatobi Olabiyi",
      "Omer Ullman Argov",
      "Ouye Xie",
      "Parth Chadha",
      "Pasha Shamis",
      "Pavlo Molchanov",
      "Pawel Morkisz",
      "Peter Dykas",
      "Peter Jin",
      "Pinky Xu",
      "Piotr Januszewski",
      "Pranav Prashant Thombre",
      "Prasoon Varshney",
      "Pritam Gundecha",
      "Qing Miao",
      "Rabeeh Karimi Mahabadi",
      "Ran El-Yaniv",
      "Ran Zilberstein",
      "Rasoul Shafipour",
      "Rich Harang",
      "Rick Izzo",
      "Rima Shahbazyan",
      "Rishabh Garg",
      "Ritika Borkar",
      "Ritu Gala",
      "Riyad Islam",
      "Roger Waleffe",
      "Rohit Watve",
      "Roi Koren",
      "Ruoxi Zhang",
      "Russell J. Hewett",
      "Ryan Prenger",
      "Ryan Timbrook",
      "Sadegh Mahdavi",
      "Sahil Modi",
      "Samuel Kriman",
      "Sanjay Kariyappa",
      "Sanjeev Satheesh",
      "Saori Kaji",
      "Satish Pasumarthi",
      "Sean Narentharen",
      "Sean Narenthiran",
      "Seonmyeong Bak",
      "Sergey Kashirsky",
      "Seth Poulos",
      "Shahar Mor",
      "Shanmugam Ramasamy",
      "Shantanu Acharya",
      "Shaona Ghosh",
      "Sharath Turuvekere Sreenivas",
      "Shelby Thomas",
      "Shiqing Fan",
      "Shreya Gopal",
      "Shrimai Prabhumoye",
      "Shubham Pachori",
      "Shubham Toshniwal",
      "Shuoyang Ding",
      "Siddharth Singh",
      "Simeng Sun",
      "Smita Ithape",
      "Somshubra Majumdar",
      "Soumye Singhal",
      "Stefania Alborghetti",
      "Stephen Ge",
      "Sugam Dipak Devare",
      "Sumeet Kumar Barua",
      "Suseella Panguluri",
      "Suyog Gupta",
      "Sweta Priyadarshi",
      "Syeda Nahida Akter",
      "Tan Bui",
      "Teodor-Dumitru Ene",
      "Terry Kong",
      "Thanh Do",
      "Tijmen Blankevoort",
      "Tom Balough",
      "Tomer Asida",
      "Tomer Bar Natan",
      "Tugrul Konuk",
      "Twinkle Vashishth",
      "Udi Karpas",
      "Ushnish De",
      "Vahid Noorozi",
      "Vahid Noroozi",
      "Venkat Srinivasan",
      "Venmugil Elango",
      "Vijay Korthikanti",
      "Vitaly Kurin",
      "Vitaly Lavrukhin",
      "Wanli Jiang",
      "Wasi Uddin Ahmad",
      "Wei Du",
      "Wei Ping",
      "Wenfei Zhou",
      "Will Jennings",
      "William Zhang",
      "Wojciech Prazuch",
      "Xiaowei Ren",
      "Yashaswi Karnati",
      "Yejin Choi",
      "Yev Meyer",
      "Yi-Fu Wu",
      "Yian Zhang",
      "Ying Lin",
      "Yonatan Geifman",
      "Yonggan Fu",
      "Yoshi Subara",
      "Yoshi Suhara",
      "Yubo Gao",
      "Zach Moshe",
      "Zhen Dong",
      "Zihan Liu",
      "Zijia Chen",
      "Zijie Yan"
    ],
    "summary": "We present Nemotron 3 Nano 30B-A3B, a Mixture-of-Experts hybrid Mamba-Transformer language model. Nemotron 3 Nano was pretrained on 25 trillion text tokens, including more than 3 trillion new unique tokens over Nemotron 2, followed by supervised fine tuning and large-scale RL on diverse environments...",
    "published": "Dec 23",
    "pdf_url": "https://arxiv.org/pdf/2512.20848v1",
    "arxiv_url": "http://arxiv.org/abs/2512.20848v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior",
    "authors": [
      "G\u00fcl Sena Alt\u0131nta\u015f",
      "Malikeh Ehghaghi",
      "Brian Lester",
      "Fengyuan Liu",
      "Wanru Zhao",
      "Marco Ciccone",
      "Colin Raffel"
    ],
    "summary": "Tokenizers provide the fundamental basis through which text is represented and processed by language models (LMs). Despite the importance of tokenization, its role in LM performance and behavior is poorly understood due to the challenge of measuring the impact of tokenization in isolation. To addres...",
    "published": "Dec 23",
    "pdf_url": "https://arxiv.org/pdf/2512.20757v1",
    "arxiv_url": "http://arxiv.org/abs/2512.20757v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "Propose, Solve, Verify: Self-Play Through Formal Verification",
    "authors": [
      "Alex Wilf",
      "Pranjal Aggarwal",
      "Bryan Parno",
      "Daniel Fried",
      "Louis-Philippe Morency",
      "Paul Pu Liang",
      "Sean Welleck"
    ],
    "summary": "Training models through self-play alone (without any human data) has been a longstanding goal in AI, but its effectiveness for training large language models remains unclear, particularly in code generation where rewards based on unit tests are brittle and prone to error propagation. We study self-p...",
    "published": "Dec 20",
    "pdf_url": "https://arxiv.org/pdf/2512.18160v1",
    "arxiv_url": "http://arxiv.org/abs/2512.18160v1",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators",
    "authors": [
      "Michael J. Ryan",
      "Yanzhe Zhang",
      "Amol Salunkhe",
      "Yi Chu",
      "Di Xu",
      "Diyi Yang"
    ],
    "summary": "Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in protot...",
    "published": "Dec 19",
    "pdf_url": "https://arxiv.org/pdf/2512.17267v1",
    "arxiv_url": "http://arxiv.org/abs/2512.17267v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image",
    "authors": [
      "Yushi Hu",
      "Reyhane Askari-Hemmat",
      "Melissa Hall",
      "Emily Dinan",
      "Luke Zettlemoyer",
      "Marjan Ghazvininejad"
    ],
    "summary": "Reward models (RMs) are essential for training large language models (LLMs), but remain underexplored for omni models that handle interleaved image and text sequences. We introduce Multimodal RewardBench 2 (MMRB2), the first comprehensive benchmark for reward models on multimodal understanding and (...",
    "published": "Dec 18",
    "pdf_url": "https://arxiv.org/pdf/2512.16899v1",
    "arxiv_url": "http://arxiv.org/abs/2512.16899v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "GenEval 2: Addressing Benchmark Drift in Text-to-Image Evaluation",
    "authors": [
      "Amita Kamath",
      "Kai-Wei Chang",
      "Ranjay Krishna",
      "Luke Zettlemoyer",
      "Yushi Hu",
      "Marjan Ghazvininejad"
    ],
    "summary": "Automating Text-to-Image (T2I) model evaluation is challenging; a judge model must be used to score correctness, and test prompts must be selected to be challenging for current T2I models but not the judge. We argue that satisfying these constraints can lead to benchmark drift over time, where the s...",
    "published": "Dec 18",
    "pdf_url": "https://arxiv.org/pdf/2512.16853v1",
    "arxiv_url": "http://arxiv.org/abs/2512.16853v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Adaptation of Agentic AI",
    "authors": [
      "Pengcheng Jiang",
      "Jiacheng Lin",
      "Zhiyi Shi",
      "Zifeng Wang",
      "Luxi He",
      "Yichen Wu",
      "Ming Zhong",
      "Peiyang Song",
      "Qizheng Zhang",
      "Heng Wang",
      "Xueqiang Xu",
      "Hanwen Xu",
      "Pengrui Han",
      "Dylan Zhang",
      "Jiashuo Sun",
      "Chaoqi Yang",
      "Kun Qian",
      "Tian Wang",
      "Changran Hu",
      "Manling Li",
      "Quanzheng Li",
      "Hao Peng",
      "Sheng Wang",
      "Jingbo Shang",
      "Chao Zhang",
      "Jiaxuan You",
      "Liyuan Liu",
      "Pan Lu",
      "Yu Zhang",
      "Heng Ji",
      "Yejin Choi",
      "Dawn Song",
      "Jimeng Sun",
      "Jiawei Han"
    ],
    "summary": "Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance,...",
    "published": "Dec 18",
    "pdf_url": "https://arxiv.org/pdf/2512.16301v2",
    "arxiv_url": "http://arxiv.org/abs/2512.16301v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception",
    "authors": [
      "Joel Mire",
      "Maria Antoniak",
      "Steven R. Wilson",
      "Zexin Ma",
      "Achyutarama R. Ganti",
      "Andrew Piper",
      "Maarten Sap"
    ],
    "summary": "Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formal...",
    "published": "Dec 17",
    "pdf_url": "https://arxiv.org/pdf/2512.15925v1",
    "arxiv_url": "http://arxiv.org/abs/2512.15925v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Bolmo: Byteifying the Next Generation of Language Models",
    "authors": [
      "Benjamin Minixhofer",
      "Tyler Murray",
      "Tomasz Limisiewicz",
      "Anna Korhonen",
      "Luke Zettlemoyer",
      "Noah A. Smith",
      "Edoardo M. Ponti",
      "Luca Soldaini",
      "Valentin Hofmann"
    ],
    "summary": "We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteifica...",
    "published": "Dec 17",
    "pdf_url": "https://arxiv.org/pdf/2512.15586v1",
    "arxiv_url": "http://arxiv.org/abs/2512.15586v1",
    "queried_author": "Luca Soldaini",
    "matching_authors": [
      "Luca Soldaini",
      "Luke Zettlemoyer",
      "Noah A. Smith"
    ]
  },
  {
    "title": "SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations",
    "authors": [
      "Wentao Guo",
      "Mayank Mishra",
      "Xinle Cheng",
      "Ion Stoica",
      "Tri Dao"
    ],
    "summary": "Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity (smaller expert intermediate dimension) and higher sparsity (c...",
    "published": "Dec 16",
    "pdf_url": "https://arxiv.org/pdf/2512.14080v1",
    "arxiv_url": "http://arxiv.org/abs/2512.14080v1",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "Olmo 3",
    "authors": [
      "Team Olmo",
      ":",
      "Allyson Ettinger",
      "Amanda Bertsch",
      "Bailey Kuehl",
      "David Graham",
      "David Heineman",
      "Dirk Groeneveld",
      "Faeze Brahman",
      "Finbarr Timbers",
      "Hamish Ivison",
      "Jacob Morrison",
      "Jake Poznanski",
      "Kyle Lo",
      "Luca Soldaini",
      "Matt Jordan",
      "Mayee Chen",
      "Michael Noukhovitch",
      "Nathan Lambert",
      "Pete Walsh",
      "Pradeep Dasigi",
      "Robert Berry",
      "Saumya Malik",
      "Saurabh Shah",
      "Scott Geng",
      "Shane Arora",
      "Shashank Gupta",
      "Taira Anderson",
      "Teng Xiao",
      "Tyler Murray",
      "Tyler Romero",
      "Victoria Graf",
      "Akari Asai",
      "Akshita Bhagia",
      "Alexander Wettig",
      "Alisa Liu",
      "Aman Rangapur",
      "Chloe Anastasiades",
      "Costa Huang",
      "Dustin Schwenk",
      "Harsh Trivedi",
      "Ian Magnusson",
      "Jaron Lochner",
      "Jiacheng Liu",
      "Lester James V. Miranda",
      "Maarten Sap",
      "Malia Morgan",
      "Michael Schmitz",
      "Michal Guerquin",
      "Michael Wilson",
      "Regan Huff",
      "Ronan Le Bras",
      "Rui Xin",
      "Rulin Shao",
      "Sam Skjonsberg",
      "Shannon Zejiang Shen",
      "Shuyue Stella Li",
      "Tucker Wilde",
      "Valentina Pyatkin",
      "Will Merrill",
      "Yapei Chang",
      "Yuling Gu",
      "Zhiyuan Zeng",
      "Ashish Sabharwal",
      "Luke Zettlemoyer",
      "Pang Wei Koh",
      "Ali Farhadi",
      "Noah A. Smith",
      "Hannaneh Hajishirzi"
    ],
    "summary": "We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow...",
    "published": "Dec 15",
    "pdf_url": "https://arxiv.org/pdf/2512.13961v1",
    "arxiv_url": "http://arxiv.org/abs/2512.13961v1",
    "queried_author": "Alexander Wettig",
    "matching_authors": [
      "Alexander Wettig",
      "Hamish Ivison",
      "Hannaneh Hajishirzi",
      "Ian Magnusson",
      "Kyle Lo",
      "Luca Soldaini",
      "Luke Zettlemoyer",
      "Maarten Sap",
      "Noah A. Smith",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Training Versatile Coding Agents in Synthetic Environments",
    "authors": [
      "Yiqi Zhu",
      "Apurva Gandhi",
      "Graham Neubig"
    ],
    "summary": "Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositorie...",
    "published": "Dec 13",
    "pdf_url": "https://arxiv.org/pdf/2512.12216v1",
    "arxiv_url": "http://arxiv.org/abs/2512.12216v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "The 2025 Foundation Model Transparency Index",
    "authors": [
      "Alexander Wan",
      "Kevin Klyman",
      "Sayash Kapoor",
      "Nestor Maslej",
      "Shayne Longpre",
      "Betty Xiong",
      "Percy Liang",
      "Rishi Bommasani"
    ],
    "summary": "Foundation model developers are among the world's most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transpa...",
    "published": "Dec 11",
    "pdf_url": "https://arxiv.org/pdf/2512.10169v1",
    "arxiv_url": "http://arxiv.org/abs/2512.10169v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit",
    "authors": [
      "Nick Jiang",
      "Xiaoqing Sun",
      "Lisa Dunlap",
      "Lewis Smith",
      "Neel Nanda"
    ],
    "summary": "Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for c...",
    "published": "Dec 10",
    "pdf_url": "https://arxiv.org/pdf/2512.10092v1",
    "arxiv_url": "http://arxiv.org/abs/2512.10092v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing",
    "authors": [
      "Justin W. Lin",
      "Eliot Krzysztof Jones",
      "Donovan Julian Jasper",
      "Ethan Jun-shen Ho",
      "Anna Wu",
      "Arnold Tianyi Yang",
      "Neil Perry",
      "Andy Zou",
      "Matt Fredrikson",
      "J. Zico Kolter",
      "Percy Liang",
      "Dan Boneh",
      "Daniel E. Ho"
    ],
    "summary": "We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 ...",
    "published": "Dec 10",
    "pdf_url": "https://arxiv.org/pdf/2512.09882v1",
    "arxiv_url": "http://arxiv.org/abs/2512.09882v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter",
      "Percy Liang"
    ]
  },
  {
    "title": "Language models as tools for investigating the distinction between possible and impossible natural languages",
    "authors": [
      "Julie Kallini",
      "Christopher Potts"
    ],
    "summary": "We argue that language models (LMs) have strong potential as investigative tools for probing the distinction between possible and impossible natural languages and thus uncovering the inductive biases that support human language learning. We outline a phased research program in which LM architectures...",
    "published": "Dec 10",
    "pdf_url": "https://arxiv.org/pdf/2512.09394v1",
    "arxiv_url": "http://arxiv.org/abs/2512.09394v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "CONCUR: A Framework for Continual Constrained and Unconstrained Routing",
    "authors": [
      "Peter Baile Chen",
      "Weiyue Li",
      "Dan Roth",
      "Michael Cafarella",
      "Samuel Madden",
      "Jacob Andreas"
    ],
    "summary": "AI tasks differ in complexity and are best addressed with different computation strategies (e.g., combinations of models and decoding methods). Hence, an effective routing system that maps tasks to the appropriate strategies is crucial. Most prior methods build the routing framework by training a si...",
    "published": "Dec 10",
    "pdf_url": "https://arxiv.org/pdf/2512.09386v1",
    "arxiv_url": "http://arxiv.org/abs/2512.09386v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models",
    "authors": [
      "Charlie Zhang",
      "Graham Neubig",
      "Xiang Yue"
    ],
    "summary": "Recent reinforcement learning (RL) techniques have yielded impressive reasoning improvements in language models, yet it remains unclear whether post-training truly extends a model's reasoning ability beyond what it acquires during pre-training. A central challenge is the lack of control in modern tr...",
    "published": "Dec 08",
    "pdf_url": "https://arxiv.org/pdf/2512.07783v1",
    "arxiv_url": "http://arxiv.org/abs/2512.07783v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "ARC-AGI Without Pretraining",
    "authors": [
      "Isaac Liao",
      "Albert Gu"
    ],
    "summary": "Conventional wisdom in the age of LLMs dictates that solving IQ-test-like visual puzzles from the ARC-AGI-1 benchmark requires capabilities derived from massive pretraining. To counter this, we introduce CompressARC, a 76K parameter model without any pretraining that solves 20% of evaluation puzzles...",
    "published": "Dec 05",
    "pdf_url": "https://arxiv.org/pdf/2512.06104v1",
    "arxiv_url": "http://arxiv.org/abs/2512.06104v1",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu"
    ]
  },
  {
    "title": "TV2TV: A Unified Framework for Interleaved Language and Video Generation",
    "authors": [
      "Xiaochuang Han",
      "Youssef Emad",
      "Melissa Hall",
      "John Nguyen",
      "Karthik Padthe",
      "Liam Robbins",
      "Amir Bar",
      "Delong Chen",
      "Michal Drozdzal",
      "Maha Elbayad",
      "Yushi Hu",
      "Shang-Wen Li",
      "Sreya Dutta Roy",
      "Jakob Verbeek",
      "XuDong Wang",
      "Marjan Ghazvininejad",
      "Luke Zettlemoyer",
      "Emily Dinan"
    ],
    "summary": "Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from rec...",
    "published": "Dec 04",
    "pdf_url": "https://arxiv.org/pdf/2512.05103v2",
    "arxiv_url": "http://arxiv.org/abs/2512.05103v2",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "LeMat-GenBench: A Unified Evaluation Framework for Crystal Generative Models",
    "authors": [
      "Siddharth Betala",
      "Samuel P. Gleason",
      "Ali Ramlaoui",
      "Andy Xu",
      "Georgia Channing",
      "Daniel Levy",
      "Cl\u00e9mentine Fourrier",
      "Nikita Kazeev",
      "Chaitanya K. Joshi",
      "S\u00e9kou-Oumar Kaba",
      "F\u00e9lix Therrien",
      "Alex Hernandez-Garcia",
      "Roc\u00edo Mercado",
      "N. M. Anoop Krishnan",
      "Alexandre Duval"
    ],
    "summary": "Generative machine learning (ML) models hold great promise for accelerating materials discovery through the inverse design of inorganic crystals, enabling an unprecedented exploration of chemical space. Yet, the lack of standardized evaluation frameworks makes it challenging to evaluate, compare, an...",
    "published": "Dec 04",
    "pdf_url": "https://arxiv.org/pdf/2512.04562v1",
    "arxiv_url": "http://arxiv.org/abs/2512.04562v1",
    "queried_author": "Cl\u00e9mentine Fourrier",
    "matching_authors": [
      "Cl\u00e9mentine Fourrier"
    ]
  },
  {
    "title": "ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation",
    "authors": [
      "Yiming Xu",
      "Yuan Yuan",
      "Vijay Viswanathan",
      "Graham Neubig"
    ],
    "summary": "Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong contextual reasoning, yet prior work mainly uses ...",
    "published": "Dec 04",
    "pdf_url": "https://arxiv.org/pdf/2512.04350v1",
    "arxiv_url": "http://arxiv.org/abs/2512.04350v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
    "authors": [
      "Zayne Sprague",
      "Jack Lu",
      "Manya Wadhwa",
      "Sedrick Keh",
      "Mengye Ren",
      "Greg Durrett"
    ],
    "summary": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforc...",
    "published": "Dec 03",
    "pdf_url": "https://arxiv.org/pdf/2512.04072v1",
    "arxiv_url": "http://arxiv.org/abs/2512.04072v1",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Learning Steerable Clarification Policies with Collaborative Self-play",
    "authors": [
      "Jonathan Berant",
      "Maximillian Chen",
      "Adam Fisch",
      "Reza Aghajani",
      "Fantine Huot",
      "Mirella Lapata",
      "Jacob Eisenstein"
    ],
    "summary": "To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies ...",
    "published": "Dec 03",
    "pdf_url": "https://arxiv.org/pdf/2512.04068v1",
    "arxiv_url": "http://arxiv.org/abs/2512.04068v1",
    "queried_author": "Jacob Eisenstein",
    "matching_authors": [
      "Jacob Eisenstein"
    ]
  },
  {
    "title": "Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs",
    "authors": [
      "Isha Chaturvedi",
      "Anjana Nair",
      "Yushen Li",
      "Adhitya Rajendra Kumar",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma"
    ],
    "summary": "We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides cau...",
    "published": "Dec 03",
    "pdf_url": "https://arxiv.org/pdf/2512.08976v1",
    "arxiv_url": "http://arxiv.org/abs/2512.08976v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval",
    "authors": [
      "Constantin Venhoff",
      "Ashkan Khakzar",
      "Sonia Joseph",
      "Philip Torr",
      "Neel Nanda"
    ],
    "summary": "Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how ef...",
    "published": "Dec 02",
    "pdf_url": "https://arxiv.org/pdf/2512.03276v1",
    "arxiv_url": "http://arxiv.org/abs/2512.03276v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Plantain: Plan-Answer Interleaved Reasoning",
    "authors": [
      "Anthony Liang",
      "Jonathan Berant",
      "Adam Fisch",
      "Abhimanyu Goyal",
      "Kalpesh Krishna",
      "Jacob Eisenstein"
    ],
    "summary": "Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is f...",
    "published": "Dec 02",
    "pdf_url": "https://arxiv.org/pdf/2512.03176v1",
    "arxiv_url": "http://arxiv.org/abs/2512.03176v1",
    "queried_author": "Jacob Eisenstein",
    "matching_authors": [
      "Jacob Eisenstein"
    ]
  },
  {
    "title": "Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning",
    "authors": [
      "Zhonghao He",
      "Tianyi Qiu",
      "Hirokazu Shirado",
      "Maarten Sap"
    ],
    "summary": "Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrench...",
    "published": "Dec 02",
    "pdf_url": "https://arxiv.org/pdf/2512.02914v1",
    "arxiv_url": "http://arxiv.org/abs/2512.02914v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models",
    "authors": [
      "Xinyue Ai",
      "Yutong He",
      "Albert Gu",
      "Ruslan Salakhutdinov",
      "J Zico Kolter",
      "Nicholas Matthew Boffi",
      "Max Simchowitz"
    ],
    "summary": "Log-likelihood evaluation enables important capabilities in generative models, including model comparison, certain fine-tuning objectives, and many downstream applications. Yet paradoxically, some of today's best generative models -- diffusion and flow-based models -- still require hundreds to thous...",
    "published": "Dec 02",
    "pdf_url": "https://arxiv.org/pdf/2512.02636v1",
    "arxiv_url": "http://arxiv.org/abs/2512.02636v1",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu",
      "J Zico Kolter"
    ]
  },
  {
    "title": "Improved Mean Flows: On the Challenges of Fastforward Generative Models",
    "authors": [
      "Zhengyang Geng",
      "Yiyang Lu",
      "Zongze Wu",
      "Eli Shechtman",
      "J. Zico Kolter",
      "Kaiming He"
    ],
    "summary": "MeanFlow (MF) has recently been established as a framework for one-step generative modeling. However, its ``fastforward'' nature introduces key challenges in both the training objective and the guidance mechanism. First, the original MF's training target depends not only on the underlying ground-tru...",
    "published": "Dec 01",
    "pdf_url": "https://arxiv.org/pdf/2512.02012v1",
    "arxiv_url": "http://arxiv.org/abs/2512.02012v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Difficulties with Evaluating a Deception Detector for AIs",
    "authors": [
      "Lewis Smith",
      "Bilal Chughtai",
      "Neel Nanda"
    ],
    "summary": "Building reliable deception detectors for AI systems -- methods that could predict when an AI system is being strategically deceptive without necessarily requiring behavioural evidence -- would be valuable in mitigating risks from advanced AI systems. But evaluating the reliability and efficacy of a...",
    "published": "Nov 27",
    "pdf_url": "https://arxiv.org/pdf/2511.22662v2",
    "arxiv_url": "http://arxiv.org/abs/2511.22662v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "RefineBench: Evaluating Refinement Capability of Language Models via Checklists",
    "authors": [
      "Young-Jun Lee",
      "Seungone Kim",
      "Byung-Kwan Lee",
      "Minkyeong Moon",
      "Yechan Hwang",
      "Jong Myoung Kim",
      "Graham Neubig",
      "Sean Welleck",
      "Ho-Jin Choi"
    ],
    "summary": "Can language models (LMs) self-refine their own responses? This question is increasingly relevant as a wide range of real-world user interactions involve refinement requests. However, prior studies have largely tested LMs' refinement abilities on verifiable tasks such as competition math or symbolic...",
    "published": "Nov 27",
    "pdf_url": "https://arxiv.org/pdf/2511.22173v1",
    "arxiv_url": "http://arxiv.org/abs/2511.22173v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Sean Welleck",
      "Seungone Kim"
    ]
  },
  {
    "title": "ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration",
    "authors": [
      "Hongjin Su",
      "Shizhe Diao",
      "Ximing Lu",
      "Mingjie Liu",
      "Jiacheng Xu",
      "Xin Dong",
      "Yonggan Fu",
      "Peter Belcak",
      "Hanrong Ye",
      "Hongxu Yin",
      "Yi Dong",
      "Evelina Bakhturina",
      "Tao Yu",
      "Yejin Choi",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "summary": "Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the u...",
    "published": "Nov 26",
    "pdf_url": "https://arxiv.org/pdf/2511.21689v1",
    "arxiv_url": "http://arxiv.org/abs/2511.21689v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Structured Prompting Enables More Robust Evaluation of Language Models",
    "authors": [
      "Asad Aali",
      "Muhammad Ahmed Mohsin",
      "Vasiliki Bikia",
      "Arnav Singhvi",
      "Richard Gaus",
      "Suhana Bedi",
      "Hejie Cui",
      "Miguel Fuentes",
      "Alyssa Unell",
      "Yifan Mai",
      "Jordan Cahoon",
      "Michael Pfeffer",
      "Roxana Daneshjou",
      "Sanmi Koyejo",
      "Emily Alsentzer",
      "Christopher Potts",
      "Nigam H. Shah",
      "Akshay S. Chaudhari"
    ],
    "summary": "As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of Language Models (HELM) enable broad evaluation across tasks, the...",
    "published": "Nov 25",
    "pdf_url": "https://arxiv.org/pdf/2511.20836v2",
    "arxiv_url": "http://arxiv.org/abs/2511.20836v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts",
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Concept-Aware Batch Sampling Improves Language-Image Pretraining",
    "authors": [
      "Adhiraj Ghosh",
      "Vishaal Udandarao",
      "Thao Nguyen",
      "Matteo Farina",
      "Mehdi Cherti",
      "Jenia Jitsev",
      "Sewoong Oh",
      "Elisa Ricci",
      "Ludwig Schmidt",
      "Matthias Bethge"
    ],
    "summary": "What data should a vision-language model be trained on? To answer this question, many data curation efforts center on the quality of a dataset. However, most of these existing methods are (i) offline, i.e. they produce a static dataset from a set of predetermined filtering criteria, and (ii) concept...",
    "published": "Nov 25",
    "pdf_url": "https://arxiv.org/pdf/2511.20643v1",
    "arxiv_url": "http://arxiv.org/abs/2511.20643v1",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Latent Collaboration in Multi-Agent Systems",
    "authors": [
      "Jiaru Zou",
      "Xiyuan Yang",
      "Ruizhong Qiu",
      "Gaotang Li",
      "Katherine Tieu",
      "Pan Lu",
      "Ke Shen",
      "Hanghang Tong",
      "Yejin Choi",
      "Jingrui He",
      "James Zou",
      "Mengdi Wang",
      "Ling Yang"
    ],
    "summary": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly...",
    "published": "Nov 25",
    "pdf_url": "https://arxiv.org/pdf/2511.20639v2",
    "arxiv_url": "http://arxiv.org/abs/2511.20639v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research",
    "authors": [
      "Rulin Shao",
      "Akari Asai",
      "Shannon Zejiang Shen",
      "Hamish Ivison",
      "Varsha Kishore",
      "Jingming Zhuo",
      "Xinran Zhao",
      "Molly Park",
      "Samuel G. Finlayson",
      "David Sontag",
      "Tyler Murray",
      "Sewon Min",
      "Pradeep Dasigi",
      "Luca Soldaini",
      "Faeze Brahman",
      "Wen-tau Yih",
      "Tongshuang Wu",
      "Luke Zettlemoyer",
      "Yoon Kim",
      "Hannaneh Hajishirzi",
      "Pang Wei Koh"
    ],
    "summary": "Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. ...",
    "published": "Nov 24",
    "pdf_url": "https://arxiv.org/pdf/2511.19399v2",
    "arxiv_url": "http://arxiv.org/abs/2511.19399v2",
    "queried_author": "Hamish Ivison",
    "matching_authors": [
      "Hamish Ivison",
      "Hannaneh Hajishirzi",
      "Luca Soldaini",
      "Luke Zettlemoyer",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Natural Emergent Misalignment from Reward Hacking in Production RL",
    "authors": [
      "Monte MacDiarmid",
      "Benjamin Wright",
      "Jonathan Uesato",
      "Joe Benton",
      "Jon Kutasov",
      "Sara Price",
      "Naia Bouscal",
      "Sam Bowman",
      "Trenton Bricken",
      "Alex Cloud",
      "Carson Denison",
      "Johannes Gasteiger",
      "Ryan Greenblatt",
      "Jan Leike",
      "Jack Lindsey",
      "Vlad Mikulik",
      "Ethan Perez",
      "Alex Rodrigues",
      "Drake Thomas",
      "Albert Webson",
      "Daniel Ziegler",
      "Evan Hubinger"
    ],
    "summary": "We show that when large language models learn to reward hack on production RL environments, this can result in egregious emergent misalignment. We start with a pretrained model, impart knowledge of reward hacking strategies via synthetic document finetuning or prompting, and train on a selection of ...",
    "published": "Nov 23",
    "pdf_url": "https://arxiv.org/pdf/2511.18397v1",
    "arxiv_url": "http://arxiv.org/abs/2511.18397v1",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez"
    ]
  },
  {
    "title": "Fantastic Bugs and Where to Find Them in AI Benchmarks",
    "authors": [
      "Sang Truong",
      "Yuheng Tu",
      "Michael Hardy",
      "Anka Reuel",
      "Zeyu Tang",
      "Jirayu Burapacheep",
      "Jonathan Perera",
      "Chibuike Uwakwe",
      "Ben Domingue",
      "Nick Haber",
      "Sanmi Koyejo"
    ],
    "summary": "Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we int...",
    "published": "Nov 20",
    "pdf_url": "https://arxiv.org/pdf/2511.16842v1",
    "arxiv_url": "http://arxiv.org/abs/2511.16842v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "ARC Is a Vision Problem!",
    "authors": [
      "Keya Hu",
      "Ali Cy",
      "Linlu Qiu",
      "Xiaoman Delores Ding",
      "Runqian Wang",
      "Yeyin Eva Zhu",
      "Jacob Andreas",
      "Kaiming He"
    ],
    "summary": "The Abstraction and Reasoning Corpus (ARC) is designed to promote research on abstract reasoning, a fundamental aspect of human intelligence. Common approaches to ARC treat it as a language-oriented problem, addressed by large language models (LLMs) or recurrent reasoning models. However, although t...",
    "published": "Nov 18",
    "pdf_url": "https://arxiv.org/pdf/2511.14761v1",
    "arxiv_url": "http://arxiv.org/abs/2511.14761v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "ParallelKittens: Systematic and Practical Simplification of Multi-GPU AI Kernels",
    "authors": [
      "Stuart H. Sul",
      "Simran Arora",
      "Benjamin F. Spector",
      "Christopher R\u00e9"
    ],
    "summary": "Inter-GPU communication has become a major bottleneck for modern AI workloads as models scale and improvements in hardware compute throughput outpace improvements in interconnect bandwidth. Existing systems mitigate this through compute-communication overlap but often fail to meet theoretical peak p...",
    "published": "Nov 17",
    "pdf_url": "https://arxiv.org/pdf/2511.13940v1",
    "arxiv_url": "http://arxiv.org/abs/2511.13940v1",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "Beat the long tail: Distribution-Aware Speculative Decoding for RL Training",
    "authors": [
      "Zelei Shao",
      "Vikranth Srivatsa",
      "Sanjana Srivastava",
      "Qingyang Wu",
      "Alpay Ariyak",
      "Xiaoxia Wu",
      "Ameen Patel",
      "Jue Wang",
      "Percy Liang",
      "Tri Dao",
      "Ce Zhang",
      "Yiying Zhang",
      "Ben Athiwaratkun",
      "Chenfeng Xu",
      "Junxiong Wang"
    ],
    "summary": "Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout len...",
    "published": "Nov 17",
    "pdf_url": "https://arxiv.org/pdf/2511.13841v1",
    "arxiv_url": "http://arxiv.org/abs/2511.13841v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang",
      "Tri Dao"
    ]
  },
  {
    "title": "CURE: Cultural Understanding and Reasoning Evaluation - A Framework for \"Thick\" Culture Alignment Evaluation in LLMs",
    "authors": [
      "Truong Vo",
      "Sanmi Koyejo"
    ],
    "summary": "Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning...",
    "published": "Nov 15",
    "pdf_url": "https://arxiv.org/pdf/2511.12014v1",
    "arxiv_url": "http://arxiv.org/abs/2511.12014v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations",
    "authors": [
      "Eunkyu Park",
      "Wesley Hanwen Deng",
      "Vasudha Varadarajan",
      "Mingxi Yan",
      "Gunhee Kim",
      "Maarten Sap",
      "Motahhare Eslami"
    ],
    "summary": "Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically pert...",
    "published": "Nov 15",
    "pdf_url": "https://arxiv.org/pdf/2511.12001v2",
    "arxiv_url": "http://arxiv.org/abs/2511.12001v2",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "On the Entropy Calibration of Language Models",
    "authors": [
      "Steven Cao",
      "Gregory Valiant",
      "Percy Liang"
    ],
    "summary": "We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing (and text quality decreasing) as generations grow longer. This error accumul...",
    "published": "Nov 15",
    "pdf_url": "https://arxiv.org/pdf/2511.11966v1",
    "arxiv_url": "http://arxiv.org/abs/2511.11966v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Modeling and Predicting Multi-Turn Answer Instability in Large Language Models",
    "authors": [
      "Jiahang He",
      "Rishi Ramachandran",
      "Neel Ramachandran",
      "Aryan Katakam",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Aryan Shrivastava"
    ],
    "summary": "As large language models (LLMs) are adopted in an increasingly wide range of applications, user-model interactions have grown in both frequency and scale. Consequently, research has focused on evaluating the robustness of LLMs, an essential quality for real-world tasks. In this paper, we employ simp...",
    "published": "Nov 12",
    "pdf_url": "https://arxiv.org/pdf/2511.10688v1",
    "arxiv_url": "http://arxiv.org/abs/2511.10688v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Training Language Models to Explain Their Own Computations",
    "authors": [
      "Belinda Z. Li",
      "Zifan Carl Guo",
      "Vincent Huang",
      "Jacob Steinhardt",
      "Jacob Andreas"
    ],
    "summary": "Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Usin...",
    "published": "Nov 11",
    "pdf_url": "https://arxiv.org/pdf/2511.08579v2",
    "arxiv_url": "http://arxiv.org/abs/2511.08579v2",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "HipKittens: Fast and Furious AMD Kernels",
    "authors": [
      "William Hu",
      "Drew Wadsworth",
      "Sean Siddens",
      "Stanley Winata",
      "Daniel Y. Fu",
      "Ryann Swann",
      "Muhammad Osama",
      "Christopher R\u00e9",
      "Simran Arora"
    ],
    "summary": "AMD GPUs offer state-of-the-art compute and memory bandwidth; however, peak performance AMD kernels are written in raw assembly. To address the difficulty of mapping AI algorithms to hardware, recent work proposes C++ embedded and PyTorch-inspired domain-specific languages like ThunderKittens (TK) t...",
    "published": "Nov 11",
    "pdf_url": "https://arxiv.org/pdf/2511.08083v1",
    "arxiv_url": "http://arxiv.org/abs/2511.08083v1",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI",
    "authors": [
      "Jon Saad-Falcon",
      "Avanika Narayan",
      "Hakki Orhun Akengin",
      "J. Wes Griffin",
      "Herumb Shandilya",
      "Adrian Gamarra Lafuente",
      "Medhya Goel",
      "Rebecca Joseph",
      "Shlok Natarajan",
      "Etash Kumar Guha",
      "Shang Zhu",
      "Ben Athiwaratkun",
      "John Hennessy",
      "Azalia Mirhoseini",
      "Christopher R\u00e9"
    ],
    "summary": "Large language model (LLM) queries are predominantly processed by frontier models in centralized cloud infrastructure. Rapidly growing demand strains this paradigm, and cloud providers struggle to scale infrastructure at pace. Two advances enable us to rethink this paradigm: small LMs (<=20B active ...",
    "published": "Nov 11",
    "pdf_url": "https://arxiv.org/pdf/2511.07885v2",
    "arxiv_url": "http://arxiv.org/abs/2511.07885v2",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought",
    "authors": [
      "Shourya Batra",
      "Pierce Tillman",
      "Samarth Gaggar",
      "Shashank Kesineni",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma",
      "Maheep Chaudhary"
    ],
    "summary": "As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes,...",
    "published": "Nov 11",
    "pdf_url": "https://arxiv.org/pdf/2511.07772v2",
    "arxiv_url": "http://arxiv.org/abs/2511.07772v2",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments",
    "authors": [
      "Zhiyuan Zeng",
      "Hamish Ivison",
      "Yiping Wang",
      "Lifan Yuan",
      "Shuyue Stella Li",
      "Zhuorui Ye",
      "Siting Li",
      "Jacqueline He",
      "Runlong Zhou",
      "Tong Chen",
      "Chenyang Zhao",
      "Yulia Tsvetkov",
      "Simon Shaolei Du",
      "Natasha Jaques",
      "Hao Peng",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi"
    ],
    "summary": "We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to d...",
    "published": "Nov 10",
    "pdf_url": "https://arxiv.org/pdf/2511.07317v1",
    "arxiv_url": "http://arxiv.org/abs/2511.07317v1",
    "queried_author": "Hamish Ivison",
    "matching_authors": [
      "Hamish Ivison",
      "Hannaneh Hajishirzi",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search",
    "authors": [
      "Samuel Sokota",
      "Eugene Vinitsky",
      "Hengyuan Hu",
      "J. Zico Kolter",
      "Gabriele Farina"
    ],
    "summary": "Few classical games have been regarded as such significant benchmarks of artificial intelligence as to have justified training costs in the millions of dollars. Among these, Stratego -- a board wargame exemplifying the challenge of strategic decision making under massive amounts of hidden informatio...",
    "published": "Nov 10",
    "pdf_url": "https://arxiv.org/pdf/2511.07312v1",
    "arxiv_url": "http://arxiv.org/abs/2511.07312v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits",
    "authors": [
      "Dev Patel",
      "Gabrielle Gervacio",
      "Diekola Raimi",
      "Kevin Zhu",
      "Ryan Lagasse",
      "Gabriel Grand",
      "Ashwinee Panda",
      "Maheep Chaudhary"
    ],
    "summary": "Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critic...",
    "published": "Nov 09",
    "pdf_url": "https://arxiv.org/pdf/2511.07482v1",
    "arxiv_url": "http://arxiv.org/abs/2511.07482v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale",
    "authors": [
      "David Acuna",
      "Chao-Han Huck Yang",
      "Yuntian Deng",
      "Jaehun Jung",
      "Ximing Lu",
      "Prithviraj Ammanabrolu",
      "Hyunwoo Kim",
      "Yuan-Hong Liao",
      "Yejin Choi"
    ],
    "summary": "Recent progress in multimodal reasoning has been driven largely by undisclosed datasets and proprietary data synthesis recipes, leaving open questions about how to systematically build large-scale, vision-centric reasoning datasets, particularly for tasks that go beyond visual math. In this work, we...",
    "published": "Nov 07",
    "pdf_url": "https://arxiv.org/pdf/2511.05705v1",
    "arxiv_url": "http://arxiv.org/abs/2511.05705v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Real-Time Reasoning Agents in Evolving Environments",
    "authors": [
      "Yule Wen",
      "Yixin Ye",
      "Yanzhe Zhang",
      "Diyi Yang",
      "Hao Zhu"
    ],
    "summary": "Agents in the real world must make not only logical but also timely judgments. This requires continuous awareness of the dynamic environment: hazards emerge, opportunities arise, and other agents act, while the agent's reasoning is still unfolding. Despite advances in language model reasoning, exist...",
    "published": "Nov 07",
    "pdf_url": "https://arxiv.org/pdf/2511.04898v1",
    "arxiv_url": "http://arxiv.org/abs/2511.04898v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Addressing divergent representations from causal interventions on neural networks",
    "authors": [
      "Satchel Grant",
      "Simon Jerome Han",
      "Alexa R. Tartaglini",
      "Christopher Potts"
    ],
    "summary": "A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raise...",
    "published": "Nov 06",
    "pdf_url": "https://arxiv.org/pdf/2511.04638v4",
    "arxiv_url": "http://arxiv.org/abs/2511.04638v4",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations",
    "authors": [
      "Anka Reuel",
      "Avijit Ghosh",
      "Jenny Chim",
      "Andrew Tran",
      "Yanan Long",
      "Jennifer Mickel",
      "Usman Gohar",
      "Srishti Yadav",
      "Pawan Sasanka Ammanamanchi",
      "Mowafak Allaham",
      "Hossein A. Rahmani",
      "Mubashara Akhtar",
      "Felix Friedrich",
      "Robert Scholz",
      "Michael Alexander Riegler",
      "Jan Batzner",
      "Eliya Habba",
      "Arushi Saxena",
      "Anastassia Kornilova",
      "Kevin Wei",
      "Prajna Soni",
      "Yohan Mathew",
      "Kevin Klyman",
      "Jeba Sania",
      "Subramanyam Sahoo",
      "Olivia Beyer Bruvik",
      "Pouya Sadeghi",
      "Sujata Goswami",
      "Angelina Wang",
      "Yacine Jernite",
      "Zeerak Talat",
      "Stella Biderman",
      "Mykel Kochenderfer",
      "Sanmi Koyejo",
      "Irene Solaiman"
    ],
    "summary": "Foundation models are increasingly central to high-stakes AI systems, and governance frameworks now depend on evaluations to assess their risks and capabilities. Although general capability evaluations are widespread, social impact assessments covering bias, fairness, privacy, environmental costs, a...",
    "published": "Nov 06",
    "pdf_url": "https://arxiv.org/pdf/2511.05613v1",
    "arxiv_url": "http://arxiv.org/abs/2511.05613v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Reusing Pre-Training Data at Test Time is a Compute Multiplier",
    "authors": [
      "Alex Fang",
      "Thomas Voice",
      "Ruoming Pang",
      "Ludwig Schmidt",
      "Tom Gunter"
    ],
    "summary": "Large language models learn from their vast pre-training corpora, gaining the ability to solve an ever increasing variety of tasks; yet although researchers work to improve these datasets, there is little effort to understand how efficient the pre-training apparatus is at extracting ideas and knowle...",
    "published": "Nov 06",
    "pdf_url": "https://arxiv.org/pdf/2511.04234v1",
    "arxiv_url": "http://arxiv.org/abs/2511.04234v1",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents",
    "authors": [
      "Xingyao Wang",
      "Simon Rosenberg",
      "Juan Michelini",
      "Calvin Smith",
      "Hoang Tran",
      "Engel Nyst",
      "Rohit Malhotra",
      "Xuhui Zhou",
      "Valerie Chen",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "summary": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to...",
    "published": "Nov 05",
    "pdf_url": "https://arxiv.org/pdf/2511.03690v1",
    "arxiv_url": "http://arxiv.org/abs/2511.03690v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Reading Between the Lines: The One-Sided Conversation Problem",
    "authors": [
      "Victoria Ebert",
      "Rishabh Singh",
      "Tuochao Chen",
      "Noah A. Smith",
      "Shyamnath Gollakota"
    ],
    "summary": "Conversational AI is constrained in many real-world settings where only one side of a dialogue can be recorded, such as telemedicine, call centers, and smart glasses. We formalize this as the one-sided conversation problem (1SC): inferring and learning from one side of a conversation. We study two t...",
    "published": "Nov 04",
    "pdf_url": "https://arxiv.org/pdf/2511.03056v1",
    "arxiv_url": "http://arxiv.org/abs/2511.03056v1",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities",
    "authors": [
      "Amanda Bertsch",
      "Adithya Pratapa",
      "Teruko Mitamura",
      "Graham Neubig",
      "Matthew R. Gormley"
    ],
    "summary": "As model context lengths continue to grow, concerns about whether models effectively use the full context length have persisted. While several carefully designed long-context evaluations have recently been released, these evaluations tend to rely on retrieval from one or more sections of the context...",
    "published": "Nov 04",
    "pdf_url": "https://arxiv.org/pdf/2511.02817v1",
    "arxiv_url": "http://arxiv.org/abs/2511.02817v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval",
    "authors": [
      "Hung-Ting Chen",
      "Xiang Liu",
      "Shauli Ravfogel",
      "Eunsol Choi"
    ],
    "summary": "Most text retrievers generate \\emph{one} query vector to retrieve relevant documents. Yet, the conditional distribution of relevant documents for the query may be multimodal, e.g., representing different interpretations of the query. We first quantify the limitations of existing retrievers. All retr...",
    "published": "Nov 04",
    "pdf_url": "https://arxiv.org/pdf/2511.02770v1",
    "arxiv_url": "http://arxiv.org/abs/2511.02770v1",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster Decode Without Retraining",
    "authors": [
      "Costin-Andrei Oncescu",
      "Qingyang Wu",
      "Wai Tong Chung",
      "Robert Wu",
      "Bryan Gopal",
      "Junxiong Wang",
      "Tri Dao",
      "Ben Athiwaratkun"
    ],
    "summary": "An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures where the feed-forward layer is replaced by a pool of experts and each token only activates a small subset of them. During autoregressive generation, these models often enter a memory-bound regime even for moderate batch size...",
    "published": "Nov 04",
    "pdf_url": "https://arxiv.org/pdf/2511.02237v1",
    "arxiv_url": "http://arxiv.org/abs/2511.02237v1",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "Training Proactive and Personalized LLM Agents",
    "authors": [
      "Weiwei Sun",
      "Xuhui Zhou",
      "Weihua Du",
      "Xingyao Wang",
      "Sean Welleck",
      "Graham Neubig",
      "Maarten Sap",
      "Yiming Yang"
    ],
    "summary": "While existing work focuses primarily on task success, we argue that effective real-world agents require optimizing three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to diverse user preferences). We introduce UserVille, an inter...",
    "published": "Nov 04",
    "pdf_url": "https://arxiv.org/pdf/2511.02208v1",
    "arxiv_url": "http://arxiv.org/abs/2511.02208v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Maarten Sap",
      "Sean Welleck"
    ]
  },
  {
    "title": "Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior",
    "authors": [
      "Daniel Aarao Reis Arturi",
      "Eric Zhang",
      "Andrew Ansah",
      "Kevin Zhu",
      "Ashwinee Panda",
      "Aishwarya Balwani"
    ],
    "summary": "Recent work has discovered that large language models can develop broadly misaligned behaviors after being fine-tuned on narrowly harmful datasets, a phenomenon known as emergent misalignment (EM). However, the fundamental mechanisms enabling such harmful generalization across disparate domains rema...",
    "published": "Nov 03",
    "pdf_url": "https://arxiv.org/pdf/2511.02022v1",
    "arxiv_url": "http://arxiv.org/abs/2511.02022v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Accumulating Context Changes the Beliefs of Language Models",
    "authors": [
      "Jiayi Geng",
      "Howard Chen",
      "Ryan Liu",
      "Manoel Horta Ribeiro",
      "Robb Willer",
      "Graham Neubig",
      "Thomas L. Griffiths"
    ],
    "summary": "Language model (LM) assistants are increasingly used in applications such as brainstorming and research. Improvements in memory and context size have allowed these models to become more autonomous, which has also resulted in more text accumulation in their context windows without explicit user inter...",
    "published": "Nov 03",
    "pdf_url": "https://arxiv.org/pdf/2511.01805v2",
    "arxiv_url": "http://arxiv.org/abs/2511.01805v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks",
    "authors": [
      "Andrew M. Bean",
      "Ryan Othniel Kearns",
      "Angelika Romanou",
      "Franziska Sofia Hafner",
      "Harry Mayne",
      "Jan Batzner",
      "Negar Foroutan",
      "Chris Schmitz",
      "Karolina Korgul",
      "Hunar Batra",
      "Oishi Deb",
      "Emma Beharry",
      "Cornelius Emde",
      "Thomas Foster",
      "Anna Gausen",
      "Mar\u00eda Grandury",
      "Simeng Han",
      "Valentin Hofmann",
      "Lujain Ibrahim",
      "Hazel Kim",
      "Hannah Rose Kirk",
      "Fangru Lin",
      "Gabrielle Kaili-May Liu",
      "Lennart Luettgau",
      "Jabez Magomere",
      "Jonathan Rystr\u00f8m",
      "Anna Sotnikova",
      "Yushi Yang",
      "Yilun Zhao",
      "Adel Bibi",
      "Antoine Bosselut",
      "Ronald Clark",
      "Arman Cohan",
      "Jakob Foerster",
      "Yarin Gal",
      "Scott A. Hale",
      "Inioluwa Deborah Raji",
      "Christopher Summerfield",
      "Philip H. S. Torr",
      "Cozmin Ududec",
      "Luc Rocher",
      "Adam Mahdi"
    ],
    "summary": "Evaluating large language models (LLMs) is crucial for both assessing their capabilities and identifying safety or robustness issues prior to deployment. Reliably measuring abstract and complex phenomena such as 'safety' and 'robustness' requires strong construct validity, that is, having measures t...",
    "published": "Nov 03",
    "pdf_url": "https://arxiv.org/pdf/2511.04703v1",
    "arxiv_url": "http://arxiv.org/abs/2511.04703v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering",
    "authors": [
      "John Yang",
      "Kilian Lieret",
      "Joyce Yang",
      "Carlos E. Jimenez",
      "Ofir Press",
      "Ludwig Schmidt",
      "Diyi Yang"
    ],
    "summary": "Current benchmarks for coding evaluate language models (LMs) on concrete, well-specified tasks such as fixing specific bugs or writing targeted tests. However, human programmers do not spend all day incessantly addressing isolated tasks. Instead, real-world software development is grounded in the pu...",
    "published": "Nov 02",
    "pdf_url": "https://arxiv.org/pdf/2511.00839v1",
    "arxiv_url": "http://arxiv.org/abs/2511.00839v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering",
    "authors": [
      "Eric Bigelow",
      "Daniel Wurgaft",
      "YingQiao Wang",
      "Noah Goodman",
      "Tomer Ullman",
      "Hidenori Tanaka",
      "Ekdeep Singh Lubana"
    ],
    "summary": "Large language models (LLMs) can be controlled at inference time through prompts (in-context learning) and internal activations (activation steering). Different accounts have been proposed to explain these methods, yet their common goal of controlling model behavior raises the question of whether th...",
    "published": "Nov 01",
    "pdf_url": "https://arxiv.org/pdf/2511.00617v1",
    "arxiv_url": "http://arxiv.org/abs/2511.00617v1",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman"
    ]
  },
  {
    "title": "Culture Cartography: Mapping the Landscape of Cultural Knowledge",
    "authors": [
      "Caleb Ziems",
      "William Held",
      "Jane Yu",
      "Amir Goldberg",
      "David Grusky",
      "Diyi Yang"
    ],
    "summary": "To serve global users safely and productively, LLMs need culture-specific knowledge that might not be learned during pre-training. How do we find such knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The most common solutions are single-initiative: either researchers define ...",
    "published": "Oct 31",
    "pdf_url": "https://arxiv.org/pdf/2510.27672v1",
    "arxiv_url": "http://arxiv.org/abs/2510.27672v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "William Held"
    ]
  },
  {
    "title": "Thought Branches: Interpreting LLM Reasoning Requires Resampling",
    "authors": [
      "Uzay Macar",
      "Paul C. Bogdan",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "Most work interpreting reasoning models studies only a single chain-of-thought (CoT), yet these models define distributions over many possible CoTs. We argue that studying a single sample is inadequate for understanding causal influence and the underlying computation. Though fully specifying this di...",
    "published": "Oct 31",
    "pdf_url": "https://arxiv.org/pdf/2510.27484v1",
    "arxiv_url": "http://arxiv.org/abs/2510.27484v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments",
    "authors": [
      "Rishika Bhagwatkar",
      "Syrielle Montariol",
      "Angelika Romanou",
      "Beatriz Borges",
      "Irina Rish",
      "Antoine Bosselut"
    ],
    "summary": "Humans can naturally identify, reason about, and explain anomalies in their environment. In computer vision, this long-standing challenge remains limited to industrial defects or unrealistic, synthetically generated anomalies, failing to capture the richness and unpredictability of real-world anomal...",
    "published": "Oct 29",
    "pdf_url": "https://arxiv.org/pdf/2510.26006v1",
    "arxiv_url": "http://arxiv.org/abs/2510.26006v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Revisiting Multilingual Data Mixtures in Language Model Pretraining",
    "authors": [
      "Negar Foroutan",
      "Paul Teiletche",
      "Ayush Kumar Tarun",
      "Antoine Bosselut"
    ],
    "summary": "The impact of different multilingual data mixtures in pretraining large language models (LLMs) has been a topic of ongoing debate, often raising concerns about potential trade-offs between language coverage and model performance (i.e., the curse of multilinguality). In this work, we investigate thes...",
    "published": "Oct 29",
    "pdf_url": "https://arxiv.org/pdf/2510.25947v1",
    "arxiv_url": "http://arxiv.org/abs/2510.25947v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution",
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ],
    "summary": "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existi...",
    "published": "Oct 29",
    "pdf_url": "https://arxiv.org/pdf/2510.25726v1",
    "arxiv_url": "http://arxiv.org/abs/2510.25726v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
    "authors": [
      "Auguste Poiroux",
      "Antoine Bosselut",
      "Viktor Kun\u010dak"
    ],
    "summary": "Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-wo...",
    "published": "Oct 29",
    "pdf_url": "https://arxiv.org/pdf/2510.25427v1",
    "arxiv_url": "http://arxiv.org/abs/2510.25427v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents",
    "authors": [
      "Yueqi Song",
      "Ketan Ramaneti",
      "Zaid Sheikh",
      "Ziru Chen",
      "Boyu Gou",
      "Tianbao Xie",
      "Yiheng Xu",
      "Danyang Zhang",
      "Apurva Gandhi",
      "Fan Yang",
      "Joseph Liu",
      "Tianyue Ou",
      "Zhihao Yuan",
      "Frank Xu",
      "Shuyan Zhou",
      "Xingyao Wang",
      "Xiang Yue",
      "Tao Yu",
      "Huan Sun",
      "Yu Su",
      "Graham Neubig"
    ],
    "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmente...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24702v1",
    "arxiv_url": "http://arxiv.org/abs/2510.24702v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning",
    "authors": [
      "Bo Liu",
      "Chuanyang Jin",
      "Seungone Kim",
      "Weizhe Yuan",
      "Wenting Zhao",
      "Ilia Kulikov",
      "Xian Li",
      "Sainbayar Sukhbaatar",
      "Jack Lanchantin",
      "Jason Weston"
    ],
    "summary": "Self-improving systems require environmental interaction for continuous adaptation. We introduce SPICE (Self-Play In Corpus Environments), a reinforcement learning framework where a single model acts in two roles: a Challenger that mines documents from a large corpus to generate diverse reasoning ta...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24684v1",
    "arxiv_url": "http://arxiv.org/abs/2510.24684v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Relative Scaling Laws for LLMs",
    "authors": [
      "William Held",
      "David Hall",
      "Percy Liang",
      "Diyi Yang"
    ],
    "summary": "Scaling laws describe how language models improve with additional data, parameters, and compute. While widely used, they are typically measured on aggregate test sets. Aggregate evaluations yield clean trends but average over heterogeneous subpopulations, obscuring performance disparities. We introd...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24626v1",
    "arxiv_url": "http://arxiv.org/abs/2510.24626v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "Percy Liang",
      "William Held"
    ]
  },
  {
    "title": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?",
    "authors": [
      "Christine Ye",
      "Sihan Yuan",
      "Suchetha Cooray",
      "Steven Dillmann",
      "Ian L. V. Roque",
      "Dalya Baron",
      "Philipp Frank",
      "Sergio Martin-Alvarez",
      "Nolan Koblischke",
      "Frank J Qu",
      "Diyi Yang",
      "Risa Wechsler",
      "Ioana Ciuca"
    ],
    "summary": "Frontier AI agents show increasing promise as scientific research assistants, and may eventually be useful for extended, open-ended research workflows. However, in order to use agents for novel research, we must first assess the underlying faithfulness and correctness of their work. To evaluate agen...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24591v2",
    "arxiv_url": "http://arxiv.org/abs/2510.24591v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "From Memorization to Reasoning in the Spectrum of Loss Curvature",
    "authors": [
      "Jack Merullo",
      "Srihita Vatsavaya",
      "Lucius Bushnaq",
      "Owen Lewis"
    ],
    "summary": "We characterize how memorization is represented in transformer models and show that it can be disentangled in the weights of both language models (LMs) and vision transformers (ViTs) using a decomposition based on the loss landscape curvature. This insight is based on prior theoretical and empirical...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24256v2",
    "arxiv_url": "http://arxiv.org/abs/2510.24256v2",
    "queried_author": "Jack Merullo",
    "matching_authors": [
      "Jack Merullo"
    ]
  },
  {
    "title": "Success and Cost Elicit Convention Formation for Efficient Communication",
    "authors": [
      "Saujas Vaduguru",
      "Yilun Hua",
      "Yoav Artzi",
      "Daniel Fried"
    ],
    "summary": "Humans leverage shared conversational context to become increasingly successful and efficient at communicating over time. One manifestation of this is the formation of ad hoc linguistic conventions, which allow people to coordinate on short, less costly utterances that are understood using shared co...",
    "published": "Oct 28",
    "pdf_url": "https://arxiv.org/pdf/2510.24023v1",
    "arxiv_url": "http://arxiv.org/abs/2510.24023v1",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)",
    "authors": [
      "Liwei Jiang",
      "Yuanjun Chai",
      "Margaret Li",
      "Mickel Liu",
      "Raymond Fok",
      "Nouha Dziri",
      "Yulia Tsvetkov",
      "Maarten Sap",
      "Alon Albalak",
      "Yejin Choi"
    ],
    "summary": "Language models (LMs) often struggle to generate diverse, human-like creative content, raising concerns about the long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods for evaluating LM output diversity remain limited, especially beyond narrow t...",
    "published": "Oct 27",
    "pdf_url": "https://arxiv.org/pdf/2510.22954v1",
    "arxiv_url": "http://arxiv.org/abs/2510.22954v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap",
      "Yejin Choi"
    ]
  },
  {
    "title": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations",
    "authors": [
      "Zora Zhiruo Wang",
      "Yijia Shao",
      "Omar Shaikh",
      "Daniel Fried",
      "Graham Neubig",
      "Diyi Yang"
    ],
    "summary": "AI agents are continually optimized for tasks related to human work, such as software engineering and professional writing, signaling a pressing trend with significant impacts on the human workforce. However, these agent developments have often not been grounded in a clear understanding of how human...",
    "published": "Oct 26",
    "pdf_url": "https://arxiv.org/pdf/2510.22780v2",
    "arxiv_url": "http://arxiv.org/abs/2510.22780v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "Graham Neubig"
    ]
  },
  {
    "title": "ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality",
    "authors": [
      "Shayne Longpre",
      "Sneha Kudugunta",
      "Niklas Muennighoff",
      "I-Hung Hsu",
      "Isaac Caswell",
      "Alex Pentland",
      "Sercan Arik",
      "Chen-Yu Lee",
      "Sayna Ebrahimi"
    ],
    "summary": "Scaling laws research has focused overwhelmingly on English -- yet the most prominent AI models explicitly serve billions of international users. In this work, we undertake the largest multilingual scaling laws study to date, totaling 774 multilingual training experiments, spanning 10M-8B model para...",
    "published": "Oct 24",
    "pdf_url": "https://arxiv.org/pdf/2510.22037v1",
    "arxiv_url": "http://arxiv.org/abs/2510.22037v1",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff"
    ]
  },
  {
    "title": "A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection",
    "authors": [
      "Gaku Morio",
      "Harri Rowlands",
      "Dominik Stammbach",
      "Christopher D. Manning",
      "Peter Henderson"
    ],
    "summary": "Companies spend large amounts of money on public relations campaigns to project a positive brand image. However, sometimes there is a mismatch between what they say and what they do. Oil & gas companies, for example, are accused of \"greenwashing\" with imagery of climate-friendly initiatives. Underst...",
    "published": "Oct 24",
    "pdf_url": "https://arxiv.org/pdf/2510.21679v1",
    "arxiv_url": "http://arxiv.org/abs/2510.21679v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "TOM-SWE: User Mental Modeling For Software Engineering Agents",
    "authors": [
      "Xuhui Zhou",
      "Valerie Chen",
      "Zora Zhiruo Wang",
      "Graham Neubig",
      "Maarten Sap",
      "Xingyao Wang"
    ],
    "summary": "Recent advances in coding agents have made them capable of planning, editing, running, and testing complex code bases. Despite their growing ability in coding tasks, these systems still struggle to infer and track user intent, especially when instructions are underspecified or context-dependent. To ...",
    "published": "Oct 24",
    "pdf_url": "https://arxiv.org/pdf/2510.21903v1",
    "arxiv_url": "http://arxiv.org/abs/2510.21903v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Maarten Sap"
    ]
  },
  {
    "title": "L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks",
    "authors": [
      "Jiyu Cui",
      "Fang Wu",
      "Haokai Zhao",
      "Minggao Feng",
      "Xenophon Evangelopoulos",
      "Andrew I. Cooper",
      "Yejin Choi"
    ],
    "summary": "Large language models have demonstrated remarkable reasoning capabilities across diverse natural language tasks. However, comparable breakthroughs in scientific discovery are more limited, because understanding complex physical phenomena demands multifaceted representations far beyond language alone...",
    "published": "Oct 23",
    "pdf_url": "https://arxiv.org/pdf/2510.20976v1",
    "arxiv_url": "http://arxiv.org/abs/2510.20976v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Code-enabled language models can outperform reasoning models on diverse tasks",
    "authors": [
      "Cedegao E. Zhang",
      "C\u00e9dric Colas",
      "Gabriel Poesia",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "summary": "Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still require large amounts of computation and data to train, and can be slow and expensive to run. In this paper, we show that...",
    "published": "Oct 23",
    "pdf_url": "https://arxiv.org/pdf/2510.20909v1",
    "arxiv_url": "http://arxiv.org/abs/2510.20909v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People",
    "authors": [
      "Gabriel Grand",
      "Valerio Pepe",
      "Jacob Andreas",
      "Joshua B. Tenenbaum"
    ],
    "summary": "Many high-stakes applications of AI require forming data-driven hypotheses and making targeted guesses; e.g., in scientific and diagnostic settings. Given limited resources, to what extent do agents based on language models (LMs) act rationally? We develop methods to benchmark and enhance agentic in...",
    "published": "Oct 23",
    "pdf_url": "https://arxiv.org/pdf/2510.20886v1",
    "arxiv_url": "http://arxiv.org/abs/2510.20886v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training",
    "authors": [
      "Yair Feldman",
      "Yoav Artzi"
    ],
    "summary": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean...",
    "published": "Oct 23",
    "pdf_url": "https://arxiv.org/pdf/2510.20797v1",
    "arxiv_url": "http://arxiv.org/abs/2510.20797v1",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Steering Evaluation-Aware Language Models to Act Like They Are Deployed",
    "authors": [
      "Tim Tian Hua",
      "Andrew Qin",
      "Samuel Marks",
      "Neel Nanda"
    ],
    "summary": "Large language models (LLMs) can sometimes detect when they are being evaluated and adjust their behavior to appear more aligned, compromising the reliability of safety evaluations. In this paper, we show that adding a steering vector to an LLM's activations can suppress evaluation-awareness and mak...",
    "published": "Oct 23",
    "pdf_url": "https://arxiv.org/pdf/2510.20487v3",
    "arxiv_url": "http://arxiv.org/abs/2510.20487v3",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "olmOCR 2: Unit Test Rewards for Document OCR",
    "authors": [
      "Jake Poznanski",
      "Luca Soldaini",
      "Kyle Lo"
    ],
    "summary": "We present olmOCR 2, the latest in our family of powerful OCR systems for converting digitized print documents, like PDFs, into clean, naturally ordered plain text. olmOCR 2 is powered by olmOCR-2-7B-1025, a specialized, 7B vision language model (VLM) trained using reinforcement learning with verifi...",
    "published": "Oct 22",
    "pdf_url": "https://arxiv.org/pdf/2510.19817v1",
    "arxiv_url": "http://arxiv.org/abs/2510.19817v1",
    "queried_author": "Kyle Lo",
    "matching_authors": [
      "Kyle Lo",
      "Luca Soldaini"
    ]
  },
  {
    "title": "Blackbox Model Provenance via Palimpsestic Membership Inference",
    "authors": [
      "Rohith Kuditipudi",
      "Jing Huang",
      "Sally Zhu",
      "Diyi Yang",
      "Christopher Potts",
      "Percy Liang"
    ],
    "summary": "Suppose Alice trains an open-weight language model and Bob uses a blackbox derivative of Alice's model to produce text. Can Alice prove that Bob is using her model, either by querying Bob's derivative model (query setting) or from the text alone (observational setting)? We formulate this question as...",
    "published": "Oct 22",
    "pdf_url": "https://arxiv.org/pdf/2510.19796v1",
    "arxiv_url": "http://arxiv.org/abs/2510.19796v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts",
      "Diyi Yang",
      "Percy Liang"
    ]
  },
  {
    "title": "GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters",
    "authors": [
      "Anand Choudhary",
      "Yasser Sula\u0131man",
      "Lukas Mauch",
      "Ghouthi Boukli Hacene",
      "Fabien Cardinaux",
      "Antoine Bosselut"
    ],
    "summary": "Sparse fine-tuning techniques adapt LLMs to downstream tasks by only tuning a sparse subset of model parameters. However, the effectiveness of sparse adaptation depends on optimally selecting the model parameters to be fine-tuned. In this work, we introduce a novel sparse fine-tuning technique named...",
    "published": "Oct 22",
    "pdf_url": "https://arxiv.org/pdf/2510.19778v1",
    "arxiv_url": "http://arxiv.org/abs/2510.19778v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "TowerVision: Understanding and Improving Multilinguality in Vision-Language Models",
    "authors": [
      "Andr\u00e9 G. Viveiros",
      "Patrick Fernandes",
      "Saul Santos",
      "Sonal Sannigrahi",
      "Emmanouil Zaranis",
      "Nuno M. Guerreiro",
      "Amin Farajian",
      "Pierre Colombo",
      "Graham Neubig",
      "Andr\u00e9 F. T. Martins"
    ],
    "summary": "Despite significant advances in vision-language models (VLMs), most existing work follows an English-centric design process, limiting their effectiveness in multilingual settings. In this work, we provide a comprehensive empirical study analyzing the impact of several multilingual design choices, su...",
    "published": "Oct 22",
    "pdf_url": "https://arxiv.org/pdf/2510.21849v3",
    "arxiv_url": "http://arxiv.org/abs/2510.21849v3",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference",
    "authors": [
      "Xiang Liu",
      "Xuming Hu",
      "Xiaowen Chu",
      "Eunsol Choi"
    ],
    "summary": "Recent reasoning Large Language Models (LLMs) demonstrate remarkable problem-solving abilities but often generate long thinking traces whose utility is unclear. Our work aims to improve their efficiency, enabling them to reach high performance without overthinking. First, we analyze the entropy of t...",
    "published": "Oct 22",
    "pdf_url": "https://arxiv.org/pdf/2510.19669v2",
    "arxiv_url": "http://arxiv.org/abs/2510.19669v2",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge",
    "authors": [
      "Zhilin Wang",
      "Jaehun Jung",
      "Ximing Lu",
      "Shizhe Diao",
      "Ellie Evans",
      "Jiaqi Zeng",
      "Pavlo Molchanov",
      "Yejin Choi",
      "Jan Kautz",
      "Yi Dong"
    ],
    "summary": "Evaluating progress in large language models (LLMs) is often constrained by the challenge of verifying responses, limiting assessments to tasks like mathematics, programming, and short-form question-answering. However, many real-world applications require evaluating LLMs in processing professional d...",
    "published": "Oct 21",
    "pdf_url": "https://arxiv.org/pdf/2510.18941v1",
    "arxiv_url": "http://arxiv.org/abs/2510.18941v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting",
    "authors": [
      "Howard Chen",
      "Noam Razin",
      "Karthik Narasimhan",
      "Danqi Chen"
    ],
    "summary": "Adapting language models (LMs) to new tasks via post-training carries the risk of degrading existing capabilities -- a phenomenon classically known as catastrophic forgetting. In this paper, toward identifying guidelines for mitigating this phenomenon, we systematically compare the forgetting patter...",
    "published": "Oct 21",
    "pdf_url": "https://arxiv.org/pdf/2510.18874v2",
    "arxiv_url": "http://arxiv.org/abs/2510.18874v2",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search",
    "authors": [
      "Howard Yen",
      "Ashwin Paranjape",
      "Mengzhou Xia",
      "Thejas Venkatesh",
      "Jack Hessel",
      "Danqi Chen",
      "Yuhao Zhang"
    ],
    "summary": "Long-horizon agentic search requires iteratively exploring the web over long trajectories and synthesizing information across many sources, and is the foundation for enabling powerful applications like deep research systems. In this work, we show that popular agentic search frameworks struggle to sc...",
    "published": "Oct 21",
    "pdf_url": "https://arxiv.org/pdf/2510.18939v1",
    "arxiv_url": "http://arxiv.org/abs/2510.18939v1",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "Extracting Rule-based Descriptions of Attention Features in Transformers",
    "authors": [
      "Dan Friedman",
      "Adithya Bhaskar",
      "Alexander Wettig",
      "Danqi Chen"
    ],
    "summary": "Mechanistic interpretability strives to explain model behavior in terms of bottom-up primitives. The leading paradigm is to express hidden states as a sparse linear combination of basis vectors, called features. However, this only identifies which text sequences (exemplars) activate which features; ...",
    "published": "Oct 20",
    "pdf_url": "https://arxiv.org/pdf/2510.18148v1",
    "arxiv_url": "http://arxiv.org/abs/2510.18148v1",
    "queried_author": "Alexander Wettig",
    "matching_authors": [
      "Alexander Wettig",
      "Danqi Chen"
    ]
  },
  {
    "title": "Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations",
    "authors": [
      "Tong Chen",
      "Akari Asai",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi",
      "Faeze Brahman"
    ],
    "summary": "Language models often generate factually incorrect information unsupported by their training data, a phenomenon known as extrinsic hallucination. Existing mitigation approaches often degrade performance on open-ended generation and downstream tasks, limiting their practical utility. We propose an on...",
    "published": "Oct 20",
    "pdf_url": "https://arxiv.org/pdf/2510.17733v1",
    "arxiv_url": "http://arxiv.org/abs/2510.17733v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Prompt-MII: Meta-Learning Instruction Induction for LLMs",
    "authors": [
      "Emily Xiao",
      "Yixiao Zeng",
      "Ada Chen",
      "Chin-Jou Li",
      "Amanda Bertsch",
      "Graham Neubig"
    ],
    "summary": "A popular method to adapt large language models (LLMs) to new tasks is in-context learning (ICL), which is effective but incurs high inference costs as context length grows. In this paper we propose a method to perform instruction induction, where we take training examples and reduce them to a compa...",
    "published": "Oct 19",
    "pdf_url": "https://arxiv.org/pdf/2510.16932v2",
    "arxiv_url": "http://arxiv.org/abs/2510.16932v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents",
    "authors": [
      "Kangrui Wang",
      "Pingyue Zhang",
      "Zihan Wang",
      "Yaning Gao",
      "Linjie Li",
      "Qineng Wang",
      "Hanyang Chen",
      "Chi Wan",
      "Yiping Lu",
      "Zhengyuan Yang",
      "Lijuan Wang",
      "Ranjay Krishna",
      "Jiajun Wu",
      "Li Fei-Fei",
      "Yejin Choi",
      "Manling Li"
    ],
    "summary": "A key challenge in training Vision-Language Model (VLM) agents, compared to Language Model (LLM) agents, lies in the shift from textual states to complex visual observations. This transition introduces partial observability and demands robust world modeling. We ask: Can VLM agents construct internal...",
    "published": "Oct 19",
    "pdf_url": "https://arxiv.org/pdf/2510.16907v1",
    "arxiv_url": "http://arxiv.org/abs/2510.16907v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes",
    "authors": [
      "Yu Ying Chiu",
      "Michael S. Lee",
      "Rachel Calcott",
      "Brandon Handoko",
      "Paul de Font-Reaulx",
      "Paula Rodriguez",
      "Chen Bo Calvin Zhang",
      "Ziwen Han",
      "Udari Madhushani Sehwag",
      "Yash Maurya",
      "Christina Q Knight",
      "Harry R. Lloyd",
      "Florence Bacus",
      "Mantas Mazeika",
      "Bing Liu",
      "Yejin Choi",
      "Mitchell L Gordon",
      "Sydney Levine"
    ],
    "summary": "As AI systems progress, we rely more on them to make decisions with us and for us. To ensure that such decisions are aligned with human values, it is imperative for us to understand not only what decisions they make but also how they come to those decisions. Reasoning language models, which provide ...",
    "published": "Oct 18",
    "pdf_url": "https://arxiv.org/pdf/2510.16380v1",
    "arxiv_url": "http://arxiv.org/abs/2510.16380v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning",
    "authors": [
      "Shih-Yang Liu",
      "Xin Dong",
      "Ximing Lu",
      "Shizhe Diao",
      "Mingjie Liu",
      "Min-Hung Chen",
      "Hongxu Yin",
      "Yu-Chiang Frank Wang",
      "Kwang-Ting Cheng",
      "Yejin Choi",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "summary": "Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve strong performance via extended chains of thought but often generate unnecessarily long outputs. Maximizing intelligence per token--accuracy relative to response length--remains an open problem. We revisit reinforcement learn...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.15110v1",
    "arxiv_url": "http://arxiv.org/abs/2510.15110v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Continual Learning via Sparse Memory Finetuning",
    "authors": [
      "Jessy Lin",
      "Luke Zettlemoyer",
      "Gargi Ghosh",
      "Wen-Tau Yih",
      "Aram Markosyan",
      "Vincent-Pierre Berges",
      "Barlas O\u011fuz"
    ],
    "summary": "Modern language models are powerful, but typically static after deployment. A major obstacle to building models that continually learn over time is catastrophic forgetting, where updating on new data erases previously acquired capabilities. Motivated by the intuition that mitigating forgetting is ch...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.15103v1",
    "arxiv_url": "http://arxiv.org/abs/2510.15103v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data",
    "authors": [
      "Alana Renda",
      "Jillian Ross",
      "Michael Cafarella",
      "Jacob Andreas"
    ],
    "summary": "Real-world settings where language models (LMs) are deployed -- in domains spanning healthcare, finance, and other forms of knowledge work -- require models to grapple with incomplete information and reason under uncertainty. Yet most LM evaluations focus on problems with well-defined answers and su...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.15096v1",
    "arxiv_url": "http://arxiv.org/abs/2510.15096v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Midtraining Bridges Pretraining and Posttraining Distributions",
    "authors": [
      "Emmy Liu",
      "Graham Neubig",
      "Chenyan Xiong"
    ],
    "summary": "Recently, many language models have been pretrained with a \"midtraining\" phase, in which higher quality, often instruction-formatted data, is mixed in at the end of pretraining. Despite the popularity of this practice, there is little scientific understanding of this phase of model training or why i...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.14865v1",
    "arxiv_url": "http://arxiv.org/abs/2510.14865v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Just-In-Time Objectives: A General Approach for Specialized AI Interactions",
    "authors": [
      "Michelle S. Lam",
      "Omar Shaikh",
      "Hallie Xu",
      "Alice Guo",
      "Diyi Yang",
      "Jeffrey Heer",
      "James A. Landay",
      "Michael S. Bernstein"
    ],
    "summary": "Large language models promise a broad set of functions, but when not given a specific objective, they default to milquetoast results such as drafting emails littered with cliches. We demonstrate that inferring the user's in-the-moment objective, then rapidly optimizing for that singular objective, e...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.14591v1",
    "arxiv_url": "http://arxiv.org/abs/2510.14591v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "MERLIN: A Testbed for Multilingual Multimodal Entity Recognition and Linking",
    "authors": [
      "Sathyanarayanan Ramamoorthy",
      "Vishwa Shah",
      "Simran Khanuja",
      "Zaid Sheikh",
      "Shan Jie",
      "Ann Chia",
      "Shearman Chua",
      "Graham Neubig"
    ],
    "summary": "This paper introduces MERLIN, a novel testbed system for the task of Multilingual Multimodal Entity Linking. The created dataset includes BBC news article titles, paired with corresponding images, in five languages: Hindi, Japanese, Indonesian, Vietnamese, and Tamil, featuring over 7,000 named entit...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.14307v1",
    "arxiv_url": "http://arxiv.org/abs/2510.14307v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Rewriting History: A Recipe for Interventional Analyses to Study Data Effects on Model Behavior",
    "authors": [
      "Rahul Nadkarni",
      "Yanai Elazar",
      "Hila Gonen",
      "Noah A. Smith"
    ],
    "summary": "We present an experimental recipe for studying the relationship between training data and language model (LM) behavior. We outline steps for intervening on data batches -- i.e., ``rewriting history'' -- and then retraining model checkpoints over that data to test hypotheses relating data to behavior...",
    "published": "Oct 16",
    "pdf_url": "https://arxiv.org/pdf/2510.14261v1",
    "arxiv_url": "http://arxiv.org/abs/2510.14261v1",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "Breadcrumbs Reasoning: Memory-Efficient Reasoning with Compression Beacons",
    "authors": [
      "Giovanni Monea",
      "Yair Feldman",
      "Shankar Padmanabhan",
      "Kiant\u00e9 Brantley",
      "Yoav Artzi"
    ],
    "summary": "The scalability of large language models for long-context reasoning is severely constrained by the linear growth of their Transformer key-value cache, which incurs significant memory and computational costs. We posit that as a model generates reasoning tokens, the informational value of past generat...",
    "published": "Oct 15",
    "pdf_url": "https://arxiv.org/pdf/2510.13797v3",
    "arxiv_url": "http://arxiv.org/abs/2510.13797v3",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences",
    "authors": [
      "Julian Minder",
      "Cl\u00e9ment Dumas",
      "Stewart Slocum",
      "Helena Casademunt",
      "Cameron Holmes",
      "Robert West",
      "Neel Nanda"
    ],
    "summary": "Finetuning on narrow domains has become an essential tool to adapt Large Language Models (LLMs) to specific tasks and to create models with known unusual properties that are useful for research. We show that narrow finetuning creates strong biases in LLM activations that can be interpreted to unders...",
    "published": "Oct 14",
    "pdf_url": "https://arxiv.org/pdf/2510.13900v1",
    "arxiv_url": "http://arxiv.org/abs/2510.13900v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations",
    "authors": [
      "Sunny Yu",
      "Ahmad Jabbar",
      "Robert Hawkins",
      "Dan Jurafsky",
      "Myra Cheng"
    ],
    "summary": "Different open-ended generation tasks require different degrees of output diversity. However, current LLMs are often miscalibrated. They collapse to overly homogeneous outputs for creative tasks and hallucinate diverse but incorrect responses for factual tasks. We argue that these two failure modes ...",
    "published": "Oct 14",
    "pdf_url": "https://arxiv.org/pdf/2510.12699v1",
    "arxiv_url": "http://arxiv.org/abs/2510.12699v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Chimera: State Space Models Beyond Sequences",
    "authors": [
      "Aakash Lahoti",
      "Tanya Marwah",
      "Ratish Puduppully",
      "Albert Gu"
    ],
    "summary": "Transformer-based deep learning methods have become the standard approach for modeling diverse data such as sequences, images, and graphs. These methods rely on self-attention, which treats data as an unordered set of elements. This ignores the neighborhood structure or graph topology of the data an...",
    "published": "Oct 14",
    "pdf_url": "https://arxiv.org/pdf/2510.12111v1",
    "arxiv_url": "http://arxiv.org/abs/2510.12111v1",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu"
    ]
  },
  {
    "title": "Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation",
    "authors": [
      "Sayash Kapoor",
      "Benedikt Stroebl",
      "Peter Kirgis",
      "Nitya Nadgir",
      "Zachary S Siegel",
      "Boyi Wei",
      "Tianci Xue",
      "Ziru Chen",
      "Felix Chen",
      "Saiteja Utpala",
      "Franck Ndzomga",
      "Dheeraj Oruganty",
      "Sophie Luskin",
      "Kangheng Liu",
      "Botao Yu",
      "Amit Arora",
      "Dongyoon Hahm",
      "Harsh Trivedi",
      "Huan Sun",
      "Juyong Lee",
      "Tengjun Jin",
      "Yifan Mai",
      "Yifei Zhou",
      "Yuxuan Zhu",
      "Rishi Bommasani",
      "Daniel Kang",
      "Dawn Song",
      "Peter Henderson",
      "Yu Su",
      "Percy Liang",
      "Arvind Narayanan"
    ],
    "summary": "AI agents have been developed for complex real-world tasks from coding to customer service. But AI agent evaluations suffer from many challenges that undermine our understanding of how well agents really work. We introduce the Holistic Agent Leaderboard (HAL) to address these challenges. We make thr...",
    "published": "Oct 13",
    "pdf_url": "https://arxiv.org/pdf/2510.11977v1",
    "arxiv_url": "http://arxiv.org/abs/2510.11977v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Data or Language Supervision: What Makes CLIP Better than DINO?",
    "authors": [
      "Yiming Liu",
      "Yuhui Zhang",
      "Dhruba Ghosh",
      "Ludwig Schmidt",
      "Serena Yeung-Levy"
    ],
    "summary": "CLIP outperforms self-supervised models like DINO as vision encoders for vision-language models (VLMs), but it remains unclear whether this advantage stems from CLIP's language supervision or its much larger training data. To disentangle these factors, we pre-train CLIP and DINO under controlled set...",
    "published": "Oct 13",
    "pdf_url": "https://arxiv.org/pdf/2510.11835v1",
    "arxiv_url": "http://arxiv.org/abs/2510.11835v1",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors",
    "authors": [
      "Alexis Ross",
      "Jacob Andreas"
    ],
    "summary": "Research on reasoning in language models (LMs) predominantly focuses on improving the correctness of their outputs. But some important applications require modeling reasoning patterns that are incorrect. For example, automated systems that can reason about and simulate student errors are useful for ...",
    "published": "Oct 13",
    "pdf_url": "https://arxiv.org/pdf/2510.11502v1",
    "arxiv_url": "http://arxiv.org/abs/2510.11502v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs",
    "authors": [
      "Nikita Afonin",
      "Nikita Andriyanov",
      "Nikhil Bageshpura",
      "Kyle Liu",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Alexander Panchenko",
      "Oleg Rogov",
      "Elena Tutubalina",
      "Mikhail Seleznyov"
    ],
    "summary": "Recent work has shown that narrow finetuning can produce broadly misaligned LLMs, a phenomenon termed emergent misalignment (EM). While concerning, these findings were limited to finetuning and activation steering, leaving out in-context learning (ICL). We therefore ask: does EM emerge in ICL? We fi...",
    "published": "Oct 13",
    "pdf_url": "https://arxiv.org/pdf/2510.11288v1",
    "arxiv_url": "http://arxiv.org/abs/2510.11288v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting",
    "authors": [
      "Michael Y. Hu",
      "Benjamin Van Durme",
      "Jacob Andreas",
      "Harsh Jhamtani"
    ],
    "summary": "Language model (LM) agents deployed in novel environments often exhibit poor sample efficiency when learning from sequential interactions. This significantly hinders the usefulness of such agents in environments where interaction is costly (for example, when they interact with humans or reset physic...",
    "published": "Oct 11",
    "pdf_url": "https://arxiv.org/pdf/2510.10304v1",
    "arxiv_url": "http://arxiv.org/abs/2510.10304v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "HUME: Measuring the Human-Model Performance Gap in Text Embedding Tasks",
    "authors": [
      "Adnan El Assadi",
      "Isaac Chung",
      "Roman Solomatin",
      "Niklas Muennighoff",
      "Kenneth Enevoldsen"
    ],
    "summary": "Comparing human and model performance offers a valuable perspective for understanding the strengths and limitations of embedding models, highlighting where they succeed and where they fail to capture meaning and nuance. However, such comparisons are rarely made, as human performance on embedding tas...",
    "published": "Oct 11",
    "pdf_url": "https://arxiv.org/pdf/2510.10062v3",
    "arxiv_url": "http://arxiv.org/abs/2510.10062v3",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff"
    ]
  },
  {
    "title": "How can we assess human-agent interactions? Case studies in software agent design",
    "authors": [
      "Valerie Chen",
      "Rohit Malhotra",
      "Xingyao Wang",
      "Juan Michelini",
      "Xuhui Zhou",
      "Aditya Bharat Soni",
      "Hoang H. Tran",
      "Calvin Smith",
      "Ameet Talwalkar",
      "Graham Neubig"
    ],
    "summary": "LLM-powered agents are both a promising new technology and a source of complexity, where choices about models, tools, and prompting can affect their usefulness. While numerous benchmarks measure agent accuracy across domains, they mostly assume full automation, failing to represent the collaborative...",
    "published": "Oct 10",
    "pdf_url": "https://arxiv.org/pdf/2510.09801v2",
    "arxiv_url": "http://arxiv.org/abs/2510.09801v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Attention to Non-Adopters",
    "authors": [
      "Kaitlyn Zhou",
      "Kristina Gligori\u0107",
      "Myra Cheng",
      "Michelle S. Lam",
      "Vyoma Raman",
      "Boluwatife Aminu",
      "Caeley Woo",
      "Michael Brockman",
      "Hannah Cha",
      "Dan Jurafsky"
    ],
    "summary": "Although language model-based chat systems are increasingly used in daily life, most Americans remain non-adopters of chat-based LLMs -- as of June 2025, 66% had never used ChatGPT. At the same time, LLM development and evaluation rely mainly on data from adopters (e.g., logs, preference data), focu...",
    "published": "Oct 10",
    "pdf_url": "https://arxiv.org/pdf/2510.15951v1",
    "arxiv_url": "http://arxiv.org/abs/2510.15951v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Neologism Learning for Controllability and Self-Verbalization",
    "authors": [
      "John Hewitt",
      "Oyvind Tafjord",
      "Robert Geirhos",
      "Been Kim"
    ],
    "summary": "Humans invent new words when there is a rising demand for a new useful concept (e.g., doomscrolling). We explore and validate a similar idea in our communication with LLMs: introducing new words to better understand and control the models, expanding on the recently introduced neologism learning. Thi...",
    "published": "Oct 09",
    "pdf_url": "https://arxiv.org/pdf/2510.08506v1",
    "arxiv_url": "http://arxiv.org/abs/2510.08506v1",
    "queried_author": "John Hewitt",
    "matching_authors": [
      "John Hewitt"
    ]
  },
  {
    "title": "Base Models Know How to Reason, Thinking Models Learn When",
    "authors": [
      "Constantin Venhoff",
      "Iv\u00e1n Arcuschin",
      "Philip Torr",
      "Arthur Conmy",
      "Neel Nanda"
    ],
    "summary": "Why do thinking language models like DeepSeek R1 outperform their base counterparts? Despite consistent performance gains, it remains unclear to what extent thinking models learn entirely new reasoning capabilities or repurpose pre-existing base model ones. In this work, we propose a hybrid model wh...",
    "published": "Oct 08",
    "pdf_url": "https://arxiv.org/pdf/2510.07364v3",
    "arxiv_url": "http://arxiv.org/abs/2510.07364v3",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline",
    "authors": [
      "Rushi Qiang",
      "Yuchen Zhuang",
      "Anikait Singh",
      "Percy Liang",
      "Chao Zhang",
      "Sherry Yang",
      "Bo Dai"
    ],
    "summary": "While Language Models (LMs) have made significant progress in automating machine learning engineering (MLE), the acquisition of high-quality MLE training data is significantly constrained. Current MLE benchmarks suffer from low scalability and limited applicability because they rely on static, manua...",
    "published": "Oct 08",
    "pdf_url": "https://arxiv.org/pdf/2510.07307v1",
    "arxiv_url": "http://arxiv.org/abs/2510.07307v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning",
    "authors": [
      "Taylor Sorensen",
      "Yejin Choi"
    ],
    "summary": "Many natural language processing (NLP) tasks involve subjectivity, ambiguity, or legitimate disagreement between annotators. In this paper, we outline our system for modeling human variation. Our system leverages language models' (LLMs) in-context learning abilities, along with a two-step meta-learn...",
    "published": "Oct 08",
    "pdf_url": "https://arxiv.org/pdf/2510.07105v1",
    "arxiv_url": "http://arxiv.org/abs/2510.07105v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?",
    "authors": [
      "Aochong Oliver Li",
      "Tanya Goyal"
    ],
    "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding strong gains on complex tasks. This transparency also opens a promising direction: multiple reasoners can directly collaborate on each other's thinking within a shared trajectory, yielding better inference efficiency and explo...",
    "published": "Oct 07",
    "pdf_url": "https://arxiv.org/pdf/2510.06410v1",
    "arxiv_url": "http://arxiv.org/abs/2510.06410v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "EVALUESTEER: Measuring Reward Model Steerability Towards Values and Preferences",
    "authors": [
      "Kshitish Ghate",
      "Andy Liu",
      "Devansh Jain",
      "Taylor Sorensen",
      "Atoosa Kasirzadeh",
      "Aylin Caliskan",
      "Mona T. Diab",
      "Maarten Sap"
    ],
    "summary": "As large language models (LLMs) are deployed globally, creating pluralistic systems that can accommodate the diverse preferences and values of users worldwide becomes essential. We introduce EVALUESTEER, a benchmark to measure LLMs' and reward models' (RMs) steerability towards users' value and styl...",
    "published": "Oct 07",
    "pdf_url": "https://arxiv.org/pdf/2510.06370v2",
    "arxiv_url": "http://arxiv.org/abs/2510.06370v2",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Latent Speech-Text Transformer",
    "authors": [
      "Yen-Ju Lu",
      "Yashesh Gaur",
      "Wei Zhou",
      "Benjamin Muller",
      "Jesus Villalba",
      "Najim Dehak",
      "Luke Zettlemoyer",
      "Gargi Ghosh",
      "Mike Lewis",
      "Srinivasan Iyer",
      "Duc Le"
    ],
    "summary": "Auto-regressive speech-text models are typically pre-trained on a large number of interleaved sequences of text tokens and raw speech encoded as speech tokens using vector quantization. These models have demonstrated state-of-the-art performance in speech-to-speech understanding and generation bench...",
    "published": "Oct 07",
    "pdf_url": "https://arxiv.org/pdf/2510.06195v1",
    "arxiv_url": "http://arxiv.org/abs/2510.06195v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer",
      "Mike Lewis"
    ]
  },
  {
    "title": "Spectrum Tuning: Post-Training for Distributional Coverage and In-Context Steerability",
    "authors": [
      "Taylor Sorensen",
      "Benjamin Newman",
      "Jared Moore",
      "Chan Park",
      "Jillian Fisher",
      "Niloofar Mireshghallah",
      "Liwei Jiang",
      "Yejin Choi"
    ],
    "summary": "Language model post-training has enhanced instruction-following and performance on many downstream tasks, but also comes with an often-overlooked cost on tasks with many possible valid answers. We characterize three desiderata for conditional distributional modeling: in-context steerability, valid o...",
    "published": "Oct 07",
    "pdf_url": "https://arxiv.org/pdf/2510.06084v1",
    "arxiv_url": "http://arxiv.org/abs/2510.06084v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "In-the-Flow Agentic System Optimization for Effective Planning and Tool Use",
    "authors": [
      "Zhuofeng Li",
      "Haoxiang Zhang",
      "Seungju Han",
      "Sheng Liu",
      "Jianwen Xie",
      "Yu Zhang",
      "Yejin Choi",
      "James Zou",
      "Pan Lu"
    ],
    "summary": "Outcome-driven reinforcement learning has advanced reasoning in large language models (LLMs), but prevailing tool-augmented approaches train a single, monolithic policy that interleaves thoughts and tool calls under full context; this scales poorly with long horizons and diverse tools and generalize...",
    "published": "Oct 07",
    "pdf_url": "https://arxiv.org/pdf/2510.05592v1",
    "arxiv_url": "http://arxiv.org/abs/2510.05592v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Efficient Prediction of Pass@k Scaling in Large Language Models",
    "authors": [
      "Joshua Kazdan",
      "Rylan Schaeffer",
      "Youssef Allouah",
      "Colin Sullivan",
      "Kyssen Yu",
      "Noam Levi",
      "Sanmi Koyejo"
    ],
    "summary": "Assessing the capabilities and risks of frontier AI systems is a critical area of research, and recent work has shown that repeated sampling from models can dramatically increase both. For instance, repeated sampling has been shown to increase their capabilities, such as solving difficult math and c...",
    "published": "Oct 06",
    "pdf_url": "https://arxiv.org/pdf/2510.05197v1",
    "arxiv_url": "http://arxiv.org/abs/2510.05197v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Modeling Student Learning with 3.8 Million Program Traces",
    "authors": [
      "Alexis Ross",
      "Megha Srivastava",
      "Jeremiah Blanchard",
      "Jacob Andreas"
    ],
    "summary": "As programmers write code, they often edit and retry multiple times, creating rich \"interaction traces\" that reveal how they approach coding tasks and provide clues about their level of skill development. For novice programmers in particular, these traces reflect the diverse reasoning processes they...",
    "published": "Oct 06",
    "pdf_url": "https://arxiv.org/pdf/2510.05056v1",
    "arxiv_url": "http://arxiv.org/abs/2510.05056v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Agentic Misalignment: How LLMs Could Be Insider Threats",
    "authors": [
      "Aengus Lynch",
      "Benjamin Wright",
      "Caleb Larson",
      "Stuart J. Ritchie",
      "Soren Mindermann",
      "Evan Hubinger",
      "Ethan Perez",
      "Kevin Troy"
    ],
    "summary": "We stress-tested 16 leading models from multiple developers in hypothetical corporate environments to identify potentially risky agentic behaviors before they cause real harm. In the scenarios, we allowed models to autonomously send emails and access sensitive information. They were assigned only ha...",
    "published": "Oct 05",
    "pdf_url": "https://arxiv.org/pdf/2510.05179v2",
    "arxiv_url": "http://arxiv.org/abs/2510.05179v2",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez"
    ]
  },
  {
    "title": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning",
    "authors": [
      "Zhanke Zhou",
      "Chentao Cao",
      "Xiao Feng",
      "Xuan Li",
      "Zongze Li",
      "Xiangyu Lu",
      "Jiangchao Yao",
      "Weikai Huang",
      "Linrui Xu",
      "Tian Cheng",
      "Guanyu Jiang",
      "Yiming Zheng",
      "Brando Miranda",
      "Tongliang Liu",
      "Sanmi Koyejo",
      "Masashi Sugiyama",
      "Bo Han"
    ],
    "summary": "We present AlphaApollo, a self-evolving agentic reasoning system that aims to address two bottlenecks in foundation model (FM) reasoning-limited model-intrinsic capacity and unreliable test-time iteration. AlphaApollo orchestrates multiple models with professional tools to enable deliberate, verifia...",
    "published": "Oct 05",
    "pdf_url": "https://arxiv.org/pdf/2510.06261v1",
    "arxiv_url": "http://arxiv.org/abs/2510.06261v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Internal states before wait modulate reasoning patterns",
    "authors": [
      "Dmitrii Troitskii",
      "Koyena Pal",
      "Chris Wendler",
      "Callum Stuart McDougall",
      "Neel Nanda"
    ],
    "summary": "Prior work has shown that a significant driver of performance in reasoning models is their ability to reason and self-correct. A distinctive marker in these reasoning traces is the token wait, which often signals reasoning behavior such as backtracking. Despite being such a complex behavior, little ...",
    "published": "Oct 05",
    "pdf_url": "https://arxiv.org/pdf/2510.04128v1",
    "arxiv_url": "http://arxiv.org/abs/2510.04128v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows",
    "authors": [
      "John Nguyen",
      "Marton Havasi",
      "Tariq Berrada",
      "Luke Zettlemoyer",
      "Ricky T. Q. Chen"
    ],
    "summary": "We present OneFlow, the first non-autoregressive multimodal model that enables variable-length and concurrent mixed-modal generation. Unlike autoregressive models that enforce rigid causal ordering between text and image generation, OneFlow combines an insertion-based Edit Flow for discrete text tok...",
    "published": "Oct 03",
    "pdf_url": "https://arxiv.org/pdf/2510.03506v3",
    "arxiv_url": "http://arxiv.org/abs/2510.03506v3",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Know Thyself? On the Incapability and Implications of AI Self-Recognition",
    "authors": [
      "Xiaoyan Bai",
      "Aryan Shrivastava",
      "Ari Holtzman",
      "Chenhao Tan"
    ],
    "summary": "Self-recognition is a crucial metacognitive capability for AI systems, relevant not only for psychological analysis but also for safety, particularly in evaluative scenarios. Motivated by contradictory interpretations of whether models possess self-recognition (Panickssery et al., 2024; Davidson et ...",
    "published": "Oct 03",
    "pdf_url": "https://arxiv.org/pdf/2510.03399v1",
    "arxiv_url": "http://arxiv.org/abs/2510.03399v1",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "PRISM-Physics: Causal DAG-Based Process Evaluation for Physics Reasoning",
    "authors": [
      "Wanjia Zhao",
      "Qinwei Ma",
      "Jingzhe Shi",
      "Shirley Wu",
      "Jiaqi Han",
      "Yijia Xiao",
      "Si-Yuan Chen",
      "Xiao Luo",
      "Ludwig Schmidt",
      "James Zou"
    ],
    "summary": "Benchmarks for competition-style reasoning have advanced evaluation in mathematics and programming, yet physics remains comparatively explored. Most existing physics benchmarks evaluate only final answers, which fail to capture reasoning processes, while recent stepwise methods rely on heuristic LLM...",
    "published": "Oct 03",
    "pdf_url": "https://arxiv.org/pdf/2510.03185v2",
    "arxiv_url": "http://arxiv.org/abs/2510.03185v2",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Transcribe, Translate, or Transliterate: An Investigation of Intermediate Representations in Spoken Language Models",
    "authors": [
      "Tol\u00falop\u00e9 \u00d2g\u00fanr\u00e8m\u00ed",
      "Christopher D. Manning",
      "Dan Jurafsky",
      "Karen Livescu"
    ],
    "summary": "Spoken language models (SLMs) that integrate speech with large language models (LMs) rely on modality adapters (MAs) to map the output of speech encoders to a representation that is understandable to the decoder LM. Yet we know very little about how these crucial MAs transform representations. Here ...",
    "published": "Oct 02",
    "pdf_url": "https://arxiv.org/pdf/2510.02569v2",
    "arxiv_url": "http://arxiv.org/abs/2510.02569v2",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning",
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models",
    "authors": [
      "Alexa R. Tartaglini",
      "Satchel Grant",
      "Daniel Wurgaft",
      "Christopher Potts",
      "Judith E. Fan"
    ],
    "summary": "Data visualizations are vital components of many scientific articles and news stories. Current vision-language models (VLMs) still struggle on basic data visualization understanding tasks, but the causes of failure remain unclear. Are VLM failures attributable to limitations in how visual informatio...",
    "published": "Oct 02",
    "pdf_url": "https://arxiv.org/pdf/2510.21740v1",
    "arxiv_url": "http://arxiv.org/abs/2510.21740v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?",
    "authors": [
      "Hanqun Cao",
      "Hongrui Zhang",
      "Junde Xu",
      "Zhou Zhang",
      "Lingdong Shen",
      "Minghao Sun",
      "Ge Liu",
      "Jinbo Xu",
      "Wu-Jun Li",
      "Jinren Ni",
      "Cesar de la Fuente-Nunez",
      "Tianfan Fu",
      "Yejin Choi",
      "Pheng-Ann Heng",
      "Fang Wu"
    ],
    "summary": "Protein language models (PLMs) have advanced computational protein science through large-scale pretraining and scalable architectures. In parallel, reinforcement learning (RL) has broadened exploration and enabled precise multi-objective optimization in protein design. Yet whether RL can push PLMs b...",
    "published": "Oct 02",
    "pdf_url": "https://arxiv.org/pdf/2510.01571v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01571v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed",
    "authors": [
      "Isha Gupta",
      "Rylan Schaeffer",
      "Joshua Kazdan",
      "Ken Ziyu Liu",
      "Sanmi Koyejo"
    ],
    "summary": "The field of adversarial robustness has long established that adversarial examples can successfully transfer between image classifiers and that text jailbreaks can successfully transfer between language models (LMs). However, a pair of recent studies reported being unable to successfully transfer im...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01494v2",
    "arxiv_url": "http://arxiv.org/abs/2510.01494v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Sycophantic AI Decreases Prosocial Intentions and Promotes Dependence",
    "authors": [
      "Myra Cheng",
      "Cinoo Lee",
      "Pranav Khadpe",
      "Sunny Yu",
      "Dyllan Han",
      "Dan Jurafsky"
    ],
    "summary": "Both the general public and academic communities have raised concerns about sycophancy, the phenomenon of artificial intelligence (AI) excessively agreeing with or flattering users. Yet, beyond isolated media reports of severe consequences, like reinforcing delusions, little is known about the exten...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01395v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01395v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "BroRL: Scaling Reinforcement Learning via Broadened Exploration",
    "authors": [
      "Jian Hu",
      "Mingjie Liu",
      "Ximing Lu",
      "Fang Wu",
      "Zaid Harchaoui",
      "Shizhe Diao",
      "Yejin Choi",
      "Pavlo Molchanov",
      "Jun Yang",
      "Jan Kautz",
      "Yi Dong"
    ],
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key ingredient for unlocking complex reasoning capabilities in large language models. Recent work ProRL has shown promise in scaling RL by increasing the number of training steps. However, performance plateaus after thousands of ...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01180v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01180v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity",
    "authors": [
      "Jiayi Zhang",
      "Simon Yu",
      "Derek Chong",
      "Anthony Sicilia",
      "Michael R. Tomz",
      "Christopher D. Manning",
      "Weiyan Shi"
    ],
    "summary": "Post-training alignment often reduces LLM diversity, leading to a phenomenon known as mode collapse. Unlike prior work that attributes this effect to algorithmic limitations, we identify a fundamental, pervasive data-level driver: typicality bias in preference data, whereby annotators systematically...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01171v3",
    "arxiv_url": "http://arxiv.org/abs/2510.01171v3",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "Pay-Per-Search Models are Abstention Models",
    "authors": [
      "Mustafa Omer Gul",
      "Claire Cardie",
      "Tanya Goyal"
    ],
    "summary": "LLMs cannot reliably recognize their parametric knowledge boundaries and often hallucinate answers to outside-of-boundary questions. In contrast, humans recognize their limitations and can either seek external help for such questions or abstain. In this paper, we introduce MASH (Modeling Abstention ...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01152v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01152v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "Eliciting Secret Knowledge from Language Models",
    "authors": [
      "Bartosz Cywi\u0144ski",
      "Emil Ryd",
      "Rowan Wang",
      "Senthooran Rajamanoharan",
      "Neel Nanda",
      "Arthur Conmy",
      "Samuel Marks"
    ],
    "summary": "We study secret elicitation: discovering knowledge that an AI possesses but does not explicitly verbalize. As a testbed, we train three families of large language models (LLMs) to possess specific knowledge that they apply downstream but deny knowing when asked directly. For example, in one setting,...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01070v2",
    "arxiv_url": "http://arxiv.org/abs/2510.01070v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "GEM: A Gym for Agentic LLMs",
    "authors": [
      "Zichen Liu",
      "Anya Sims",
      "Keyu Duan",
      "Changyu Chen",
      "Simon Yu",
      "Xiangxin Zhou",
      "Haotian Xu",
      "Shaopan Xiong",
      "Bo Liu",
      "Chenmien Tan",
      "Chuen Yang Beh",
      "Weixun Wang",
      "Hao Zhu",
      "Weiyan Shi",
      "Diyi Yang",
      "Michael Shieh",
      "Yee Whye Teh",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "summary": "The training paradigm for large language models (LLMs) is moving from static datasets to experience-based learning, where agents acquire skills via interacting with complex environments. To facilitate this transition we introduce GEM (General Experience Maker), an open-source environment simulator d...",
    "published": "Oct 01",
    "pdf_url": "https://arxiv.org/pdf/2510.01051v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01051v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Thoughtbubbles: an Unsupervised Method for Parallel Thinking in Latent Space",
    "authors": [
      "Houjun Liu",
      "Shikhar Murty",
      "Christopher D. Manning",
      "R\u00f3bert Csord\u00e1s"
    ],
    "summary": "Current approaches for scaling inference-time compute in transformers rely on training them to emit explicit chain-of-thought tokens before producing an answer. While these methods are powerful, they are limited because they cannot be applied during pretraining and are limited to only serially-gener...",
    "published": "Sep 30",
    "pdf_url": "https://arxiv.org/pdf/2510.00219v1",
    "arxiv_url": "http://arxiv.org/abs/2510.00219v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It",
    "authors": [
      "Shuyue Stella Li",
      "Avinandan Bose",
      "Faeze Brahman",
      "Simon Shaolei Du",
      "Pang Wei Koh",
      "Maryam Fazel",
      "Yulia Tsvetkov"
    ],
    "summary": "Current large language model (LLM) development treats task-solving and preference alignment as separate challenges, optimizing first for objective correctness, then for alignment to aggregated human preferences. This paradigm fails in human-facing applications where solving a problem correctly is in...",
    "published": "Sep 30",
    "pdf_url": "https://arxiv.org/pdf/2510.00177v1",
    "arxiv_url": "http://arxiv.org/abs/2510.00177v1",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Auto-ARGUE: LLM-Based Report Generation Evaluation",
    "authors": [
      "William Walden",
      "Marc Mason",
      "Orion Weller",
      "Laura Dietz",
      "John Conroy",
      "Neil Molino",
      "Hannah Recknor",
      "Bryan Li",
      "Gabrielle Kaili-May Liu",
      "Yu Hou",
      "Dawn Lawrie",
      "James Mayfield",
      "Eugene Yang"
    ],
    "summary": "Generation of long-form, citation-backed reports is a primary use case for retrieval augmented generation (RAG) systems. While open-source evaluation tools exist for various RAG tasks, ones tailored to report generation (RG) are lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based imple...",
    "published": "Sep 30",
    "pdf_url": "https://arxiv.org/pdf/2509.26184v4",
    "arxiv_url": "http://arxiv.org/abs/2509.26184v4",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search",
    "authors": [
      "Fang Wu",
      "Weihao Xuan",
      "Heli Qi",
      "Ximing Lu",
      "Aaron Tu",
      "Li Erran Li",
      "Yejin Choi"
    ],
    "summary": "Although RLVR has become an essential component for developing advanced reasoning skills in LLMs, contemporary studies have documented training plateaus that emerge following thousands of optimization steps, demonstrating notable decreases in performance gains despite increased computational investm...",
    "published": "Sep 29",
    "pdf_url": "https://arxiv.org/pdf/2509.25454v2",
    "arxiv_url": "http://arxiv.org/abs/2509.25454v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Humanline: Online Alignment as Perceptual Loss",
    "authors": [
      "Sijia Liu",
      "Niklas Muennighoff",
      "Kawin Ethayarajh"
    ],
    "summary": "Online alignment (e.g., GRPO) is generally more performant than offline alignment (e.g., DPO) -- but why? Drawing on prospect theory from behavioral economics, we propose a human-centric explanation. We prove that online on-policy sampling better approximates the human-perceived distribution of what...",
    "published": "Sep 29",
    "pdf_url": "https://arxiv.org/pdf/2509.24207v1",
    "arxiv_url": "http://arxiv.org/abs/2509.24207v1",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff"
    ]
  },
  {
    "title": "Pretraining Scaling Laws for Generative Evaluations of Language Models",
    "authors": [
      "Rylan Schaeffer",
      "Noam Levi",
      "Brando Miranda",
      "Sanmi Koyejo"
    ],
    "summary": "Neural scaling laws have played a central role in modern machine learning, driving the field's ever-expanding scaling of parameters, data and compute. While much research has gone into fitting scaling laws and predicting performance on pretraining losses and on discriminative evaluations such as mul...",
    "published": "Sep 28",
    "pdf_url": "https://arxiv.org/pdf/2509.24012v1",
    "arxiv_url": "http://arxiv.org/abs/2509.24012v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Evaluating the Robustness of Chinchilla Compute-Optimal Scaling",
    "authors": [
      "Rylan Schaeffer",
      "Noam Levi",
      "Andreas Kirsch",
      "Theo Guenais",
      "Brando Miranda",
      "Elyas Obbad",
      "Sanmi Koyejo"
    ],
    "summary": "Hoffman et al (2022)'s Chinchilla paper introduced the principle of compute-optimal scaling, laying a foundation for future scaling of language models. In the years since, however, valid concerns about Chinchilla have been raised: wide confidence intervals, discrepancies between its three approaches...",
    "published": "Sep 28",
    "pdf_url": "https://arxiv.org/pdf/2509.23963v1",
    "arxiv_url": "http://arxiv.org/abs/2509.23963v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Mapping Overlaps in Benchmarks through Perplexity in the Wild",
    "authors": [
      "Siyang Wu",
      "Honglin Bao",
      "Sida Li",
      "Ari Holtzman",
      "James A. Evans"
    ],
    "summary": "We develop signatures of capacity familiarity to characterize large language model (LLM) benchmarks and their meaningful overlaps. Benchmark signatures probe the capacity required for benchmark performance. We formally define them as a set of salient tokens drawn from in-the-wild, naturally authored...",
    "published": "Sep 27",
    "pdf_url": "https://arxiv.org/pdf/2509.23488v3",
    "arxiv_url": "http://arxiv.org/abs/2509.23488v3",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "Multiplayer Nash Preference Optimization",
    "authors": [
      "Fang Wu",
      "Xu Huang",
      "Weihao Xuan",
      "Zhiwei Zhang",
      "Yijia Xiao",
      "Guancheng Wan",
      "Xiaomin Li",
      "Bing Hu",
      "Peng Xia",
      "Jure Leskovec",
      "Yejin Choi"
    ],
    "summary": "Reinforcement learning from human feedback (RLHF) has emerged as the standard paradigm for aligning large language models (LLMs) with human preferences. However, reward-based methods built on the Bradley-Terry assumption struggle to capture the non-transitive and heterogeneous nature of real-world p...",
    "published": "Sep 27",
    "pdf_url": "https://arxiv.org/pdf/2509.23102v1",
    "arxiv_url": "http://arxiv.org/abs/2509.23102v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data",
    "authors": [
      "Syeda Nahida Akter",
      "Shrimai Prabhumoye",
      "Eric Nyberg",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Yejin Choi",
      "Bryan Catanzaro"
    ],
    "summary": "The prevailing paradigm for enhancing the reasoning abilities of LLMs revolves around post-training on high-quality, reasoning-intensive data. While emerging literature suggests that reasoning data is increasingly incorporated also during the mid-training stage-a practice that is relatively more pro...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2510.03264v1",
    "arxiv_url": "http://arxiv.org/abs/2510.03264v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Adaptive Margin RLHF via Preference over Preferences",
    "authors": [
      "Yaswanth Chittepu",
      "Prasann Singhal",
      "Greg Durrett",
      "Scott Niekum"
    ],
    "summary": "Margin-based optimization is fundamental to improving generalization and robustness in classification tasks. In the context of reward model learning from preferences within Reinforcement Learning from Human Feedback (RLHF), existing methods typically rely on no margins, fixed margins, or margins tha...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2509.22851v3",
    "arxiv_url": "http://arxiv.org/abs/2509.22851v3",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs",
    "authors": [
      "Xingyu Fu",
      "Siyi Liu",
      "Yinuo Xu",
      "Pan Lu",
      "Guangqiuse Hu",
      "Tianbo Yang",
      "Taran Anantasagar",
      "Christopher Shen",
      "Yikai Mao",
      "Yuanzhe Liu",
      "Keyush Shah",
      "Chung Un Lee",
      "Yejin Choi",
      "James Zou",
      "Dan Roth",
      "Chris Callison-Burch"
    ],
    "summary": "Can humans identify AI-generated (fake) videos and provide grounded reasons? While video generation models have advanced rapidly, a critical dimension -- whether humans can detect deepfake traces within a generated video, i.e., spatiotemporal grounded visual artifacts that reveal a video as machine ...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2509.22646v2",
    "arxiv_url": "http://arxiv.org/abs/2509.22646v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "RLP: Reinforcement as a Pretraining Objective",
    "authors": [
      "Ali Hatamizadeh",
      "Syeda Nahida Akter",
      "Shrimai Prabhumoye",
      "Jan Kautz",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Yejin Choi"
    ],
    "summary": "The dominant paradigm for training large reasoning models starts with pre-training using next-token prediction loss on vast amounts of data. Reinforcement learning, while powerful in scaling reasoning, is introduced only as the very last phase of post-training, preceded by supervised fine-tuning. Wh...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2510.01265v1",
    "arxiv_url": "http://arxiv.org/abs/2510.01265v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers",
    "authors": [
      "Peter Shaw",
      "James Cohan",
      "Jacob Eisenstein",
      "Kristina Toutanova"
    ],
    "summary": "The Minimum Description Length (MDL) principle offers a formal framework for applying Occam's razor in machine learning. However, its application to neural networks such as Transformers is challenging due to the lack of a principled, universal measure for model complexity. This paper introduces the ...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2509.22445v2",
    "arxiv_url": "http://arxiv.org/abs/2509.22445v2",
    "queried_author": "Jacob Eisenstein",
    "matching_authors": [
      "Jacob Eisenstein"
    ]
  },
  {
    "title": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Aaron Tu",
      "Weihao Xuan",
      "Heli Qi",
      "Xu Huang",
      "Qingcheng Zeng",
      "Shayan Talaei",
      "Yijia Xiao",
      "Peng Xia",
      "Xiangru Tang",
      "Yuchen Zhuang",
      "Bing Hu",
      "Hanqun Cao",
      "Wenqi Shi",
      "Tianang Leng",
      "Rui Yang",
      "Yingjian Chen",
      "Ziqi Wang",
      "Irene Li",
      "Nan Liu",
      "Huaxiu Yao",
      "Li Erran Li",
      "Ge Liu",
      "Amin Saberi",
      "Naoto Yokoya",
      "Jure Leskovec",
      "Yejin Choi",
      "Fang Wu"
    ],
    "summary": "Reinforcement learning with verifiable rewards (RLVR) is a practical and scalable approach to enhancing large language models in areas such as math, code, and other structured tasks. Two questions motivate this paper: how much of the reported gains survive under strictly parity-controlled evaluation...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2509.21882v1",
    "arxiv_url": "http://arxiv.org/abs/2509.21882v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "A Unifying Framework for Parallelizing Sequential Models with Linear Dynamical Systems",
    "authors": [
      "Xavier Gonzalez",
      "E. Kelly Buchanan",
      "Hyun Dong Lee",
      "Jerry Weihong Liu",
      "Ke Alexander Wang",
      "David M. Zoltowski",
      "Christopher R\u00e9",
      "Scott W. Linderman"
    ],
    "summary": "Harnessing parallelism in seemingly sequential models is a central challenge for modern machine learning. Several approaches have been proposed for evaluating sequential processes in parallel using fixed-point methods, like Newton, Picard, and Jacobi iterations. In this work, we show that these meth...",
    "published": "Sep 26",
    "pdf_url": "https://arxiv.org/pdf/2509.21716v1",
    "arxiv_url": "http://arxiv.org/abs/2509.21716v1",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "DistillKac: Few-Step Image Generation via Damped Wave Equations",
    "authors": [
      "Weiqiao Han",
      "Chenlin Meng",
      "Christopher D. Manning",
      "Stefano Ermon"
    ],
    "summary": "We present DistillKac, a fast image generator that uses the damped wave equation and its stochastic Kac representation to move probability mass at finite speed. In contrast to diffusion models whose reverse time velocities can become stiff and implicitly allow unbounded propagation speed, Kac dynami...",
    "published": "Sep 25",
    "pdf_url": "https://arxiv.org/pdf/2509.21513v1",
    "arxiv_url": "http://arxiv.org/abs/2509.21513v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding",
    "authors": [
      "Abdul Waheed",
      "Zhen Wu",
      "Dareen Alharthi",
      "Seungone Kim",
      "Bhiksha Raj"
    ],
    "summary": "Precisely evaluating video understanding models remains challenging: commonly used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of human judgment, while obtaining such judgments through manual evaluation is costly. Recent work has explored using large language models (LLMs...",
    "published": "Sep 25",
    "pdf_url": "https://arxiv.org/pdf/2509.21451v1",
    "arxiv_url": "http://arxiv.org/abs/2509.21451v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "RL Grokking Recipe: How Does RL Unlock and Transfer New Algorithms in LLMs?",
    "authors": [
      "Yiyou Sun",
      "Yuhan Cao",
      "Pohao Huang",
      "Haoyue Bai",
      "Hannaneh Hajishirzi",
      "Nouha Dziri",
      "Dawn Song"
    ],
    "summary": "It remains an open question whether LLMs can acquire or generalize genuinely new reasoning strategies, beyond the sharpened skills encoded in their parameters during pre-training or post-training. To attempt to answer this debate, we introduce DELTA-Code -- Distributional Evaluation of Learnability ...",
    "published": "Sep 25",
    "pdf_url": "https://arxiv.org/pdf/2509.21016v2",
    "arxiv_url": "http://arxiv.org/abs/2509.21016v2",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Language Models that Think, Chat Better",
    "authors": [
      "Adithya Bhaskar",
      "Xi Ye",
      "Danqi Chen"
    ],
    "summary": "Reinforcement learning with verifiable rewards (RLVR) improves language model reasoning by using rule-based rewards in verifiable domains such as mathematics and code. However, RLVR leads to limited generalization for open-ended tasks -- such as writing outline essays or making meal plans -- where h...",
    "published": "Sep 24",
    "pdf_url": "https://arxiv.org/pdf/2509.20357v1",
    "arxiv_url": "http://arxiv.org/abs/2509.20357v1",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models",
    "authors": [
      "Julie Kallini",
      "Dan Jurafsky",
      "Christopher Potts",
      "Martijn Bartelds"
    ],
    "summary": "Subword tokenizers trained on multilingual corpora naturally produce overlapping tokens across languages. Does token overlap facilitate cross-lingual transfer or instead introduce interference between languages? Prior work offers mixed evidence, partly due to varied setups and confounders, such as t...",
    "published": "Sep 23",
    "pdf_url": "https://arxiv.org/pdf/2509.18750v2",
    "arxiv_url": "http://arxiv.org/abs/2509.18750v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts",
      "Dan Jurafsky"
    ]
  },
  {
    "title": "The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies",
    "authors": [
      "Jiaxu Zhou",
      "Jen-tse Huang",
      "Xuhui Zhou",
      "Man Ho Lam",
      "Xintao Wang",
      "Hao Zhu",
      "Wenxuan Wang",
      "Maarten Sap"
    ],
    "summary": "Large Language Models (LLMs) are increasingly used for social simulation, where populations of agents are expected to reproduce human-like collective behavior. However, we find that many recent studies adopt experimental designs that systematically undermine the validity of their claims. From a surv...",
    "published": "Sep 22",
    "pdf_url": "https://arxiv.org/pdf/2509.18052v1",
    "arxiv_url": "http://arxiv.org/abs/2509.18052v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models",
    "authors": [
      "Satyapriya Krishna",
      "Andy Zou",
      "Rahul Gupta",
      "Eliot Krzysztof Jones",
      "Nick Winter",
      "Dan Hendrycks",
      "J. Zico Kolter",
      "Matt Fredrikson",
      "Spyros Matsoukas"
    ],
    "summary": "The safety and alignment of Large Language Models (LLMs) are critical for their responsible deployment. Current evaluation methods predominantly focus on identifying and preventing overtly harmful outputs. However, they often fail to address a more insidious failure mode: models that produce benign-...",
    "published": "Sep 22",
    "pdf_url": "https://arxiv.org/pdf/2509.17938v1",
    "arxiv_url": "http://arxiv.org/abs/2509.17938v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology",
    "authors": [
      "Fagun Patel",
      "Duc Q. Nguyen",
      "Sang T. Truong",
      "Jody Vaynshtok",
      "Sanmi Koyejo",
      "Nick Haber"
    ],
    "summary": "According to the U.S. National Institutes of Health, more than 3.4 million children experience speech disorders that require clinical intervention. The number of speech-language pathologists (SLPs) is roughly 20 times fewer than the number of affected children, highlighting a significant gap in chil...",
    "published": "Sep 20",
    "pdf_url": "https://arxiv.org/pdf/2509.16765v2",
    "arxiv_url": "http://arxiv.org/abs/2509.16765v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior",
    "authors": [
      "Angelina Wang",
      "Daniel E. Ho",
      "Sanmi Koyejo"
    ],
    "summary": "Standard offline evaluations for language models -- a series of independent, state-less inferences made by models -- fail to capture how language models actually behave in practice, where personalization fundamentally alters model behavior. For instance, identical benchmark questions to the same lan...",
    "published": "Sep 18",
    "pdf_url": "https://arxiv.org/pdf/2509.19364v1",
    "arxiv_url": "http://arxiv.org/abs/2509.19364v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Pre-training under infinite compute",
    "authors": [
      "Konwoo Kim",
      "Suhas Kotha",
      "Percy Liang",
      "Tatsunori Hashimoto"
    ],
    "summary": "Since compute grows much faster than web text available for language model pre-training, we ask how one should approach pre-training under fixed data and no compute constraints. We first show that existing data-constrained approaches of increasing epoch count and parameter count eventually overfit, ...",
    "published": "Sep 18",
    "pdf_url": "https://arxiv.org/pdf/2509.14786v1",
    "arxiv_url": "http://arxiv.org/abs/2509.14786v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Value Alignment of Social Media Ranking Algorithms",
    "authors": [
      "Farnaz Jahanbakhsh",
      "Dora Zhao",
      "Tiziano Piccardi",
      "Zachary Robertson",
      "Ziv Epstein",
      "Sanmi Koyejo",
      "Michael S. Bernstein"
    ],
    "summary": "While social media feed rankings are primarily driven by engagement signals rather than any explicit value system, the resulting algorithmic feeds are not value-neutral: engagement may prioritize specific individualistic values. This paper presents an approach for social media feed value alignment. ...",
    "published": "Sep 17",
    "pdf_url": "https://arxiv.org/pdf/2509.14434v1",
    "arxiv_url": "http://arxiv.org/abs/2509.14434v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments",
    "authors": [
      "Project Apertus",
      "Alejandro Hern\u00e1ndez-Cano",
      "Alexander H\u00e4gele",
      "Allen Hao Huang",
      "Angelika Romanou",
      "Antoni-Joan Solergibert",
      "Barna Pasztor",
      "Bettina Messmer",
      "Dhia Garbaya",
      "Eduard Frank \u010eurech",
      "Ido Hakimi",
      "Juan Garc\u00eda Giraldo",
      "Mete Ismayilzada",
      "Negar Foroutan",
      "Skander Moalla",
      "Tiancheng Chen",
      "Vinko Sabol\u010dec",
      "Yixuan Xu",
      "Michael Aerni",
      "Badr AlKhamissi",
      "In\u00e9s Altemir Mari\u00f1as",
      "Mohammad Hossein Amani",
      "Matin Ansaripour",
      "Ilia Badanin",
      "Harold Benoit",
      "Emanuela Boros",
      "Nicholas Browning",
      "Fabian B\u00f6sch",
      "Maximilian B\u00f6ther",
      "Niklas Canova",
      "Camille Challier",
      "Clement Charmillot",
      "Jonathan Coles",
      "Jan Deriu",
      "Arnout Devos",
      "Lukas Drescher",
      "Daniil Dzenhaliou",
      "Maud Ehrmann",
      "Dongyang Fan",
      "Simin Fan",
      "Silin Gao",
      "Miguel Gila",
      "Mar\u00eda Grandury",
      "Diba Hashemi",
      "Alexander Hoyle",
      "Jiaming Jiang",
      "Mark Klein",
      "Andrei Kucharavy",
      "Anastasiia Kucherenko",
      "Frederike L\u00fcbeck",
      "Roman Machacek",
      "Theofilos Manitaras",
      "Andreas Marfurt",
      "Kyle Matoba",
      "Simon Matrenok",
      "Henrique Mendon\u00e7a",
      "Fawzi Roberto Mohamed",
      "Syrielle Montariol",
      "Luca Mouchel",
      "Sven Najem-Meyer",
      "Jingwei Ni",
      "Gennaro Oliva",
      "Matteo Pagliardini",
      "Elia Palme",
      "Andrei Panferov",
      "L\u00e9o Paoletti",
      "Marco Passerini",
      "Ivan Pavlov",
      "Auguste Poiroux",
      "Kaustubh Ponkshe",
      "Nathan Ranchin",
      "Javi Rando",
      "Mathieu Sauser",
      "Jakhongir Saydaliev",
      "Muhammad Ali Sayfiddinov",
      "Marian Schneider",
      "Stefano Schuppli",
      "Marco Scialanga",
      "Andrei Semenov",
      "Kumar Shridhar",
      "Raghav Singhal",
      "Anna Sotnikova",
      "Alexander Sternfeld",
      "Ayush Kumar Tarun",
      "Paul Teiletche",
      "Jannis Vamvas",
      "Xiaozhe Yao",
      "Hao Zhao",
      "Alexander Ilic",
      "Ana Klimovic",
      "Andreas Krause",
      "Caglar Gulcehre",
      "David Rosenthal",
      "Elliott Ash",
      "Florian Tram\u00e8r",
      "Joost VandeVondele",
      "Livio Veraldi",
      "Martin Rajman",
      "Thomas Schulthess",
      "Torsten Hoefler",
      "Antoine Bosselut",
      "Martin Jaggi",
      "Imanol Schlag"
    ],
    "summary": "We present Apertus, a fully open suite of large language models (LLMs) designed to address two systemic shortcomings in today's open model ecosystem: data compliance and multilingual representation. Unlike many prior models that release weights without reproducible data pipelines or regard for conte...",
    "published": "Sep 17",
    "pdf_url": "https://arxiv.org/pdf/2509.14233v2",
    "arxiv_url": "http://arxiv.org/abs/2509.14233v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "A deep reinforcement learning platform for antibiotic discovery",
    "authors": [
      "Hanqun Cao",
      "Marcelo D. T. Torres",
      "Jingjie Zhang",
      "Zijun Gao",
      "Fang Wu",
      "Chunbin Gu",
      "Jure Leskovec",
      "Yejin Choi",
      "Cesar de la Fuente-Nunez",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ],
    "summary": "Antimicrobial resistance (AMR) is projected to cause up to 10 million deaths annually by 2050, underscoring the urgent need for new antibiotics. Here we present ApexAmphion, a deep-learning framework for de novo design of antibiotics that couples a 6.4-billion-parameter protein language model with r...",
    "published": "Sep 16",
    "pdf_url": "https://arxiv.org/pdf/2509.18153v1",
    "arxiv_url": "http://arxiv.org/abs/2509.18153v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Fluid Language Model Benchmarking",
    "authors": [
      "Valentin Hofmann",
      "David Heineman",
      "Ian Magnusson",
      "Kyle Lo",
      "Jesse Dodge",
      "Maarten Sap",
      "Pang Wei Koh",
      "Chun Wang",
      "Hannaneh Hajishirzi",
      "Noah A. Smith"
    ],
    "summary": "Language model (LM) benchmarking faces several challenges: comprehensive evaluations are costly, benchmarks often fail to measure the intended capabilities, and evaluation quality can degrade due to labeling errors and benchmark saturation. Although various strategies have been proposed to mitigate ...",
    "published": "Sep 14",
    "pdf_url": "https://arxiv.org/pdf/2509.11106v1",
    "arxiv_url": "http://arxiv.org/abs/2509.11106v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Ian Magnusson",
      "Jesse Dodge",
      "Kyle Lo",
      "Maarten Sap",
      "Noah A. Smith",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness",
    "authors": [
      "Anand Swaroop",
      "Akshat Nallani",
      "Saksham Uboweja",
      "Adiliia Uzdenova",
      "Michael Nguyen",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma",
      "Maheep Chaudhary"
    ],
    "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving large language model performance on complex tasks, but recent work shows that reasoning steps often fail to causally influence the final answer, creating brittle and untrustworthy outputs. Prior approaches focus primarily ...",
    "published": "Sep 10",
    "pdf_url": "https://arxiv.org/pdf/2509.13334v1",
    "arxiv_url": "http://arxiv.org/abs/2509.13334v1",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization",
    "authors": [
      "Nathan Egbuna",
      "Saatvik Gaur",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Maheep Chaudhary"
    ],
    "summary": "Test-time optimization remains impractical at scale due to prohibitive inference costs--techniques like iterative refinement and multi-step verification can require $10-100\\times$ more compute per query than standard decoding. Latent space test-time optimization methods like LatentSeek offer a more ...",
    "published": "Sep 10",
    "pdf_url": "https://arxiv.org/pdf/2509.18116v2",
    "arxiv_url": "http://arxiv.org/abs/2509.18116v2",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models",
    "authors": [
      "Maheep Chaudhary",
      "Ian Su",
      "Nikhil Hooda",
      "Nishith Shankar",
      "Julia Tan",
      "Kevin Zhu",
      "Ryan Lagasse",
      "Vasu Sharma",
      "Ashwinee Panda"
    ],
    "summary": "Large language models (LLMs) can internally distinguish between evaluation and deployment contexts, a behaviour known as \\emph{evaluation awareness}. This undermines AI safety evaluations, as models may conceal dangerous capabilities during testing. Prior work demonstrated this in a single $70$B mod...",
    "published": "Sep 10",
    "pdf_url": "https://arxiv.org/pdf/2509.13333v2",
    "arxiv_url": "http://arxiv.org/abs/2509.13333v2",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Reconstruction Alignment Improves Unified Multimodal Models",
    "authors": [
      "Ji Xie",
      "Trevor Darrell",
      "Luke Zettlemoyer",
      "XuDong Wang"
    ],
    "summary": "Unified multimodal models (UMMs) unify visual understanding and generation within a single architecture. However, conventional training relies on image-text pairs (or sequences) whose captions are typically sparse and miss fine-grained visual details--even when they use hundreds of words to describe...",
    "published": "Sep 08",
    "pdf_url": "https://arxiv.org/pdf/2509.07295v3",
    "arxiv_url": "http://arxiv.org/abs/2509.07295v3",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties",
    "authors": [
      "William Chen",
      "Chutong Meng",
      "Jiatong Shi",
      "Martijn Bartelds",
      "Shih-Heng Wang",
      "Hsiu-Hsuan Wang",
      "Rafael Mosquera",
      "Sara Hincapie",
      "Dan Jurafsky",
      "Antonis Anastasopoulos",
      "Hung-yi Lee",
      "Karen Livescu",
      "Shinji Watanabe"
    ],
    "summary": "Recent improvements in multilingual ASR have not been equally distributed across languages and language varieties. To advance state-of-the-art (SOTA) ASR models, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a new test suite that consists of data from 200+ languages, accents,...",
    "published": "Sep 08",
    "pdf_url": "https://arxiv.org/pdf/2509.07139v1",
    "arxiv_url": "http://arxiv.org/abs/2509.07139v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "mmBERT: A Modern Multilingual Encoder with Annealed Language Learning",
    "authors": [
      "Marc Marone",
      "Orion Weller",
      "William Fleshman",
      "Eugene Yang",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "summary": "Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only langu...",
    "published": "Sep 08",
    "pdf_url": "https://arxiv.org/pdf/2509.06888v1",
    "arxiv_url": "http://arxiv.org/abs/2509.06888v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "Audits Under Resource, Data, and Access Constraints: Scaling Laws For Less Discriminatory Alternatives",
    "authors": [
      "Sarah H. Cen",
      "Salil Goyal",
      "Zaynah Javed",
      "Ananya Karthik",
      "Percy Liang",
      "Daniel E. Ho"
    ],
    "summary": "AI audits play a critical role in AI accountability and safety. One branch of the law for which AI audits are particularly salient is anti-discrimination law. Several areas of anti-discrimination law implicate the \"less discriminatory alternative\" (LDA) requirement, in which a protocol (e.g., model)...",
    "published": "Sep 06",
    "pdf_url": "https://arxiv.org/pdf/2509.05627v1",
    "arxiv_url": "http://arxiv.org/abs/2509.05627v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Ad hoc conventions generalize to new referents",
    "authors": [
      "Anya Ji",
      "Claire Augusta Bergey",
      "Ron Eliav",
      "Yoav Artzi",
      "Robert D. Hawkins"
    ],
    "summary": "How do people talk about things they've never talked about before? One view suggests that a new shared naming system establishes an arbitrary link to a specific target, like proper names that cannot extend beyond their bearers. An alternative view proposes that forming a shared way of describing obj...",
    "published": "Sep 06",
    "pdf_url": "https://arxiv.org/pdf/2509.05566v1",
    "arxiv_url": "http://arxiv.org/abs/2509.05566v1",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining",
    "authors": [
      "Deniz Bayazit",
      "Aaron Mueller",
      "Antoine Bosselut"
    ],
    "summary": "Large language models (LLMs) learn non-trivial abstractions during pretraining, like detecting irregular plural noun subjects. However, it is not well understood when and how specific linguistic abilities emerge as traditional evaluation methods such as benchmarking fail to reveal how models acquire...",
    "published": "Sep 05",
    "pdf_url": "https://arxiv.org/pdf/2509.05291v1",
    "arxiv_url": "http://arxiv.org/abs/2509.05291v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "DynaGuard: A Dynamic Guardian Model With User-Defined Policies",
    "authors": [
      "Monte Hoover",
      "Vatsal Baherwani",
      "Neel Jain",
      "Khalid Saifullah",
      "Joseph Vincent",
      "Chirag Jain",
      "Melissa Kazemi Rad",
      "C. Bayan Bruss",
      "Ashwinee Panda",
      "Tom Goldstein"
    ],
    "summary": "Guardian models play a crucial role in ensuring the safety and ethical behavior of user-facing AI applications by enforcing guardrails and detecting harmful content. While standard guardian models are limited to predefined, static harm categories, we introduce DynaGuard, a suite of dynamic guardian ...",
    "published": "Sep 02",
    "pdf_url": "https://arxiv.org/pdf/2509.02563v3",
    "arxiv_url": "http://arxiv.org/abs/2509.02563v3",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "SpecEval: Evaluating Model Adherence to Behavior Specifications",
    "authors": [
      "Ahmed Ahmed",
      "Kevin Klyman",
      "Yi Zeng",
      "Sanmi Koyejo",
      "Percy Liang"
    ],
    "summary": "Companies that develop foundation models publish behavioral guidelines they pledge their models will follow, but it remains unclear if models actually do so. While providers such as OpenAI, Anthropic, and Google have published detailed specifications describing both desired safety constraints and qu...",
    "published": "Sep 02",
    "pdf_url": "https://arxiv.org/pdf/2509.02464v2",
    "arxiv_url": "http://arxiv.org/abs/2509.02464v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang",
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Fantastic Pretraining Optimizers and Where to Find Them",
    "authors": [
      "Kaiyue Wen",
      "David Hall",
      "Tengyu Ma",
      "Percy Liang"
    ],
    "summary": "AdamW has long been the dominant optimizer in language model pretraining, despite numerous claims that alternative optimizers offer 1.4 to 2x speedup. We posit that two methodological shortcomings have obscured fair comparisons and hindered practical adoption: (i) unequal hyperparameter tuning and (...",
    "published": "Sep 02",
    "pdf_url": "https://arxiv.org/pdf/2509.02046v2",
    "arxiv_url": "http://arxiv.org/abs/2509.02046v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Reinforcement Learning for Machine Learning Engineering Agents",
    "authors": [
      "Sherry Yang",
      "Joy He-Yueya",
      "Percy Liang"
    ],
    "summary": "Existing agents for solving tasks such as ML engineering rely on prompting powerful language models. As a result, these agents do not improve with more experience. In this paper, we show that agents backed by weaker models that improve via reinforcement learning (RL) can outperform agents backed by ...",
    "published": "Sep 01",
    "pdf_url": "https://arxiv.org/pdf/2509.01684v1",
    "arxiv_url": "http://arxiv.org/abs/2509.01684v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Statutory Construction and Interpretation for Artificial Intelligence",
    "authors": [
      "Luxi He",
      "Nimra Nadeem",
      "Michel Liao",
      "Howard Chen",
      "Danqi Chen",
      "Mariano-Florentino Cu\u00e9llar",
      "Peter Henderson"
    ],
    "summary": "AI systems are increasingly governed by natural language principles, yet a key challenge arising from reliance on language remains underexplored: interpretive ambiguity. As in legal systems, ambiguity arises both from how these principles are written and how they are applied. But while legal systems...",
    "published": "Sep 01",
    "pdf_url": "https://arxiv.org/pdf/2509.01186v1",
    "arxiv_url": "http://arxiv.org/abs/2509.01186v1",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "Social World Models",
    "authors": [
      "Xuhui Zhou",
      "Jiarui Liu",
      "Akhila Yerukola",
      "Hyunwoo Kim",
      "Maarten Sap"
    ],
    "summary": "Humans intuitively navigate social interactions by simulating unspoken dynamics and reasoning about others' perspectives, even with limited information. In contrast, AI systems struggle to automatically structure and reason about these implicit social contexts. In this paper, we introduce a novel st...",
    "published": "Aug 30",
    "pdf_url": "https://arxiv.org/pdf/2509.00559v1",
    "arxiv_url": "http://arxiv.org/abs/2509.00559v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "AHELM: A Holistic Evaluation of Audio-Language Models",
    "authors": [
      "Tony Lee",
      "Haoqin Tu",
      "Chi Heem Wong",
      "Zijun Wang",
      "Siwei Yang",
      "Yifan Mai",
      "Yuyin Zhou",
      "Cihang Xie",
      "Percy Liang"
    ],
    "summary": "Evaluations of audio-language models (ALMs) -- multimodal models that take interleaved audio and text as input and output text -- are hindered by the lack of standardized benchmarks; most benchmarks measure only one or two capabilities and omit evaluative aspects such as fairness or safety. Furtherm...",
    "published": "Aug 29",
    "pdf_url": "https://arxiv.org/pdf/2508.21376v2",
    "arxiv_url": "http://arxiv.org/abs/2508.21376v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "RelP: Faithful and Efficient Circuit Discovery in Language Models via Relevance Patching",
    "authors": [
      "Farnoush Rezaei Jafari",
      "Oliver Eberle",
      "Ashkan Khakzar",
      "Neel Nanda"
    ],
    "summary": "Activation patching is a standard method in mechanistic interpretability for localizing the components of a model responsible for specific behaviors, but it is computationally expensive to apply at scale. Attribution patching offers a faster, gradient-based approximation, yet suffers from noise and ...",
    "published": "Aug 28",
    "pdf_url": "https://arxiv.org/pdf/2508.21258v2",
    "arxiv_url": "http://arxiv.org/abs/2508.21258v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
    "authors": [
      "Orion Weller",
      "Michael Boratko",
      "Iftekhar Naim",
      "Jinhyuk Lee"
    ],
    "summary": "Vector embeddings have been tasked with an ever-increasing set of retrieval tasks over the years, with a nascent rise in using them for reasoning, instruction-following, coding, and more. These new benchmarks push embeddings to work for any query and any notion of relevance that could be given. Whil...",
    "published": "Aug 28",
    "pdf_url": "https://arxiv.org/pdf/2508.21038v1",
    "arxiv_url": "http://arxiv.org/abs/2508.21038v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "OLMoASR: Open Models and Data for Training Robust Speech Recognition Models",
    "authors": [
      "Huong Ngo",
      "Matt Deitke",
      "Martijn Bartelds",
      "Sarah Pratt",
      "Josh Gardner",
      "Matt Jordan",
      "Ludwig Schmidt"
    ],
    "summary": "Improvements in training data scale and quality have led to significant advances, yet its influence in speech recognition remains underexplored. In this paper, we present a large-scale dataset, OLMoASR-Pool, and series of models, OLMoASR, to study and develop robust zero-shot speech recognition mode...",
    "published": "Aug 28",
    "pdf_url": "https://arxiv.org/pdf/2508.20869v1",
    "arxiv_url": "http://arxiv.org/abs/2508.20869v1",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Evaluating Language Model Reasoning about Confidential Information",
    "authors": [
      "Dylan Sam",
      "Alexander Robey",
      "Andy Zou",
      "Matt Fredrikson",
      "J. Zico Kolter"
    ],
    "summary": "As language models are increasingly deployed as autonomous agents in high-stakes settings, ensuring that they reliably follow user-defined rules has become a critical safety concern. To this end, we study whether language models exhibit contextual robustness, or the capability to adhere to context-d...",
    "published": "Aug 27",
    "pdf_url": "https://arxiv.org/pdf/2508.19980v1",
    "arxiv_url": "http://arxiv.org/abs/2508.19980v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Language and Experience: A Computational Model of Social Learning in Complex Tasks",
    "authors": [
      "C\u00e9dric Colas",
      "Tracey Mills",
      "Ben Prystawski",
      "Michael Henry Tessler",
      "Noah Goodman",
      "Jacob Andreas",
      "Joshua Tenenbaum"
    ],
    "summary": "The ability to combine linguistic guidance from others with direct experience is central to human development, enabling safe and rapid learning in new environments. How do people integrate these two sources of knowledge, and how might AI systems? We present a computational framework that models soci...",
    "published": "Aug 26",
    "pdf_url": "https://arxiv.org/pdf/2509.00074v1",
    "arxiv_url": "http://arxiv.org/abs/2509.00074v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas",
      "Noah Goodman"
    ]
  },
  {
    "title": "Generative Interfaces for Language Models",
    "authors": [
      "Jiaqi Chen",
      "Yanzhe Zhang",
      "Yutong Zhang",
      "Yijia Shao",
      "Diyi Yang"
    ],
    "summary": "Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn,...",
    "published": "Aug 26",
    "pdf_url": "https://arxiv.org/pdf/2508.19227v2",
    "arxiv_url": "http://arxiv.org/abs/2508.19227v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Real-Time Detection of Hallucinated Entities in Long-Form Generation",
    "authors": [
      "Oscar Obeso",
      "Andy Arditi",
      "Javier Ferrando",
      "Joshua Freeman",
      "Cameron Holmes",
      "Neel Nanda"
    ],
    "summary": "Large language models are now routinely used in high-stakes applications where hallucinations can cause serious harm, such as medical consultations or legal advice. Existing hallucination detection methods, however, are impractical for real-world use, as they are either limited to short factual quer...",
    "published": "Aug 26",
    "pdf_url": "https://arxiv.org/pdf/2509.03531v1",
    "arxiv_url": "http://arxiv.org/abs/2509.03531v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "UQ: Assessing Language Models on Unsolved Questions",
    "authors": [
      "Fan Nie",
      "Ken Ziyu Liu",
      "Zihao Wang",
      "Rui Sun",
      "Wei Liu",
      "Weijia Shi",
      "Huaxiu Yao",
      "Linjun Zhang",
      "Andrew Y. Ng",
      "James Zou",
      "Sanmi Koyejo",
      "Yejin Choi",
      "Percy Liang",
      "Niklas Muennighoff"
    ],
    "summary": "Benchmarks shape progress in AI research. A useful benchmark should be both difficult and realistic: questions should challenge frontier models while also reflecting real-world usage. Yet, current paradigms face a difficulty-realism tension: exam-style benchmarks are often made artificially difficul...",
    "published": "Aug 25",
    "pdf_url": "https://arxiv.org/pdf/2508.17580v1",
    "arxiv_url": "http://arxiv.org/abs/2508.17580v1",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff",
      "Percy Liang",
      "Sanmi Koyejo",
      "Yejin Choi"
    ]
  },
  {
    "title": "Towards Safeguarding LLM Fine-tuning APIs against Cipher Attacks",
    "authors": [
      "Jack Youstra",
      "Mohammed Mahfoud",
      "Yang Yan",
      "Henry Sleight",
      "Ethan Perez",
      "Mrinank Sharma"
    ],
    "summary": "Large language model fine-tuning APIs enable widespread model customization, yet pose significant safety risks. Recent work shows that adversaries can exploit access to these APIs to bypass model safety mechanisms by encoding harmful content in seemingly harmless fine-tuning data, evading both human...",
    "published": "Aug 23",
    "pdf_url": "https://arxiv.org/pdf/2508.17158v1",
    "arxiv_url": "http://arxiv.org/abs/2508.17158v1",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez"
    ]
  },
  {
    "title": "Zero-shot Multimodal Document Retrieval via Cross-modal Question Generation",
    "authors": [
      "Yejin Choi",
      "Jaewoo Park",
      "Janghan Yoon",
      "Saejin Kim",
      "Jaehyun Jeon",
      "Youngjae Yu"
    ],
    "summary": "Rapid advances in Multimodal Large Language Models (MLLMs) have expanded information retrieval beyond purely textual inputs, enabling retrieval from complex real world documents that combine text and visuals. However, most documents are private either owned by individuals or confined within corporat...",
    "published": "Aug 23",
    "pdf_url": "https://arxiv.org/pdf/2508.17079v1",
    "arxiv_url": "http://arxiv.org/abs/2508.17079v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model",
    "authors": [
      "NVIDIA",
      ":",
      "Aarti Basant",
      "Abhijit Khairnar",
      "Abhijit Paithankar",
      "Abhinav Khattar",
      "Adithya Renduchintala",
      "Aditya Malte",
      "Akhiad Bercovich",
      "Akshay Hazare",
      "Alejandra Rico",
      "Aleksander Ficek",
      "Alex Kondratenko",
      "Alex Shaposhnikov",
      "Alexander Bukharin",
      "Ali Taghibakhshi",
      "Amelia Barton",
      "Ameya Sunil Mahabaleshwarkar",
      "Amy Shen",
      "Andrew Tao",
      "Ann Guan",
      "Anna Shors",
      "Anubhav Mandarwal",
      "Arham Mehta",
      "Arun Venkatesan",
      "Ashton Sharabiani",
      "Ashwath Aithal",
      "Ashwin Poojary",
      "Ayush Dattagupta",
      "Balaram Buddharaju",
      "Banghua Zhu",
      "Barnaby Simkin",
      "Bilal Kartal",
      "Bita Darvish Rouhani",
      "Bobby Chen",
      "Boris Ginsburg",
      "Brandon Norick",
      "Brian Yu",
      "Bryan Catanzaro",
      "Charles Wang",
      "Charlie Truong",
      "Chetan Mungekar",
      "Chintan Patel",
      "Chris Alexiuk",
      "Christian Munley",
      "Christopher Parisien",
      "Dan Su",
      "Daniel Afrimi",
      "Daniel Korzekwa",
      "Daniel Rohrer",
      "Daria Gitman",
      "David Mosallanezhad",
      "Deepak Narayanan",
      "Dima Rekesh",
      "Dina Yared",
      "Dmytro Pykhtar",
      "Dong Ahn",
      "Duncan Riach",
      "Eileen Long",
      "Elliott Ning",
      "Eric Chung",
      "Erick Galinkin",
      "Evelina Bakhturina",
      "Gargi Prasad",
      "Gerald Shen",
      "Haifeng Qian",
      "Haim Elisha",
      "Harsh Sharma",
      "Hayley Ross",
      "Helen Ngo",
      "Herman Sahota",
      "Hexin Wang",
      "Hoo Chang Shin",
      "Hua Huang",
      "Iain Cunningham",
      "Igor Gitman",
      "Ivan Moshkov",
      "Jaehun Jung",
      "Jan Kautz",
      "Jane Polak Scowcroft",
      "Jared Casper",
      "Jian Zhang",
      "Jiaqi Zeng",
      "Jimmy Zhang",
      "Jinze Xue",
      "Jocelyn Huang",
      "Joey Conway",
      "John Kamalu",
      "Jonathan Cohen",
      "Joseph Jennings",
      "Julien Veron Vialard",
      "Junkeun Yi",
      "Jupinder Parmar",
      "Kari Briski",
      "Katherine Cheung",
      "Katherine Luna",
      "Keith Wyss",
      "Keshav Santhanam",
      "Kezhi Kong",
      "Krzysztof Pawelec",
      "Kumar Anik",
      "Kunlun Li",
      "Kushan Ahmadian",
      "Lawrence McAfee",
      "Laya Sleiman",
      "Leon Derczynski",
      "Luis Vega",
      "Maer Rodrigues de Melo",
      "Makesh Narsimhan Sreedhar",
      "Marcin Chochowski",
      "Mark Cai",
      "Markus Kliegl",
      "Marta Stepniewska-Dziubinska",
      "Matvei Novikov",
      "Mehrzad Samadi",
      "Meredith Price",
      "Meriem Boubdir",
      "Michael Boone",
      "Michael Evans",
      "Michal Bien",
      "Michal Zawalski",
      "Miguel Martinez",
      "Mike Chrzanowski",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Namit Dhameja",
      "Nave Assaf",
      "Negar Habibi",
      "Nidhi Bhatia",
      "Nikki Pope",
      "Nima Tajbakhsh",
      "Nirmal Kumar Juluru",
      "Oleg Rybakov",
      "Oleksii Hrinchuk",
      "Oleksii Kuchaiev",
      "Oluwatobi Olabiyi",
      "Pablo Ribalta",
      "Padmavathy Subramanian",
      "Parth Chadha",
      "Pavlo Molchanov",
      "Peter Dykas",
      "Peter Jin",
      "Piotr Bialecki",
      "Piotr Januszewski",
      "Pradeep Thalasta",
      "Prashant Gaikwad",
      "Prasoon Varshney",
      "Pritam Gundecha",
      "Przemek Tredak",
      "Rabeeh Karimi Mahabadi",
      "Rajen Patel",
      "Ran El-Yaniv",
      "Ranjit Rajan",
      "Ria Cheruvu",
      "Rima Shahbazyan",
      "Ritika Borkar",
      "Ritu Gala",
      "Roger Waleffe",
      "Ruoxi Zhang",
      "Russell J. Hewett",
      "Ryan Prenger",
      "Sahil Jain",
      "Samuel Kriman",
      "Sanjeev Satheesh",
      "Saori Kaji",
      "Sarah Yurick",
      "Saurav Muralidharan",
      "Sean Narenthiran",
      "Seonmyeong Bak",
      "Sepehr Sameni",
      "Seungju Han",
      "Shanmugam Ramasamy",
      "Shaona Ghosh",
      "Sharath Turuvekere Sreenivas",
      "Shelby Thomas",
      "Shizhe Diao",
      "Shreya Gopal",
      "Shrimai Prabhumoye",
      "Shubham Toshniwal",
      "Shuoyang Ding",
      "Siddharth Singh",
      "Siddhartha Jain",
      "Somshubra Majumdar",
      "Soumye Singhal",
      "Stefania Alborghetti",
      "Syeda Nahida Akter",
      "Terry Kong",
      "Tim Moon",
      "Tomasz Hliwiak",
      "Tomer Asida",
      "Tony Wang",
      "Tugrul Konuk",
      "Twinkle Vashishth",
      "Tyler Poon",
      "Udi Karpas",
      "Vahid Noroozi",
      "Venkat Srinivasan",
      "Vijay Korthikanti",
      "Vikram Fugro",
      "Vineeth Kalluru",
      "Vitaly Kurin",
      "Vitaly Lavrukhin",
      "Wasi Uddin Ahmad",
      "Wei Du",
      "Wonmin Byeon",
      "Ximing Lu",
      "Xin Dong",
      "Yashaswi Karnati",
      "Yejin Choi",
      "Yian Zhang",
      "Ying Lin",
      "Yonggan Fu",
      "Yoshi Suhara",
      "Zhen Dong",
      "Zhiyu Li",
      "Zhongbo Zhu",
      "Zijia Chen"
    ],
    "summary": "We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer language model designed to increase throughput for reasoning workloads while achieving state-of-the-art accuracy compared to similarly-sized models. Nemotron-Nano-9B-v2 builds on the Nemotron-H architecture, in which the majority of the se...",
    "published": "Aug 20",
    "pdf_url": "https://arxiv.org/pdf/2508.14444v4",
    "arxiv_url": "http://arxiv.org/abs/2508.14444v4",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation",
    "authors": [
      "David Heineman",
      "Valentin Hofmann",
      "Ian Magnusson",
      "Yuling Gu",
      "Noah A. Smith",
      "Hannaneh Hajishirzi",
      "Kyle Lo",
      "Jesse Dodge"
    ],
    "summary": "Developing large language models is expensive and involves making decisions with small experiments, typically by evaluating on large, multi-task evaluation suites. In this work, we analyze specific properties which make a benchmark more reliable for such decisions, and interventions to design higher...",
    "published": "Aug 18",
    "pdf_url": "https://arxiv.org/pdf/2508.13144v1",
    "arxiv_url": "http://arxiv.org/abs/2508.13144v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Ian Magnusson",
      "Jesse Dodge",
      "Kyle Lo",
      "Noah A. Smith"
    ]
  },
  {
    "title": "OptimalThinkingBench: Evaluating Over and Underthinking in LLMs",
    "authors": [
      "Pranjal Aggarwal",
      "Seungone Kim",
      "Jack Lanchantin",
      "Sean Welleck",
      "Jason Weston",
      "Ilia Kulikov",
      "Swarnadeep Saha"
    ],
    "summary": "Thinking LLMs solve complex tasks at the expense of increased compute and overthinking on simpler problems, while non-thinking LLMs are faster and cheaper but underthink on harder reasoning problems. This has led to the development of separate thinking and non-thinking LLM variants, leaving the onus...",
    "published": "Aug 18",
    "pdf_url": "https://arxiv.org/pdf/2508.13141v2",
    "arxiv_url": "http://arxiv.org/abs/2508.13141v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck",
      "Seungone Kim"
    ]
  },
  {
    "title": "AI Behavioral Science",
    "authors": [
      "Matthew O. Jackson",
      "Qiaozhu Me",
      "Stephanie W. Wang",
      "Yutong Xie",
      "Walter Yuan",
      "Seth Benzell",
      "Erik Brynjolfsson",
      "Colin F. Camerer",
      "James Evans",
      "Brian Jabarian",
      "Jon Kleinberg",
      "Juanjuan Meng",
      "Sendhil Mullainathan",
      "Asuman Ozdaglar",
      "Thomas Pfeiffer",
      "Moshe Tennenholtz",
      "Robb Willer",
      "Diyi Yang",
      "Teng Ye"
    ],
    "summary": "We discuss the three main areas comprising the new and emerging field of \"AI Behavioral Science\". This includes not only how AI can enhance research in the behavioral sciences, but also how the behavioral sciences can be used to study and better design AI and to understand how the world will change ...",
    "published": "Aug 17",
    "pdf_url": "https://arxiv.org/pdf/2509.13323v1",
    "arxiv_url": "http://arxiv.org/abs/2509.13323v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Searching for Privacy Risks in LLM Agents via Simulation",
    "authors": [
      "Yanzhe Zhang",
      "Diyi Yang"
    ],
    "summary": "The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. However, the evolving nature of such dynamic dialogues makes it challenging to anticipate emerg...",
    "published": "Aug 14",
    "pdf_url": "https://arxiv.org/pdf/2508.10880v2",
    "arxiv_url": "http://arxiv.org/abs/2508.10880v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage",
    "authors": [
      "Skyler Hallinan",
      "Jaehun Jung",
      "Melanie Sclar",
      "Ximing Lu",
      "Abhilasha Ravichander",
      "Sahana Ramnath",
      "Yejin Choi",
      "Sai Praneeth Karimireddy",
      "Niloofar Mireshghallah",
      "Xiang Ren"
    ],
    "summary": "Membership inference attacks serves as useful tool for fair use of language models, such as detecting potential copyright infringement and auditing data leakage. However, many current state-of-the-art attacks require access to models' hidden states or probability distribution, which prevents investi...",
    "published": "Aug 13",
    "pdf_url": "https://arxiv.org/pdf/2508.09603v1",
    "arxiv_url": "http://arxiv.org/abs/2508.09603v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "OpenCUA: Open Foundations for Computer-Use Agents",
    "authors": [
      "Xinyuan Wang",
      "Bowen Wang",
      "Dunjie Lu",
      "Junlin Yang",
      "Tianbao Xie",
      "Junli Wang",
      "Jiaqi Deng",
      "Xiaole Guo",
      "Yiheng Xu",
      "Chen Henry Wu",
      "Zhennan Shen",
      "Zhuokai Li",
      "Ryan Li",
      "Xiaochuan Li",
      "Junda Chen",
      "Boyuan Zheng",
      "Peihang Li",
      "Fangyu Lei",
      "Ruisheng Cao",
      "Yeqiao Fu",
      "Dongchan Shin",
      "Martin Shin",
      "Jiarui Hu",
      "Yuyan Wang",
      "Jixuan Chen",
      "Yuxiao Ye",
      "Danyang Zhang",
      "Dikang Du",
      "Hao Hu",
      "Huarong Chen",
      "Zaida Zhou",
      "Haotian Yao",
      "Ziwei Chen",
      "Qizheng Gu",
      "Yipu Wang",
      "Heng Wang",
      "Diyi Yang",
      "Victor Zhong",
      "Flood Sung",
      "Y. Charles",
      "Zhilin Yang",
      "Tao Yu"
    ],
    "summary": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interact...",
    "published": "Aug 12",
    "pdf_url": "https://arxiv.org/pdf/2508.09123v3",
    "arxiv_url": "http://arxiv.org/abs/2508.09123v3",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "OverFill: Two-Stage Models for Efficient Language Model Decoding",
    "authors": [
      "Woojeong Kim",
      "Junxiong Wang",
      "Jing Nathan Yan",
      "Mohamed Abdelfattah",
      "Alexander M. Rush"
    ],
    "summary": "Large language models (LLMs) excel across diverse tasks but face significant deployment challenges due to high inference costs. LLM inference comprises prefill (compute-bound) and decode (memory-bound) stages, with decode dominating latency particularly for long sequences. Current decoder-only model...",
    "published": "Aug 11",
    "pdf_url": "https://arxiv.org/pdf/2508.08446v1",
    "arxiv_url": "http://arxiv.org/abs/2508.08446v1",
    "queried_author": "Alexander M Rush",
    "matching_authors": [
      "Alexander M Rush",
      "Alexander M. Rush"
    ]
  },
  {
    "title": "LL3M: Large Language 3D Modelers",
    "authors": [
      "Sining Lu",
      "Guan Chen",
      "Nam Anh Dinh",
      "Itai Lang",
      "Ari Holtzman",
      "Rana Hanocka"
    ],
    "summary": "We present LL3M, a multi-agent system that leverages pretrained large language models (LLMs) to generate 3D assets by writing interpretable Python code in Blender. We break away from the typical generative approach that learns from a collection of 3D data. Instead, we reformulate shape generation as...",
    "published": "Aug 11",
    "pdf_url": "https://arxiv.org/pdf/2508.08228v1",
    "arxiv_url": "http://arxiv.org/abs/2508.08228v1",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning",
    "authors": [
      "Wenkai Li",
      "Liwen Sun",
      "Zhenxiang Guan",
      "Xuhui Zhou",
      "Maarten Sap"
    ],
    "summary": "Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning int...",
    "published": "Aug 11",
    "pdf_url": "https://arxiv.org/pdf/2508.07667v1",
    "arxiv_url": "http://arxiv.org/abs/2508.07667v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Algorithmic Fairness amid Social Determinants: Reflection, Characterization, and Approach",
    "authors": [
      "Zeyu Tang",
      "Alex John London",
      "Atoosa Kasirzadeh",
      "Sanmi Koyejo",
      "Peter Spirtes",
      "Kun Zhang"
    ],
    "summary": "Social determinants are variables that, while not directly pertaining to any specific individual, capture key aspects of contexts and environments that have direct causal influences on certain attributes of an individual. Previous algorithmic fairness literature has primarily focused on sensitive at...",
    "published": "Aug 10",
    "pdf_url": "https://arxiv.org/pdf/2508.08337v1",
    "arxiv_url": "http://arxiv.org/abs/2508.08337v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Grounding Multilingual Multimodal LLMs With Cultural Knowledge",
    "authors": [
      "Jean de Dieu Nyandwi",
      "Yueqi Song",
      "Simran Khanuja",
      "Graham Neubig"
    ],
    "summary": "Multimodal Large Language Models excel in high-resource settings, but often misinterpret long-tail cultural entities and underperform in low-resource languages. To address this gap, we propose a data-centric approach that directly grounds MLLMs in cultural knowledge. Leveraging a large scale knowled...",
    "published": "Aug 10",
    "pdf_url": "https://arxiv.org/pdf/2508.07414v2",
    "arxiv_url": "http://arxiv.org/abs/2508.07414v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Post-training for Efficient Communication via Convention Formation",
    "authors": [
      "Yilun Hua",
      "Evan Wang",
      "Yoav Artzi"
    ],
    "summary": "Humans communicate with increasing efficiency in multi-turn interactions, by adapting their language and forming ad-hoc conventions. In contrast, prior work shows that LLMs do not naturally show this behavior. We develop a post-training process to develop this ability through targeted fine-tuning on...",
    "published": "Aug 08",
    "pdf_url": "https://arxiv.org/pdf/2508.06482v1",
    "arxiv_url": "http://arxiv.org/abs/2508.06482v1",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Devstral: Fine-tuning Language Models for Coding Agent Applications",
    "authors": [
      "Abhinav Rastogi",
      "Adam Yang",
      "Albert Q. Jiang",
      "Alexander H. Liu",
      "Alexandre Sablayrolles",
      "Am\u00e9lie H\u00e9liou",
      "Am\u00e9lie Martin",
      "Anmol Agarwal",
      "Andy Ehrenberg",
      "Andy Lo",
      "Antoine Roux",
      "Arthur Darcet",
      "Arthur Mensch",
      "Baptiste Bout",
      "Baptiste Rozi\u00e8re",
      "Baudouin De Monicault",
      "Chris Bamford",
      "Christian Wallenwein",
      "Christophe Renaudin",
      "Cl\u00e9mence Lanfranchi",
      "Cl\u00e9ment Denoix",
      "Corentin Barreau",
      "Darius Dabert Devon Mizelle",
      "Diego de las Casas",
      "Elliot Chane-Sane",
      "Emilien Fugier",
      "Emma Bou Hanna",
      "Gabrielle Berrada",
      "Gauthier Delerce",
      "Gauthier Guinet",
      "Georgii Novikov",
      "Graham Neubig",
      "Guillaume Lample",
      "Guillaume Martin",
      "Himanshu Jaju",
      "Jan Ludziejewski",
      "Jason Rute",
      "Jean-Malo Delignon",
      "JeanHadrien Chabran",
      "Joachim Studnia",
      "Joep Barmentlo",
      "Jonas Amar",
      "Josselin Somerville Roberts",
      "Julien Denize",
      "Karan Saxena",
      "Karmesh Yadav",
      "Kartik Khandelwal",
      "Khyathi Raghavi Chandu",
      "Kush Jain",
      "L\u00e9lio Renard Lavaud",
      "L\u00e9onard Blier",
      "Lingxiao Zhao",
      "Louis Martin",
      "Lucile Saulnier",
      "Luyu Gao",
      "Marie Pellat",
      "Mathilde Guillaumin",
      "Mathis Felardos",
      "Matthieu Dinot",
      "Maxime Darrin",
      "Maximilian Augustin",
      "Micka\u00ebl Seznec",
      "Neha Gupta",
      "Nikhil Raghuraman",
      "Olivier Duchenne",
      "Patricia Wang",
      "Patrick von Platen",
      "Patryk Saffer",
      "Paul Jacob",
      "Paul Wambergue",
      "Paula Kurylowicz",
      "Philom\u00e8ne Chagniot",
      "Pierre Stock",
      "Pravesh Agrawal",
      "R\u00e9mi Delacourt",
      "Roman Soletskyi",
      "Romain Sauvestre",
      "Sagar Vaze",
      "Sanchit Gandhi",
      "Sandeep Subramanian",
      "Shashwat Dalal",
      "Siddharth Gandhi",
      "Soham Ghosh",
      "Srijan Mishra",
      "Sumukh Aithal",
      "Szymon Antoniak",
      "Teven Le Scao",
      "Thibaut Lavril",
      "Thibault Schueller",
      "Thomas Foubert",
      "Thomas Robert",
      "Thomas Wang",
      "Timoth\u00e9e Lacroix",
      "Tom Bewley",
      "Valeriia Nemychnikova",
      "Victor Paltz",
      "Virgile Richard",
      "Wen-Ding Li",
      "William Marshall",
      "Xingyao Wang",
      "Xuanyu Zhang",
      "Yihan Wan",
      "Yunhao Tang"
    ],
    "summary": "We introduce Devstral-Small, a lightweight open source model for code agents with the best performance among models below 100B size. In this technical report, we give an overview of how we design and develop a model and craft specializations in agentic software development. The resulting model, Devs...",
    "published": "Aug 08",
    "pdf_url": "https://arxiv.org/pdf/2509.25193v1",
    "arxiv_url": "http://arxiv.org/abs/2509.25193v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes",
    "authors": [
      "Zachary Robertson",
      "Sanmi Koyejo"
    ],
    "summary": "We study evaluation of AI systems without ground truth by exploiting a link between strategic gaming and information loss. We analyze which information-theoretic mechanisms resist adversarial manipulation, extending finite-sample bounds to show that bounded f-divergences (e.g., total variation dista...",
    "published": "Aug 07",
    "pdf_url": "https://arxiv.org/pdf/2508.05469v2",
    "arxiv_url": "http://arxiv.org/abs/2508.05469v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization",
    "authors": [
      "Negar Foroutan",
      "Clara Meister",
      "Debjit Paul",
      "Joel Niklaus",
      "Sina Ahmadi",
      "Antoine Bosselut",
      "Rico Sennrich"
    ],
    "summary": "Tokenization is the first -- and often least scrutinized -- step of most NLP pipelines. Standard algorithms for learning tokenizers rely on frequency-based objectives, which favor languages dominant in the training data and consequently leave lower-resource languages with tokenizations that are disp...",
    "published": "Aug 06",
    "pdf_url": "https://arxiv.org/pdf/2508.04796v2",
    "arxiv_url": "http://arxiv.org/abs/2508.04796v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Multi-module GRPO: Composing Policy Gradients and Prompt Optimization for Language Model Programs",
    "authors": [
      "Noah Ziems",
      "Dilara Soylu",
      "Lakshya A Agrawal",
      "Isaac Miller",
      "Liheng Lai",
      "Chen Qian",
      "Kaiqiang Song",
      "Meng Jiang",
      "Dan Klein",
      "Matei Zaharia",
      "Karel D'Oosterlinck",
      "Christopher Potts",
      "Omar Khattab"
    ],
    "summary": "Group Relative Policy Optimization (GRPO) has proven to be an effective tool for post-training language models (LMs). However, AI systems are increasingly expressed as modular programs that mix together multiple LM calls with distinct prompt templates and other tools, and it is not clear how best to...",
    "published": "Aug 06",
    "pdf_url": "https://arxiv.org/pdf/2508.04660v1",
    "arxiv_url": "http://arxiv.org/abs/2508.04660v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning in LLMs",
    "authors": [
      "Aryan Gulati",
      "Brando Miranda",
      "Eric Chen",
      "Emily Xia",
      "Kai Fronsdal",
      "Bruno Dumont",
      "Elyas Obbad",
      "Sanmi Koyejo"
    ],
    "summary": "Current mathematical reasoning benchmarks for large language models (LLMs) are approaching saturation, with some achieving > 90% accuracy, and are increasingly compromised by training-set contamination. We introduce Putnam-AXIOM, a benchmark of 522 university-level competition problems drawn from th...",
    "published": "Aug 05",
    "pdf_url": "https://arxiv.org/pdf/2508.08292v2",
    "arxiv_url": "http://arxiv.org/abs/2508.08292v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction",
    "authors": [
      "Yong Lin",
      "Shange Tang",
      "Bohan Lyu",
      "Ziran Yang",
      "Jui-Hui Chung",
      "Haoyu Zhao",
      "Lai Jiang",
      "Yihan Geng",
      "Jiawei Ge",
      "Jingruo Sun",
      "Jiayun Wu",
      "Jiri Gesi",
      "Ximing Lu",
      "David Acuna",
      "Kaiyu Yang",
      "Hongzhou Lin",
      "Yejin Choi",
      "Danqi Chen",
      "Sanjeev Arora",
      "Chi Jin"
    ],
    "summary": "We introduce Goedel-Prover-V2, a series of open-source language models that set a new state-of-the-art in automated theorem proving. Built on the standard expert iteration and reinforcement learning pipeline, our approach incorporates three key innovations: (1) Scaffolded data synthesis: We generate...",
    "published": "Aug 05",
    "pdf_url": "https://arxiv.org/pdf/2508.03613v1",
    "arxiv_url": "http://arxiv.org/abs/2508.03613v1",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen",
      "Yejin Choi"
    ]
  },
  {
    "title": "I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2",
    "authors": [
      "Oliver McLaughlin",
      "Arjun Khurana",
      "Jack Merullo"
    ],
    "summary": "Large language models demonstrate proficiency on phonetic tasks, such as rhyming, without explicit phonetic or auditory grounding. In this work, we investigate how \\verb|Llama-3.2-1B-Instruct| represents token-level phonetic information. Our results suggest that Llama uses a rich internal model of p...",
    "published": "Aug 04",
    "pdf_url": "https://arxiv.org/pdf/2508.02527v2",
    "arxiv_url": "http://arxiv.org/abs/2508.02527v2",
    "queried_author": "Jack Merullo",
    "matching_authors": [
      "Jack Merullo"
    ]
  },
  {
    "title": "WebDS: An End-to-End Benchmark for Web-based Data Science",
    "authors": [
      "Ethan Hsu",
      "Hong Meng Yam",
      "Ines Bouissou",
      "Aaron Murali John",
      "Raj Thota",
      "Josh Koe",
      "Vivek Sarath Putta",
      "G K Dharesan",
      "Alexander Spangher",
      "Shikhar Murty",
      "Tenghao Huang",
      "Christopher D. Manning"
    ],
    "summary": "A large portion of real-world data science tasks are complex and require multi-hop web-based interactions: finding appropriate data available on the internet, synthesizing real-time data of various modalities from different locations, and producing summarized analyses. Existing web benchmarks often ...",
    "published": "Aug 02",
    "pdf_url": "https://arxiv.org/pdf/2508.01222v1",
    "arxiv_url": "http://arxiv.org/abs/2508.01222v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal",
    "authors": [
      "Yuhan Liu",
      "Michael J. Q. Zhang",
      "Eunsol Choi"
    ],
    "summary": "Once language models (LMs) are deployed, they can interact with users long-term, ideally evolving based on their feedback. Asking for direct user feedback can be disruptive; thus, we study harvesting implicit user feedback from user-LM interaction logs. We study two user-LM interaction datasets (Wil...",
    "published": "Jul 30",
    "pdf_url": "https://arxiv.org/pdf/2507.23158v2",
    "arxiv_url": "http://arxiv.org/abs/2507.23158v2",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "Meta CLIP 2: A Worldwide Scaling Recipe",
    "authors": [
      "Yung-Sung Chuang",
      "Yang Li",
      "Dong Wang",
      "Ching-Feng Yeh",
      "Kehan Lyu",
      "Ramya Raghavendra",
      "James Glass",
      "Lifei Huang",
      "Jason Weston",
      "Luke Zettlemoyer",
      "Xinlei Chen",
      "Zhuang Liu",
      "Saining Xie",
      "Wen-tau Yih",
      "Shang-Wen Li",
      "Hu Xu"
    ],
    "summary": "Contrastive Language-Image Pretraining (CLIP) is a popular foundation model, supporting from zero-shot classification, retrieval to encoders for multimodal large language models (MLLMs). Although CLIP is successfully trained on billion-scale image-text pairs from the English world, scaling CLIP's tr...",
    "published": "Jul 29",
    "pdf_url": "https://arxiv.org/pdf/2507.22062v3",
    "arxiv_url": "http://arxiv.org/abs/2507.22062v3",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition",
    "authors": [
      "Andy Zou",
      "Maxwell Lin",
      "Eliot Jones",
      "Micha Nowak",
      "Mateusz Dziemian",
      "Nick Winter",
      "Alexander Grattan",
      "Valent Nathanael",
      "Ayla Croft",
      "Xander Davies",
      "Jai Patel",
      "Robert Kirk",
      "Nate Burnikell",
      "Yarin Gal",
      "Dan Hendrycks",
      "J. Zico Kolter",
      "Matt Fredrikson"
    ],
    "summary": "Recent advances have enabled LLM-powered AI agents to autonomously execute complex tasks by combining language model reasoning with tools, memory, and web access. But can these systems be trusted to follow deployment policies in realistic environments, especially under attack? To investigate, we ran...",
    "published": "Jul 28",
    "pdf_url": "https://arxiv.org/pdf/2507.20526v1",
    "arxiv_url": "http://arxiv.org/abs/2507.20526v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations",
    "authors": [
      "Eunkyu Park",
      "Wesley Hanwen Deng",
      "Gunhee Kim",
      "Motahhare Eslami",
      "Maarten Sap"
    ],
    "summary": "Chain-of-Thought (CoT) prompting helps models think step by step. But what happens when they must see, understand, and judge-all at once? In visual tasks grounded in social context, where bridging perception with norm-grounded judgments is essential, flat CoT often breaks down. We introduce Cognitiv...",
    "published": "Jul 27",
    "pdf_url": "https://arxiv.org/pdf/2507.20409v1",
    "arxiv_url": "http://arxiv.org/abs/2507.20409v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
    "authors": [
      "Lakshya A Agrawal",
      "Shangyin Tan",
      "Dilara Soylu",
      "Noah Ziems",
      "Rishi Khare",
      "Krista Opsahl-Ong",
      "Arnav Singhvi",
      "Herumb Shandilya",
      "Michael J Ryan",
      "Meng Jiang",
      "Christopher Potts",
      "Koushik Sen",
      "Alexandros G. Dimakis",
      "Ion Stoica",
      "Dan Klein",
      "Matei Zaharia",
      "Omar Khattab"
    ],
    "summary": "Large language models (LLMs) are increasingly adapted to downstream tasks via reinforcement learning (RL) methods like Group Relative Policy Optimization (GRPO), which often require thousands of rollouts to learn new tasks. We argue that the interpretable nature of language can often provide a much ...",
    "published": "Jul 25",
    "pdf_url": "https://arxiv.org/pdf/2507.19457v1",
    "arxiv_url": "http://arxiv.org/abs/2507.19457v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences",
    "authors": [
      "Yusuke Hirota",
      "Boyi Li",
      "Ryo Hachiuma",
      "Yueh-Hua Wu",
      "Boris Ivanovic",
      "Yuta Nakashima",
      "Marco Pavone",
      "Yejin Choi",
      "Yu-Chiang Frank Wang",
      "Chao-Han Huck Yang"
    ],
    "summary": "Large Vision-Language Models (LVLMs) have transformed image captioning, shifting from concise captions to detailed descriptions. We introduce LOTUS, a leaderboard for evaluating detailed captions, addressing three main gaps in existing evaluations: lack of standardized criteria, bias-aware assessmen...",
    "published": "Jul 25",
    "pdf_url": "https://arxiv.org/pdf/2507.19362v1",
    "arxiv_url": "http://arxiv.org/abs/2507.19362v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Closing the Modality Gap for Mixed Modality Search",
    "authors": [
      "Binxu Li",
      "Yuhui Zhang",
      "Xiaohan Wang",
      "Weixin Liang",
      "Ludwig Schmidt",
      "Serena Yeung-Levy"
    ],
    "summary": "Mixed modality search -- retrieving information across a heterogeneous corpus composed of images, texts, and multimodal documents -- is an important yet underexplored real-world application. In this work, we investigate how contrastive vision-language models, such as CLIP, perform on the mixed modal...",
    "published": "Jul 25",
    "pdf_url": "https://arxiv.org/pdf/2507.19054v1",
    "arxiv_url": "http://arxiv.org/abs/2507.19054v1",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator",
    "authors": [
      "YuXin Li",
      "Felix Dangel",
      "Derek Tam",
      "Colin Raffel"
    ],
    "summary": "The diagonal of a model's Fisher Information Matrix (the \"Fisher diagonal\") has frequently been used as a way to measure parameter sensitivity. Typically, the Fisher diagonal is estimated via squared sampled gradients of the model's likelihood with respect to its parameters, averaged over a few hund...",
    "published": "Jul 24",
    "pdf_url": "https://arxiv.org/pdf/2507.18807v1",
    "arxiv_url": "http://arxiv.org/abs/2507.18807v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "Checklists Are Better Than Reward Models For Aligning Language Models",
    "authors": [
      "Vijay Viswanathan",
      "Yanchao Sun",
      "Shuang Ma",
      "Xiang Kong",
      "Meng Cao",
      "Graham Neubig",
      "Tongshuang Wu"
    ],
    "summary": "Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as \"helpfulness\" and \"harmfulness\". In our work, we instead propose using flexible, instruction-specific criteria as a means of ...",
    "published": "Jul 24",
    "pdf_url": "https://arxiv.org/pdf/2507.18624v2",
    "arxiv_url": "http://arxiv.org/abs/2507.18624v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "A New Pair of GloVes",
    "authors": [
      "Riley Carlson",
      "John Bauer",
      "Christopher D. Manning"
    ],
    "summary": "This report documents, describes, and evaluates new 2024 English GloVe (Global Vectors for Word Representation) models. While the original GloVe models built in 2014 have been widely used and found useful, languages and the world continue to evolve and we thought that current usage could benefit fro...",
    "published": "Jul 24",
    "pdf_url": "https://arxiv.org/pdf/2507.18103v1",
    "arxiv_url": "http://arxiv.org/abs/2507.18103v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty",
    "authors": [
      "Mehul Damani",
      "Isha Puri",
      "Stewart Slocum",
      "Idan Shenfeld",
      "Leshem Choshen",
      "Yoon Kim",
      "Jacob Andreas"
    ],
    "summary": "When language models (LMs) are trained via reinforcement learning (RL) to generate natural language \"reasoning chains\", their performance improves on a variety of difficult question answering tasks. Today, almost all successful applications of RL for reasoning use binary reward functions that evalua...",
    "published": "Jul 22",
    "pdf_url": "https://arxiv.org/pdf/2507.16806v1",
    "arxiv_url": "http://arxiv.org/abs/2507.16806v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning",
    "authors": [
      "Helena Casademunt",
      "Caden Juang",
      "Adam Karvonen",
      "Samuel Marks",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "Fine-tuning large language models (LLMs) can lead to unintended out-of-distribution generalization. Standard approaches to this problem rely on modifying training data, for example by adding data that better specify the intended generalization. However, this is not always practical. We introduce Con...",
    "published": "Jul 22",
    "pdf_url": "https://arxiv.org/pdf/2507.16795v2",
    "arxiv_url": "http://arxiv.org/abs/2507.16795v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Distributional Machine Unlearning via Selective Data Removal",
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Sanmi Koyejo"
    ],
    "summary": "Machine learning systems increasingly face requirements to remove entire domains of information -- such as toxic language or biases -- rather than individual user data. This task presents a dilemma: full removal of the unwanted domain data is computationally expensive, while random partial removal i...",
    "published": "Jul 20",
    "pdf_url": "https://arxiv.org/pdf/2507.15112v3",
    "arxiv_url": "http://arxiv.org/abs/2507.15112v3",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin",
    "authors": [
      "Fang Wu",
      "Weihao Xuan",
      "Ximing Lu",
      "Mingjie Liu",
      "Yi Dong",
      "Zaid Harchaoui",
      "Yejin Choi"
    ],
    "summary": "Recent advances in LLMs highlight RLVR as a promising method for enhancing AI's capabilities, particularly in solving complex logical tasks. However, it remains unclear whether the current practice of RLVR truly expands a model's reasoning boundary or mainly amplifies high-reward outputs that the ba...",
    "published": "Jul 20",
    "pdf_url": "https://arxiv.org/pdf/2507.14843v2",
    "arxiv_url": "http://arxiv.org/abs/2507.14843v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Inverse Scaling in Test-Time Compute",
    "authors": [
      "Aryo Pradipta Gema",
      "Alexander H\u00e4gele",
      "Runjin Chen",
      "Andy Arditi",
      "Jacob Goldman-Wetzler",
      "Kit Fraser-Taliente",
      "Henry Sleight",
      "Linda Petrini",
      "Julian Michael",
      "Beatrice Alex",
      "Pasquale Minervini",
      "Yanda Chen",
      "Joe Benton",
      "Ethan Perez"
    ],
    "summary": "We construct evaluation tasks where extending the reasoning length of Large Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling relationship between test-time compute and accuracy. Our evaluation tasks span four categories: simple counting tasks with distractors, regressi...",
    "published": "Jul 19",
    "pdf_url": "https://arxiv.org/pdf/2507.14417v2",
    "arxiv_url": "http://arxiv.org/abs/2507.14417v2",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez"
    ]
  },
  {
    "title": "Intent-Aware Schema Generation And Refinement For Literature Review Tables",
    "authors": [
      "Vishakh Padmakumar",
      "Joseph Chee Chang",
      "Kyle Lo",
      "Doug Downey",
      "Aakanksha Naik"
    ],
    "summary": "The increasing volume of academic literature makes it essential for researchers to organize, compare, and contrast collections of documents. Large language models (LLMs) can support this process by generating schemas defining shared aspects along which to compare papers. However, progress on schema ...",
    "published": "Jul 18",
    "pdf_url": "https://arxiv.org/pdf/2507.19521v2",
    "arxiv_url": "http://arxiv.org/abs/2507.19521v2",
    "queried_author": "Kyle Lo",
    "matching_authors": [
      "Kyle Lo"
    ]
  },
  {
    "title": "Assessing Adaptive World Models in Machines with Novel Games",
    "authors": [
      "Lance Ying",
      "Katherine M. Collins",
      "Prafull Sharma",
      "Cedric Colas",
      "Kaiya Ivy Zhao",
      "Adrian Weller",
      "Zenna Tavares",
      "Phillip Isola",
      "Samuel J. Gershman",
      "Jacob D. Andreas",
      "Thomas L. Griffiths",
      "Francois Chollet",
      "Kelsey R. Allen",
      "Joshua B. Tenenbaum"
    ],
    "summary": "Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonl...",
    "published": "Jul 17",
    "pdf_url": "https://arxiv.org/pdf/2507.12821v2",
    "arxiv_url": "http://arxiv.org/abs/2507.12821v2",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation",
    "authors": [
      "Potsawee Manakul",
      "Woody Haosheng Gan",
      "Michael J. Ryan",
      "Ali Sartaz Khan",
      "Warit Sirichotedumrong",
      "Kunat Pipatanakul",
      "William Held",
      "Diyi Yang"
    ],
    "summary": "Current speech evaluation suffers from two critical limitations: the need and difficulty of designing specialized systems targeting individual audio characteristics, and poor correlation between automatic evaluation methods and human preferences. This work presents a systematic study of Large Audio ...",
    "published": "Jul 17",
    "pdf_url": "https://arxiv.org/pdf/2507.12705v1",
    "arxiv_url": "http://arxiv.org/abs/2507.12705v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "William Held"
    ]
  },
  {
    "title": "Reasoning-Finetuning Repurposes Latent Representations in Base Models",
    "authors": [
      "Jake Ward",
      "Chuqiao Lin",
      "Constantin Venhoff",
      "Neel Nanda"
    ],
    "summary": "Backtracking, an emergent behavior elicited by reasoning fine-tuning, has been shown to be a key mechanism in reasoning models' enhanced capabilities. Prior work has succeeded in manipulating this behavior via steering vectors, but the underlying mechanism remains poorly understood. In this work, we...",
    "published": "Jul 16",
    "pdf_url": "https://arxiv.org/pdf/2507.12638v1",
    "arxiv_url": "http://arxiv.org/abs/2507.12638v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models",
    "authors": [
      "Lionel Wong",
      "Katherine M. Collins",
      "Lance Ying",
      "Cedegao E. Zhang",
      "Adrian Weller",
      "Tobias Gerstenberg",
      "Timothy O'Donnell",
      "Alexander K. Lew",
      "Jacob D. Andreas",
      "Joshua B. Tenenbaum",
      "Tyler Brooke-Wilson"
    ],
    "summary": "When faced with novel situations, people are able to marshal relevant considerations from a wide range of background knowledge and put these to use in inferences and predictions. What permits us to draw in globally relevant information and reason over it coherently? Here, we explore the hypothesis t...",
    "published": "Jul 16",
    "pdf_url": "https://arxiv.org/pdf/2507.12547v2",
    "arxiv_url": "http://arxiv.org/abs/2507.12547v2",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training",
    "authors": [
      "Mingjie Liu",
      "Shizhe Diao",
      "Jian Hu",
      "Ximing Lu",
      "Xin Dong",
      "Hao Zhang",
      "Alexander Bukharin",
      "Shaokun Zhang",
      "Jiaqi Zeng",
      "Makesh Narsimhan Sreedhar",
      "Gerald Shen",
      "David Mosallanezhad",
      "Di Zhang",
      "Jonas Yang",
      "June Yang",
      "Oleksii Kuchaiev",
      "Guilin Liu",
      "Zhiding Yu",
      "Pavlo Molchanov",
      "Yejin Choi",
      "Jan Kautz",
      "Yi Dong"
    ],
    "summary": "Recent advancements in reasoning-focused language models such as OpenAI's O1 and DeepSeek-R1 have shown that scaling test-time computation-through chain-of-thought reasoning and iterative exploration-can yield substantial improvements on complex tasks like mathematics and code generation. These brea...",
    "published": "Jul 16",
    "pdf_url": "https://arxiv.org/pdf/2507.12507v1",
    "arxiv_url": "http://arxiv.org/abs/2507.12507v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety",
    "authors": [
      "Tomek Korbak",
      "Mikita Balesni",
      "Elizabeth Barnes",
      "Yoshua Bengio",
      "Joe Benton",
      "Joseph Bloom",
      "Mark Chen",
      "Alan Cooney",
      "Allan Dafoe",
      "Anca Dragan",
      "Scott Emmons",
      "Owain Evans",
      "David Farhi",
      "Ryan Greenblatt",
      "Dan Hendrycks",
      "Marius Hobbhahn",
      "Evan Hubinger",
      "Geoffrey Irving",
      "Erik Jenner",
      "Daniel Kokotajlo",
      "Victoria Krakovna",
      "Shane Legg",
      "David Lindner",
      "David Luan",
      "Aleksander M\u0105dry",
      "Julian Michael",
      "Neel Nanda",
      "Dave Orr",
      "Jakub Pachocki",
      "Ethan Perez",
      "Mary Phuong",
      "Fabien Roger",
      "Joshua Saxe",
      "Buck Shlegeris",
      "Mart\u00edn Soto",
      "Eric Steinberger",
      "Jasmine Wang",
      "Wojciech Zaremba",
      "Bowen Baker",
      "Rohin Shah",
      "Vlad Mikulik"
    ],
    "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI safety: we can monitor their chains of thought (CoT) for the intent to misbehave. Like all other known AI oversight methods, CoT monitoring is imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows pro...",
    "published": "Jul 15",
    "pdf_url": "https://arxiv.org/pdf/2507.11473v2",
    "arxiv_url": "http://arxiv.org/abs/2507.11473v2",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez",
      "Neel Nanda"
    ]
  },
  {
    "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders",
    "authors": [
      "Orion Weller",
      "Kathryn Ricci",
      "Marc Marone",
      "Antoine Chaffin",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "summary": "The large language model (LLM) community focuses almost exclusively on decoder-only language models, since they are easier to use for text generation. However, a large subset of the community still uses encoder-only models for tasks such as classification or retrieval. Previous work has attempted to...",
    "published": "Jul 15",
    "pdf_url": "https://arxiv.org/pdf/2507.11412v1",
    "arxiv_url": "http://arxiv.org/abs/2507.11412v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "The Curious Case of Factuality Finetuning: Models' Internal Beliefs Can Improve Factuality",
    "authors": [
      "Benjamin Newman",
      "Abhilasha Ravichander",
      "Jaehun Jung",
      "Rui Xin",
      "Hamish Ivison",
      "Yegor Kuznetsov",
      "Pang Wei Koh",
      "Yejin Choi"
    ],
    "summary": "Language models are prone to hallucination - generating text that is factually incorrect. Finetuning models on high-quality factual information can potentially reduce hallucination, but concerns remain; obtaining factual gold data can be expensive and training on correct but unfamiliar data may pote...",
    "published": "Jul 11",
    "pdf_url": "https://arxiv.org/pdf/2507.08371v1",
    "arxiv_url": "http://arxiv.org/abs/2507.08371v1",
    "queried_author": "Hamish Ivison",
    "matching_authors": [
      "Hamish Ivison",
      "Pang Wei Koh",
      "Yejin Choi"
    ]
  },
  {
    "title": "Simple Mechanistic Explanations for Out-Of-Context Reasoning",
    "authors": [
      "Atticus Wang",
      "Joshua Engels",
      "Oliver Clive-Griffin",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "Out-of-context reasoning (OOCR) is a phenomenon in which fine-tuned LLMs exhibit surprisingly deep out-of-distribution generalization. Rather than learning shallow heuristics, they implicitly internalize and act on the consequences of observations scattered throughout the fine-tuning data. In this w...",
    "published": "Jul 10",
    "pdf_url": "https://arxiv.org/pdf/2507.08218v2",
    "arxiv_url": "http://arxiv.org/abs/2507.08218v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling",
    "authors": [
      "Sukjun Hwang",
      "Brandon Wang",
      "Albert Gu"
    ],
    "summary": "Major progress on language models (LMs) in recent years has largely resulted from moving away from specialized models designed for specific tasks, to general models based on powerful architectures (e.g. the Transformer) that learn everything from raw data. Despite this trend, pre-processing steps su...",
    "published": "Jul 10",
    "pdf_url": "https://arxiv.org/pdf/2507.07955v2",
    "arxiv_url": "http://arxiv.org/abs/2507.07955v2",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu"
    ]
  },
  {
    "title": "FlexOlmo: Open Language Models for Flexible Data Use",
    "authors": [
      "Weijia Shi",
      "Akshita Bhagia",
      "Kevin Farhat",
      "Niklas Muennighoff",
      "Pete Walsh",
      "Jacob Morrison",
      "Dustin Schwenk",
      "Shayne Longpre",
      "Jake Poznanski",
      "Allyson Ettinger",
      "Daogao Liu",
      "Margaret Li",
      "Dirk Groeneveld",
      "Mike Lewis",
      "Wen-tau Yih",
      "Luca Soldaini",
      "Kyle Lo",
      "Noah A. Smith",
      "Luke Zettlemoyer",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi",
      "Ali Farhadi",
      "Sewon Min"
    ],
    "summary": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flex...",
    "published": "Jul 09",
    "pdf_url": "https://arxiv.org/pdf/2507.07024v4",
    "arxiv_url": "http://arxiv.org/abs/2507.07024v4",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Kyle Lo",
      "Luca Soldaini",
      "Luke Zettlemoyer",
      "Mike Lewis",
      "Niklas Muennighoff",
      "Noah A. Smith",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning",
    "authors": [
      "Zeming Chen",
      "Angelika Romanou",
      "Gail Weiss",
      "Antoine Bosselut"
    ],
    "summary": "Long-context reasoning requires accurately identifying relevant information in extensive, noisy input contexts. Previous research shows that using test-time learning to encode context directly into model parameters can effectively enable reasoning over noisy information. However, meta-learning metho...",
    "published": "Jul 08",
    "pdf_url": "https://arxiv.org/pdf/2507.06415v2",
    "arxiv_url": "http://arxiv.org/abs/2507.06415v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Humans overrely on overconfident language models, across languages",
    "authors": [
      "Neil Rathi",
      "Dan Jurafsky",
      "Kaitlyn Zhou"
    ],
    "summary": "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Prior work shows that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. Howe...",
    "published": "Jul 08",
    "pdf_url": "https://arxiv.org/pdf/2507.06306v2",
    "arxiv_url": "http://arxiv.org/abs/2507.06306v2",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains",
    "authors": [
      "Scott Geng",
      "Hamish Ivison",
      "Chun-Liang Li",
      "Maarten Sap",
      "Jerry Li",
      "Ranjay Krishna",
      "Pang Wei Koh"
    ],
    "summary": "Improvements in language models are often driven by improving the quality of the data we train them on, which can be limiting when strong supervision is scarce. In this work, we show that paired preference data consisting of individually weak data points can enable gains beyond the strength of each ...",
    "published": "Jul 08",
    "pdf_url": "https://arxiv.org/pdf/2507.06187v1",
    "arxiv_url": "http://arxiv.org/abs/2507.06187v1",
    "queried_author": "Hamish Ivison",
    "matching_authors": [
      "Hamish Ivison",
      "Maarten Sap",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety",
    "authors": [
      "Sanidhya Vijayvargiya",
      "Aditya Bharat Soni",
      "Xuhui Zhou",
      "Zora Zhiruo Wang",
      "Nouha Dziri",
      "Graham Neubig",
      "Maarten Sap"
    ],
    "summary": "Recent advances in AI agents capable of solving complex, everyday tasks, from scheduling to customer service, have enabled deployment in real-world settings, but their possibilities for unsafe behavior demands rigorous evaluation. While prior benchmarks have attempted to assess agent safety, most fa...",
    "published": "Jul 08",
    "pdf_url": "https://arxiv.org/pdf/2507.06134v1",
    "arxiv_url": "http://arxiv.org/abs/2507.06134v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Maarten Sap"
    ]
  },
  {
    "title": "Agentic-R1: Distilled Dual-Strategy Reasoning",
    "authors": [
      "Weihua Du",
      "Pranjal Aggarwal",
      "Sean Welleck",
      "Yiming Yang"
    ],
    "summary": "Current long chain-of-thought (long-CoT) models excel at mathematical reasoning but rely on slow and error-prone natural language traces. Tool-augmented agents address arithmetic via code execution, but often falter on complex logical tasks. We introduce a fine-tuning framework, DualDistill, that di...",
    "published": "Jul 08",
    "pdf_url": "https://arxiv.org/pdf/2507.05707v2",
    "arxiv_url": "http://arxiv.org/abs/2507.05707v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
    "authors": [
      "Gheorghe Comanici",
      "Eric Bieber",
      "Mike Schaekermann",
      "Ice Pasupat",
      "Noveen Sachdeva",
      "Inderjit Dhillon",
      "Marcel Blistein",
      "Ori Ram",
      "Dan Zhang",
      "Evan Rosen",
      "Luke Marris",
      "Sam Petulla",
      "Colin Gaffney",
      "Asaf Aharoni",
      "Nathan Lintz",
      "Tiago Cardal Pais",
      "Henrik Jacobsson",
      "Idan Szpektor",
      "Nan-Jiang Jiang",
      "Krishna Haridasan",
      "Ahmed Omran",
      "Nikunj Saunshi",
      "Dara Bahri",
      "Gaurav Mishra",
      "Eric Chu",
      "Toby Boyd",
      "Brad Hekman",
      "Aaron Parisi",
      "Chaoyi Zhang",
      "Kornraphop Kawintiranon",
      "Tania Bedrax-Weiss",
      "Oliver Wang",
      "Ya Xu",
      "Ollie Purkiss",
      "Uri Mendlovic",
      "Ila\u00ef Deutel",
      "Nam Nguyen",
      "Adam Langley",
      "Flip Korn",
      "Lucia Rossazza",
      "Alexandre Ram\u00e9",
      "Sagar Waghmare",
      "Helen Miller",
      "Nathan Byrd",
      "Ashrith Sheshan",
      "Raia Hadsell",
      "Sangnie Bhardwaj",
      "Pawel Janus",
      "Tero Rissa",
      "Dan Horgan",
      "Alvin Abdagic",
      "Lior Belenki",
      "James Allingham",
      "Anima Singh",
      "Theo Guidroz",
      "Srivatsan Srinivasan",
      "Herman Schmit",
      "Kristen Chiafullo",
      "Andre Elisseeff",
      "Nilpa Jha",
      "Prateek Kolhar",
      "Leonard Berrada",
      "Frank Ding",
      "Xiance Si",
      "Shrestha Basu Mallick",
      "Franz Och",
      "Sofia Erell",
      "Eric Ni",
      "Tejasi Latkar",
      "Sherry Yang",
      "Petar Sirkovic",
      "Ziqiang Feng",
      "Robert Leland",
      "Rachel Hornung",
      "Gang Wu",
      "Charles Blundell",
      "Hamidreza Alvari",
      "Po-Sen Huang",
      "Cathy Yip",
      "Sanja Deur",
      "Li Liu",
      "Gabriela Surita",
      "Pablo Duque",
      "Dima Damen",
      "Johnson Jia",
      "Arthur Guez",
      "Markus Mircea",
      "Animesh Sinha",
      "Alberto Magni",
      "Pawe\u0142 Stradomski",
      "Tal Marian",
      "Vlado Gali\u0107",
      "Wenhu Chen",
      "Hisham Husain",
      "Achintya Singhal",
      "Dominik Grewe",
      "Fran\u00e7ois-Xavier Aubet",
      "Shuang Song",
      "Lorenzo Blanco",
      "Leland Rechis",
      "Lewis Ho",
      "Rich Munoz",
      "Kelvin Zheng",
      "Jessica Hamrick",
      "Kevin Mather",
      "Hagai Taitelbaum",
      "Eliza Rutherford",
      "Yun Lei",
      "Kuangyuan Chen",
      "Anand Shukla",
      "Erica Moreira",
      "Eric Doi",
      "Berivan Isik",
      "Nir Shabat",
      "Dominika Rogozi\u0144ska",
      "Kashyap Kolipaka",
      "Jason Chang",
      "Eugen Vu\u0161ak",
      "Srinivasan Venkatachary",
      "Shadi Noghabi",
      "Tarun Bharti",
      "Younghoon Jun",
      "Aleksandr Zaks",
      "Simon Green",
      "Jeshwanth Challagundla",
      "William Wong",
      "Muqthar Mohammad",
      "Dean Hirsch",
      "Yong Cheng",
      "Iftekhar Naim",
      "Lev Proleev",
      "Damien Vincent",
      "Aayush Singh",
      "Maxim Krikun",
      "Dilip Krishnan",
      "Zoubin Ghahramani",
      "Aviel Atias",
      "Rajeev Aggarwal",
      "Christo Kirov",
      "Dimitrios Vytiniotis",
      "Christy Koh",
      "Alexandra Chronopoulou",
      "Pawan Dogra",
      "Vlad-Doru Ion",
      "Gladys Tyen",
      "Jason Lee",
      "Felix Weissenberger",
      "Trevor Strohman",
      "Ashwin Balakrishna",
      "Jack Rae",
      "Marko Velic",
      "Raoul de Liedekerke",
      "Oded Elyada",
      "Wentao Yuan",
      "Canoee Liu",
      "Lior Shani",
      "Sergey Kishchenko",
      "Bea Alessio",
      "Yandong Li",
      "Richard Song",
      "Sam Kwei",
      "Orion Jankowski",
      "Aneesh Pappu",
      "Youhei Namiki",
      "Yenai Ma",
      "Nilesh Tripuraneni",
      "Colin Cherry",
      "Marissa Ikonomidis",
      "Yu-Cheng Ling",
      "Colin Ji",
      "Beka Westberg",
      "Auriel Wright",
      "Da Yu",
      "David Parkinson",
      "Swaroop Ramaswamy",
      "Jerome Connor",
      "Soheil Hassas Yeganeh",
      "Snchit Grover",
      "George Kenwright",
      "Lubo Litchev",
      "Chris Apps",
      "Alex Tomala",
      "Felix Halim",
      "Alex Castro-Ros",
      "Zefei Li",
      "Anudhyan Boral",
      "Pauline Sho",
      "Michal Yarom",
      "Eric Malmi",
      "David Klinghoffer",
      "Rebecca Lin",
      "Alan Ansell",
      "Pradeep Kumar S",
      "Shubin Zhao",
      "Siqi Zuo",
      "Adam Santoro",
      "Heng-Tze Cheng",
      "Solomon Demmessie",
      "Yuchi Liu",
      "Nicole Brichtova",
      "Allie Culp",
      "Nathaniel Braun",
      "Dan Graur",
      "Will Ng",
      "Nikhil Mehta",
      "Aaron Phillips",
      "Patrik Sundberg",
      "Varun Godbole",
      "Fangyu Liu",
      "Yash Katariya",
      "David Rim",
      "Mojtaba Seyedhosseini",
      "Sean Ammirati",
      "Jonas Valfridsson",
      "Mahan Malihi",
      "Timothy Knight",
      "Andeep Toor",
      "Thomas Lampe",
      "Abe Ittycheriah",
      "Lewis Chiang",
      "Chak Yeung",
      "Alexandre Fr\u00e9chette",
      "Jinmeng Rao",
      "Huisheng Wang",
      "Himanshu Srivastava",
      "Richard Zhang",
      "Rocky Rhodes",
      "Ariel Brand",
      "Dean Weesner",
      "Ilya Figotin",
      "Felix Gimeno",
      "Rachana Fellinger",
      "Pierre Marcenac",
      "Jos\u00e9 Leal",
      "Eyal Marcus",
      "Victor Cotruta",
      "Rodrigo Cabrera",
      "Sheryl Luo",
      "Dan Garrette",
      "Vera Axelrod",
      "Sorin Baltateanu",
      "David Barker",
      "Dongkai Chen",
      "Horia Toma",
      "Ben Ingram",
      "Jason Riesa",
      "Chinmay Kulkarni",
      "Yujing Zhang",
      "Hongbin Liu",
      "Chao Wang",
      "Martin Polacek",
      "Will Wu",
      "Kai Hui",
      "Adrian N Reyes",
      "Yi Su",
      "Megan Barnes",
      "Ishaan Malhi",
      "Anfal Siddiqui",
      "Qixuan Feng",
      "Mihai Damaschin",
      "Daniele Pighin",
      "Andreas Steiner",
      "Samuel Yang",
      "Ramya Sree Boppana",
      "Simeon Ivanov",
      "Arun Kandoor",
      "Aditya Shah",
      "Asier Mujika",
      "Da Huang",
      "Christopher A. Choquette-Choo",
      "Mohak Patel",
      "Tianhe Yu",
      "Toni Creswell",
      "Jerry",
      "Liu",
      "Catarina Barros",
      "Yasaman Razeghi",
      "Aurko Roy",
      "Phil Culliton",
      "Binbin Xiong",
      "Jiaqi Pan",
      "Thomas Strohmann",
      "Tolly Powell",
      "Babi Seal",
      "Doug DeCarlo",
      "Pranav Shyam",
      "Kaan Katircioglu",
      "Xuezhi Wang",
      "Cassidy Hardin",
      "Immanuel Odisho",
      "Josef Broder",
      "Oscar Chang",
      "Arun Nair",
      "Artem Shtefan",
      "Maura O'Brien",
      "Manu Agarwal",
      "Sahitya Potluri",
      "Siddharth Goyal",
      "Amit Jhindal",
      "Saksham Thakur",
      "Yury Stuken",
      "James Lyon",
      "Kristina Toutanova",
      "Fangxiaoyu Feng",
      "Austin Wu",
      "Ben Horn",
      "Alek Wang",
      "Alex Cullum",
      "Gabe Taubman",
      "Disha Shrivastava",
      "Chongyang Shi",
      "Hamish Tomlinson",
      "Roma Patel",
      "Tao Tu",
      "Ada Maksutaj Oflazer",
      "Francesco Pongetti",
      "Mingyao Yang",
      "Adrien Ali Ta\u00efga",
      "Vincent Perot",
      "Nuo Wang Pierse",
      "Feng Han",
      "Yoel Drori",
      "I\u00f1aki Iturrate",
      "Ayan Chakrabarti",
      "Legg Yeung",
      "Dave Dopson",
      "Yi-ting Chen",
      "Apoorv Kulshreshtha",
      "Tongfei Guo",
      "Philip Pham",
      "Tal Schuster",
      "Junquan Chen",
      "Alex Polozov",
      "Jinwei Xing",
      "Huanjie Zhou",
      "Praneeth Kacham",
      "Doron Kukliansky",
      "Antoine Miech",
      "Sergey Yaroshenko",
      "Ed Chi",
      "Sholto Douglas",
      "Hongliang Fei",
      "Mathieu Blondel",
      "Preethi Myla",
      "Lior Madmoni",
      "Xing Wu",
      "Daniel Keysers",
      "Kristian Kjems",
      "Isabela Albuquerque",
      "Lijun Yu",
      "Joel D'sa",
      "Michelle Plantan",
      "Vlad Ionescu",
      "Jaume Sanchez Elias",
      "Abhirut Gupta",
      "Manish Reddy Vuyyuru",
      "Fred Alcober",
      "Tong Zhou",
      "Kaiyang Ji",
      "Florian Hartmann",
      "Subha Puttagunta",
      "Hugo Song",
      "Ehsan Amid",
      "Anca Stefanoiu",
      "Andrew Lee",
      "Paul Pucciarelli",
      "Emma Wang",
      "Amit Raul",
      "Slav Petrov",
      "Isaac Tian",
      "Valentin Anklin",
      "Nana Nti",
      "Victor Gomes",
      "Max Schumacher",
      "Grace Vesom",
      "Alex Panagopoulos",
      "Konstantinos Bousmalis",
      "Daniel Andor",
      "Josh Jacob",
      "Yuan Zhang",
      "Bill Rosgen",
      "Matija Kecman",
      "Matthew Tung",
      "Alexandra Belias",
      "Noah Goodman",
      "Paul Covington",
      "Brian Wieder",
      "Nikita Saxena",
      "Elnaz Davoodi",
      "Muhuan Huang",
      "Sharath Maddineni",
      "Vincent Roulet",
      "Folawiyo Campbell-Ajala",
      "Pier Giuseppe Sessa",
      "Xintian",
      "Wu",
      "Guangda Lai",
      "Paul Collins",
      "Alex Haig",
      "Vytenis Sakenas",
      "Xiaowei Xu",
      "Marissa Giustina",
      "Laurent El Shafey",
      "Pichi Charoenpanit",
      "Shefali Garg",
      "Joshua Ainslie",
      "Boone Severson",
      "Montse Gonzalez Arenas",
      "Shreya Pathak",
      "Sujee Rajayogam",
      "Jie Feng",
      "Michiel Bakker",
      "Sheng Li",
      "Nevan Wichers",
      "Jamie Rogers",
      "Xinyang Geng",
      "Yeqing Li",
      "Rolf Jagerman",
      "Chao Jia",
      "Nadav Olmert",
      "David Sharon",
      "Matthew Mauger",
      "Sandeep Mariserla",
      "Hongxu Ma",
      "Megha Mohabey",
      "Kyuyeun Kim",
      "Alek Andreev",
      "Scott Pollom",
      "Juliette Love",
      "Vihan Jain",
      "Priyanka Agrawal",
      "Yannick Schroecker",
      "Alisa Fortin",
      "Manfred Warmuth",
      "Ji Liu",
      "Andrew Leach",
      "Irina Blok",
      "Ganesh Poomal Girirajan",
      "Roee Aharoni",
      "Benigno Uria",
      "Andrei Sozanschi",
      "Dan Goldberg",
      "Lucian Ionita",
      "Marco Tulio Ribeiro",
      "Martin Zlocha",
      "Vighnesh Birodkar",
      "Sami Lachgar",
      "Liangzhe Yuan",
      "Himadri Choudhury",
      "Matt Ginsberg",
      "Fei Zheng",
      "Gregory Dibb",
      "Emily Graves",
      "Swachhand Lokhande",
      "Gabriel Rasskin",
      "George-Cristian Muraru",
      "Corbin Quick",
      "Sandeep Tata",
      "Pierre Sermanet",
      "Aditya Chawla",
      "Itay Karo",
      "Yan Wang",
      "Susan Zhang",
      "Orgad Keller",
      "Anca Dragan",
      "Guolong Su",
      "Ian Chou",
      "Xi Liu",
      "Yiqing Tao",
      "Shruthi Prabhakara",
      "Marc Wilson",
      "Ruibo Liu",
      "Shibo Wang",
      "Georgie Evans",
      "David Du",
      "Alfonso Casta\u00f1o",
      "Gautam Prasad",
      "Mona El Mahdy",
      "Sebastian Gerlach",
      "Machel Reid",
      "Jarrod Kahn",
      "Amir Zait",
      "Thanumalayan Sankaranarayana Pillai",
      "Thatcher Ulrich",
      "Guanyu Wang",
      "Jan Wassenberg",
      "Efrat Farkash",
      "Kiran Yalasangi",
      "Congchao Wang",
      "Maria Bauza",
      "Simon Bucher",
      "Ting Liu",
      "Jun Yan",
      "Gary Leung",
      "Vikas Sindhwani",
      "Parker Barnes",
      "Avi Singh",
      "Ivan Jurin",
      "Jichuan Chang",
      "Niket Kumar Bhumihar",
      "Sivan Eiger",
      "Gui Citovsky",
      "Ben Withbroe",
      "Zhang Li",
      "Siyang Xue",
      "Niccol\u00f2 Dal Santo",
      "Georgi Stoyanov",
      "Yves Raimond",
      "Steven Zheng",
      "Yilin Gao",
      "V\u00edt List\u00edk",
      "S\u0142awek Kwasiborski",
      "Rachel Saputro",
      "Adnan Ozturel",
      "Ganesh Mallya",
      "Kushal Majmundar",
      "Ross West",
      "Paul Caron",
      "Jinliang Wei",
      "Lluis Castrejon",
      "Sharad Vikram",
      "Deepak Ramachandran",
      "Nikhil Dhawan",
      "Jiho Park",
      "Sara Smoot",
      "George van den Driessche",
      "Yochai Blau",
      "Chase Malik",
      "Wei Liang",
      "Roy Hirsch",
      "Cicero Nogueira dos Santos",
      "Eugene Weinstein",
      "A\u00e4ron van den Oord",
      "Sid Lall",
      "Nicholas FitzGerald",
      "Zixuan Jiang",
      "Xuan Yang",
      "Dale Webster",
      "Ali Elqursh",
      "Aedan Pope",
      "Georges Rotival",
      "David Raposo",
      "Wanzheng Zhu",
      "Jeff Dean",
      "Sami Alabed",
      "Dustin Tran",
      "Arushi Gupta",
      "Zach Gleicher",
      "Jessica Austin",
      "Edouard Rosseel",
      "Megh Umekar",
      "Dipanjan Das",
      "Yinghao Sun",
      "Kai Chen",
      "Karolis Misiunas",
      "Xiang Zhou",
      "Yixian Di",
      "Alyssa Loo",
      "Josh Newlan",
      "Bo Li",
      "Vinay Ramasesh",
      "Ying Xu",
      "Alex Chen",
      "Sudeep Gandhe",
      "Radu Soricut",
      "Nikita Gupta",
      "Shuguang Hu",
      "Seliem El-Sayed",
      "Xavier Garcia",
      "Idan Brusilovsky",
      "Pu-Chin Chen",
      "Andrew Bolt",
      "Lu Huang",
      "Alex Gurney",
      "Zhiying Zhang",
      "Alexander Pritzel",
      "Jarek Wilkiewicz",
      "Bryan Seybold",
      "Bhargav Kanagal Shamanna",
      "Felix Fischer",
      "Josef Dean",
      "Karan Gill",
      "Ross Mcilroy",
      "Abhishek Bhowmick",
      "Jeremy Selier",
      "Antoine Yang",
      "Derek Cheng",
      "Vladimir Magay",
      "Jie Tan",
      "Dhriti Varma",
      "Christian Walder",
      "Tomas Kocisky",
      "Ryo Nakashima",
      "Paul Natsev",
      "Mike Kwong",
      "Ionel Gog",
      "Chiyuan Zhang",
      "Sander Dieleman",
      "Thomas Jimma",
      "Andrey Ryabtsev",
      "Siddhartha Brahma",
      "David Steiner",
      "Dayou Du",
      "Ante \u017du\u017eul",
      "Mislav \u017dani\u0107",
      "Mukund Raghavachari",
      "Willi Gierke",
      "Zeyu Zheng",
      "Dessie Petrova",
      "Yann Dauphin",
      "Yuchuan Liu",
      "Ido Kessler",
      "Steven Hand",
      "Chris Duvarney",
      "Seokhwan Kim",
      "Hyo Lee",
      "L\u00e9onard Hussenot",
      "Jeffrey Hui",
      "Josh Smith",
      "Deepali Jain",
      "Jiawei Xia",
      "Gaurav Singh Tomar",
      "Keyvan Amiri",
      "Du Phan",
      "Fabian Fuchs",
      "Tobias Weyand",
      "Nenad Tomasev",
      "Alexandra Cordell",
      "Xin Liu",
      "Jonathan Mallinson",
      "Pankaj Joshi",
      "Andy Crawford",
      "Arun Suggala",
      "Steve Chien",
      "Nick Fernando",
      "Mariella Sanchez-Vargas",
      "Duncan Williams",
      "Phil Crone",
      "Xiyang Luo",
      "Igor Karpov",
      "Jyn Shan",
      "Terry Thurk",
      "Robin Strudel",
      "Paul Voigtlaender",
      "Piyush Patil",
      "Tim Dozat",
      "Ali Khodaei",
      "Sahil Singla",
      "Piotr Ambroszczyk",
      "Qiyin Wu",
      "Yifan Chang",
      "Brian Roark",
      "Chaitra Hegde",
      "Tianli Ding",
      "Angelos Filos",
      "Zhongru Wu",
      "Andr\u00e9 Susano Pinto",
      "Shuang Liu",
      "Saarthak Khanna",
      "Aditya Pandey",
      "Siobhan Mcloughlin",
      "Qiujia Li",
      "Sam Haves",
      "Allan Zhou",
      "Elena Buchatskaya",
      "Isabel Leal",
      "Peter de Boursac",
      "Nami Akazawa",
      "Nina Anderson",
      "Terry Chen",
      "Krishna Somandepalli",
      "Chen Liang",
      "Sheela Goenka",
      "Stephanie Winkler",
      "Alexander Grushetsky",
      "Yifan Ding",
      "Jamie Smith",
      "Fan Ye",
      "Jordi Pont-Tuset",
      "Eric Li",
      "Ruichao Li",
      "Tomer Golany",
      "Dawid Wegner",
      "Tao Jiang",
      "Omer Barak",
      "Yuan Shangguan",
      "Eszter V\u00e9rtes",
      "Renee Wong",
      "J\u00f6rg Bornschein",
      "Alex Tudor",
      "Michele Bevilacqua",
      "Tom Schaul",
      "Ankit Singh Rawat",
      "Yang Zhao",
      "Kyriakos Axiotis",
      "Lei Meng",
      "Cory McLean",
      "Jonathan Lai",
      "Jennifer Beattie",
      "Nate Kushman",
      "Yaxin Liu",
      "Blair Kutzman",
      "Fiona Lang",
      "Jingchen Ye",
      "Praneeth Netrapalli",
      "Pushkar Mishra",
      "Myriam Khan",
      "Megha Goel",
      "Rob Willoughby",
      "David Tian",
      "Honglei Zhuang",
      "JD Chen",
      "Zak Tsai",
      "Tasos Kementsietsidis",
      "Arjun Khare",
      "James Keeling",
      "Keyang Xu",
      "Nathan Waters",
      "Florent Altch\u00e9",
      "Ashok Popat",
      "Bhavishya Mittal",
      "David Saxton",
      "Dalia El Badawy",
      "Michael Mathieu",
      "Zheng Zheng",
      "Hao Zhou",
      "Nishant Ranka",
      "Richard Shin",
      "Qingnan Duan",
      "Tim Salimans",
      "Ioana Mihailescu",
      "Uri Shaham",
      "Ming-Wei Chang",
      "Yannis Assael",
      "Nishanth Dikkala",
      "Martin Izzard",
      "Vincent Cohen-Addad",
      "Cat Graves",
      "Vlad Feinberg",
      "Grace Chung",
      "DJ Strouse",
      "Danny Karmon",
      "Sahand Sharifzadeh",
      "Zoe Ashwood",
      "Khiem Pham",
      "Jon Blanton",
      "Alex Vasiloff",
      "Jarred Barber",
      "Mark Geller",
      "Aurick Zhou",
      "Fedir Zubach",
      "Tzu-Kuo Huang",
      "Lei Zhang",
      "Himanshu Gupta",
      "Matt Young",
      "Julia Proskurnia",
      "Ronny Votel",
      "Valentin Gabeur",
      "Gabriel Barcik",
      "Aditya Tripathi",
      "Hongkun Yu",
      "Geng Yan",
      "Beer Changpinyo",
      "Filip Paveti\u0107",
      "Amy Coyle",
      "Yasuhisa Fujii",
      "Jorge Gonzalez Mendez",
      "Tianhao Zhou",
      "Harish Rajamani",
      "Blake Hechtman",
      "Eddie Cao",
      "Da-Cheng Juan",
      "Yi-Xuan Tan",
      "Valentin Dalibard",
      "Yilun Du",
      "Natalie Clay",
      "Kaisheng Yao",
      "Wenhao Jia",
      "Dimple Vijaykumar",
      "Yuxiang Zhou",
      "Xinyi Bai",
      "Wei-Chih Hung",
      "Steven Pecht",
      "Georgi Todorov",
      "Nikhil Khadke",
      "Pramod Gupta",
      "Preethi Lahoti",
      "Arnaud Autef",
      "Karthik Duddu",
      "James Lee-Thorp",
      "Alexander Bykovsky",
      "Tautvydas Misiunas",
      "Sebastian Flennerhag",
      "Santhosh Thangaraj",
      "Jed McGiffin",
      "Zack Nado",
      "Markus Kunesch",
      "Andreas Noever",
      "Amir Hertz",
      "Marco Liang",
      "Victor Stone",
      "Evan Palmer",
      "Samira Daruki",
      "Arijit Pramanik",
      "Siim P\u00f5der",
      "Austin Kyker",
      "Mina Khan",
      "Evgeny Sluzhaev",
      "Marvin Ritter",
      "Avraham Ruderman",
      "Wenlei Zhou",
      "Chirag Nagpal",
      "Kiran Vodrahalli",
      "George Necula",
      "Paul Barham",
      "Ellie Pavlick",
      "Jay Hartford",
      "Izhak Shafran",
      "Long Zhao",
      "Maciej Miku\u0142a",
      "Tom Eccles",
      "Hidetoshi Shimokawa",
      "Kanav Garg",
      "Luke Vilnis",
      "Hanwen Chen",
      "Ilia Shumailov",
      "Kuang-Huei Lee",
      "Abdelrahman Abdelhamed",
      "Meiyan Xie",
      "Vered Cohen",
      "Ester Hlavnova",
      "Dan Malkin",
      "Chawin Sitawarin",
      "James Lottes",
      "Pauline Coquinot",
      "Tianli Yu",
      "Sandeep Kumar",
      "Jingwei Zhang",
      "Aroma Mahendru",
      "Zafarali Ahmed",
      "James Martens",
      "Tao Chen",
      "Aviel Boag",
      "Daiyi Peng",
      "Coline Devin",
      "Arseniy Klimovskiy",
      "Mary Phuong",
      "Danny Vainstein",
      "Jin Xie",
      "Bhuvana Ramabhadran",
      "Nathan Howard",
      "Xinxin Yu",
      "Gitartha Goswami",
      "Jingyu Cui",
      "Sam Shleifer",
      "Mario Pinto",
      "Chih-Kuan Yeh",
      "Ming-Hsuan Yang",
      "Sara Javanmardi",
      "Dan Ethier",
      "Chace Lee",
      "Jordi Orbay",
      "Suyog Kotecha",
      "Carla Bromberg",
      "Pete Shaw",
      "James Thornton",
      "Adi Gerzi Rosenthal",
      "Shane Gu",
      "Matt Thomas",
      "Ian Gemp",
      "Aditya Ayyar",
      "Asahi Ushio",
      "Aarush Selvan",
      "Joel Wee",
      "Chenxi Liu",
      "Maryam Majzoubi",
      "Weiren Yu",
      "Jake Abernethy",
      "Tyler Liechty",
      "Renke Pan",
      "Hoang Nguyen",
      "Qiong",
      "Hu",
      "Sarah Perrin",
      "Abhinav Arora",
      "Emily Pitler",
      "Weiyi Wang",
      "Kaushik Shivakumar",
      "Flavien Prost",
      "Ben Limonchik",
      "Jing Wang",
      "Yi Gao",
      "Timothee Cour",
      "Shyamal Buch",
      "Huan Gui",
      "Maria Ivanova",
      "Philipp Neubeck",
      "Kelvin Chan",
      "Lucy Kim",
      "Huizhong Chen",
      "Naman Goyal",
      "Da-Woon Chung",
      "Lu Liu",
      "Yao Su",
      "Anastasia Petrushkina",
      "Jiajun Shen",
      "Armand Joulin",
      "Yuanzhong Xu",
      "Stein Xudong Lin",
      "Yana Kulizhskaya",
      "Ciprian Chelba",
      "Shobha Vasudevan",
      "Eli Collins",
      "Vasilisa Bashlovkina",
      "Tony Lu",
      "Doug Fritz",
      "Jongbin Park",
      "Yanqi Zhou",
      "Chen Su",
      "Richard Tanburn",
      "Mikhail Sushkov",
      "Mitchelle Rasquinha",
      "Jinning Li",
      "Jennifer Prendki",
      "Yiming Li",
      "Pallavi LV",
      "Shriya Sharma",
      "Hen Fitoussi",
      "Hui Huang",
      "Andrew Dai",
      "Phuong Dao",
      "Mike Burrows",
      "Henry Prior",
      "Danfeng Qin",
      "Golan Pundak",
      "Lars Lowe Sjoesund",
      "Art Khurshudov",
      "Zhenkai Zhu",
      "Albert Webson",
      "Elizabeth Kemp",
      "Tat Tan",
      "Saurabh Agrawal",
      "Susie Sargsyan",
      "Liqun Cheng",
      "Jim Stephan",
      "Tom Kwiatkowski",
      "David Reid",
      "Arunkumar Byravan",
      "Assaf Hurwitz Michaely",
      "Nicolas Heess",
      "Luowei Zhou",
      "Sonam Goenka",
      "Viral Carpenter",
      "Anselm Levskaya",
      "Bo Wang",
      "Reed Roberts",
      "R\u00e9mi Leblond",
      "Sharat Chikkerur",
      "Stav Ginzburg",
      "Max Chang",
      "Robert Riachi",
      "Chuqiao",
      "Xu",
      "Zal\u00e1n Borsos",
      "Michael Pliskin",
      "Julia Pawar",
      "Morgane Lustman",
      "Hannah Kirkwood",
      "Ankit Anand",
      "Aditi Chaudhary",
      "Norbert Kalb",
      "Kieran Milan",
      "Sean Augenstein",
      "Anna Goldie",
      "Laurel Prince",
      "Karthik Raman",
      "Yanhua Sun",
      "Vivian Xia",
      "Aaron Cohen",
      "Zhouyuan Huo",
      "Josh Camp",
      "Seher Ellis",
      "Lukas Zilka",
      "David Vilar Torres",
      "Lisa Patel",
      "Sho Arora",
      "Betty Chan",
      "Jonas Adler",
      "Kareem Ayoub",
      "Jacky Liang",
      "Fayaz Jamil",
      "Jiepu Jiang",
      "Simon Baumgartner",
      "Haitian Sun",
      "Yael Karov",
      "Yaroslav Akulov",
      "Hui Zheng",
      "Irene Cai",
      "Claudio Fantacci",
      "James Rubin",
      "Alex Rav Acha",
      "Mengchao Wang",
      "Nina D'Souza",
      "Rohit Sathyanarayana",
      "Shengyang Dai",
      "Simon Rowe",
      "Andrey Simanovsky",
      "Omer Goldman",
      "Yuheng Kuang",
      "Xiaoyue Pan",
      "Andrew Rosenberg",
      "Tania Rojas-Esponda",
      "Praneet Dutta",
      "Amy Zeng",
      "Irina Jurenka",
      "Greg Farquhar",
      "Yamini Bansal",
      "Shariq Iqbal",
      "Becca Roelofs",
      "Ga-Young Joung",
      "Parker Beak",
      "Changwan Ryu",
      "Ryan Poplin",
      "Yan Wu",
      "Jean-Baptiste Alayrac",
      "Senaka Buthpitiya",
      "Olaf Ronneberger",
      "Caleb Habtegebriel",
      "Wei Li",
      "Paul Cavallaro",
      "Aurora Wei",
      "Guy Bensky",
      "Timo Denk",
      "Harish Ganapathy",
      "Jeff Stanway",
      "Pratik Joshi",
      "Francesco Bertolini",
      "Jessica Lo",
      "Olivia Ma",
      "Zachary Charles",
      "Geta Sampemane",
      "Himanshu Sahni",
      "Xu Chen",
      "Harry Askham",
      "David Gaddy",
      "Peter Young",
      "Jiewen Tan",
      "Matan Eyal",
      "Arthur Bra\u017einskas",
      "Li Zhong",
      "Zhichun Wu",
      "Mark Epstein",
      "Kai Bailey",
      "Andrew Hard",
      "Kamyu Lee",
      "Sasha Goldshtein",
      "Alex Ruiz",
      "Mohammed Badawi",
      "Matthias Lochbrunner",
      "JK Kearns",
      "Ashley Brown",
      "Fabio Pardo",
      "Theophane Weber",
      "Haichuan Yang",
      "Pan-Pan Jiang",
      "Berkin Akin",
      "Zhao Fu",
      "Marcus Wainwright",
      "Chi Zou",
      "Meenu Gaba",
      "Pierre-Antoine Manzagol",
      "Wendy Kan",
      "Yang Song",
      "Karina Zainullina",
      "Rui Lin",
      "Jeongwoo Ko",
      "Salil Deshmukh",
      "Apoorv Jindal",
      "James Svensson",
      "Divya Tyam",
      "Heri Zhao",
      "Christine Kaeser-Chen",
      "Scott Baird",
      "Pooya Moradi",
      "Jamie Hall",
      "Qiuchen Guo",
      "Vincent Tsang",
      "Bowen Liang",
      "Fernando Pereira",
      "Suhas Ganesh",
      "Ivan Korotkov",
      "Jakub Adamek",
      "Sridhar Thiagarajan",
      "Vinh Tran",
      "Charles Chen",
      "Chris Tar",
      "Sanil Jain",
      "Ishita Dasgupta",
      "Taylan Bilal",
      "David Reitter",
      "Kai Zhao",
      "Giulia Vezzani",
      "Yasmin Gehman",
      "Pulkit Mehta",
      "Lauren Beltrone",
      "Xerxes Dotiwalla",
      "Sergio Guadarrama",
      "Zaheer Abbas",
      "Stefani Karp",
      "Petko Georgiev",
      "Chun-Sung Ferng",
      "Marc Brockschmidt",
      "Liqian Peng",
      "Christoph Hirnschall",
      "Vikas Verma",
      "Yingying Bi",
      "Ying Xiao",
      "Avigail Dabush",
      "Kelvin Xu",
      "Phil Wallis",
      "Randall Parker",
      "Qifei Wang",
      "Yang Xu",
      "Ilkin Safarli",
      "Dinesh Tewari",
      "Yin Zhang",
      "Seungyeon Kim",
      "Andrea Gesmundo",
      "Mackenzie Thomas",
      "Sergey Levi",
      "Ahmed Chowdhury",
      "Kanishka Rao",
      "Peter Garst",
      "Sam Conway-Rahman",
      "Helen Ran",
      "Kay McKinney",
      "Zhisheng Xiao",
      "Wenhao Yu",
      "Rohan Agrawal",
      "Axel Stjerngren",
      "Catalin Ionescu",
      "Jingjing Chen",
      "Vivek Sharma",
      "Justin Chiu",
      "Fei Liu",
      "Ken Franko",
      "Clayton Sanford",
      "Xingyu Cai",
      "Paul Michel",
      "Sanjay Ganapathy",
      "Jane Labanowski",
      "Zachary Garrett",
      "Ben Vargas",
      "Sean Sun",
      "Bryan Gale",
      "Thomas Buschmann",
      "Guillaume Desjardins",
      "Nimesh Ghelani",
      "Palak Jain",
      "Mudit Verma",
      "Chulayuth Asawaroengchai",
      "Julian Eisenschlos",
      "Jitendra Harlalka",
      "Hideto Kazawa",
      "Don Metzler",
      "Joshua Howland",
      "Ying Jian",
      "Jake Ades",
      "Viral Shah",
      "Tynan Gangwani",
      "Seungji Lee",
      "Roman Ring",
      "Steven M. Hernandez",
      "Dean Reich",
      "Amer Sinha",
      "Ashutosh Sathe",
      "Joe Kovac",
      "Ashleah Gill",
      "Ajay Kannan",
      "Andrea D'olimpio",
      "Martin Sevenich",
      "Jay Whang",
      "Been Kim",
      "Khe Chai Sim",
      "Jilin Chen",
      "Jiageng Zhang",
      "Shuba Lall",
      "Yossi Matias",
      "Bill Jia",
      "Abe Friesen",
      "Sara Nasso",
      "Ashish Thapliyal",
      "Bryan Perozzi",
      "Ting Yu",
      "Anna Shekhawat",
      "Safeen Huda",
      "Peter Grabowski",
      "Eric Wang",
      "Ashwin Sreevatsa",
      "Hilal Dib",
      "Mehadi Hassen",
      "Parker Schuh",
      "Vedrana Milutinovic",
      "Chris Welty",
      "Michael Quinn",
      "Ali Shah",
      "Bangju Wang",
      "Gabe Barth-Maron",
      "Justin Frye",
      "Natalie Axelsson",
      "Tao Zhu",
      "Yukun Ma",
      "Irene Giannoumis",
      "Hanie Sedghi",
      "Chang Ye",
      "Yi Luan",
      "Kevin Aydin",
      "Bilva Chandra",
      "Vivek Sampathkumar",
      "Ronny Huang",
      "Victor Lavrenko",
      "Ahmed Eleryan",
      "Zhi Hong",
      "Steven Hansen",
      "Sara Mc Carthy",
      "Bidisha Samanta",
      "Domagoj \u0106evid",
      "Xin Wang",
      "Fangtao Li",
      "Michael Voznesensky",
      "Matt Hoffman",
      "Andreas Terzis",
      "Vikash Sehwag",
      "Gil Fidel",
      "Luheng He",
      "Mu Cai",
      "Yanzhang He",
      "Alex Feng",
      "Martin Nikoltchev",
      "Samrat Phatale",
      "Jason Chase",
      "Rory Lawton",
      "Ming Zhang",
      "Tom Ouyang",
      "Manuel Tragut",
      "Mehdi Hafezi Manshadi",
      "Arjun Narayanan",
      "Jiaming Shen",
      "Xu Gao",
      "Tolga Bolukbasi",
      "Nick Roy",
      "Xin Li",
      "Daniel Golovin",
      "Liviu Panait",
      "Zhen Qin",
      "Guangxing Han",
      "Thomas Anthony",
      "Sneha Kudugunta",
      "Viorica Patraucean",
      "Aniket Ray",
      "Xinyun Chen",
      "Xiaochen Yang",
      "Tanuj Bhatia",
      "Pranav Talluri",
      "Alex Morris",
      "Andrija Ra\u017enatovi\u0107",
      "Bethanie Brownfield",
      "James An",
      "Sheng Peng",
      "Patrick Kane",
      "Ce Zheng",
      "Nico Duduta",
      "Joshua Kessinger",
      "James Noraky",
      "Siqi Liu",
      "Keran Rong",
      "Petar Veli\u010dkovi\u0107",
      "Keith Rush",
      "Alex Goldin",
      "Fanny Wei",
      "Shiva Mohan Reddy Garlapati",
      "Caroline Pantofaru",
      "Okwan Kwon",
      "Jianmo Ni",
      "Eric Noland",
      "Julia Di Trapani",
      "Fran\u00e7oise Beaufays",
      "Abhijit Guha Roy",
      "Yinlam Chow",
      "Aybuke Turker",
      "Geoffrey Cideron",
      "Lantao Mei",
      "Jon Clark",
      "Qingyun Dou",
      "Matko Bo\u0161njak",
      "Ralph Leith",
      "Yuqing Du",
      "Amir Yazdanbakhsh",
      "Milad Nasr",
      "Chester Kwak",
      "Suraj Satishkumar Sheth",
      "Alex Kaskasoli",
      "Ankesh Anand",
      "Balaji Lakshminarayanan",
      "Sammy Jerome",
      "David Bieber",
      "Chun-Te Chu",
      "Alexandre Senges",
      "Tianxiao Shen",
      "Mukund Sridhar",
      "Ndaba Ndebele",
      "Benjamin Beyret",
      "Shakir Mohamed",
      "Mia Chen",
      "Markus Freitag",
      "Jiaxian Guo",
      "Luyang Liu",
      "Paul Roit",
      "Heng Chen",
      "Shen Yan",
      "Tom Stone",
      "JD Co-Reyes",
      "Jeremy Cole",
      "Salvatore Scellato",
      "Shekoofeh Azizi",
      "Hadi Hashemi",
      "Alicia Jin",
      "Anand Iyer",
      "Marcella Valentine",
      "Andr\u00e1s Gy\u00f6rgy",
      "Arun Ahuja",
      "Daniel Hernandez Diaz",
      "Chen-Yu Lee",
      "Nathan Clement",
      "Weize Kong",
      "Drew Garmon",
      "Ishaan Watts",
      "Kush Bhatia",
      "Khyatti Gupta",
      "Matt Miecnikowski",
      "Hugo Vallet",
      "Ankur Taly",
      "Edward Loper",
      "Saket Joshi",
      "James Atwood",
      "Jo Chick",
      "Mark Collier",
      "Fotis Iliopoulos",
      "Ryan Trostle",
      "Beliz Gunel",
      "Ramiro Leal-Cavazos",
      "Arnar Mar Hrafnkelsson",
      "Michael Guzman",
      "Xiaoen Ju",
      "Andy Forbes",
      "Jesse Emond",
      "Kushal Chauhan",
      "Ben Caine",
      "Li Xiao",
      "Wenjun Zeng",
      "Alexandre Moufarek",
      "Daniel Murphy",
      "Maya Meng",
      "Nitish Gupta",
      "Felix Riedel",
      "Anil Das",
      "Elijah Lawal",
      "Shashi Narayan",
      "Tiberiu Sosea",
      "James Swirhun",
      "Linda Friso",
      "Behnam Neyshabur",
      "Jing Lu",
      "Sertan Girgin",
      "Michael Wunder",
      "Edouard Yvinec",
      "Aroonalok Pyne",
      "Victor Carbune",
      "Shruti Rijhwani",
      "Yang Guo",
      "Tulsee Doshi",
      "Anton Briukhov",
      "Max Bain",
      "Ayal Hitron",
      "Xuanhui Wang",
      "Ashish Gupta",
      "Ke Chen",
      "Cosmo Du",
      "Weiyang Zhang",
      "Dhruv Shah",
      "Arjun Akula",
      "Max Dylla",
      "Ashyana Kachra",
      "Weicheng Kuo",
      "Tingting Zou",
      "Lily Wang",
      "Luyao Xu",
      "Jifan Zhu",
      "Justin Snyder",
      "Sachit Menon",
      "Orhan Firat",
      "Igor Mordatch",
      "Yuan Yuan",
      "Natalia Ponomareva",
      "Rory Blevins",
      "Lawrence Moore",
      "Weijun Wang",
      "Phil Chen",
      "Martin Scholz",
      "Artur Dwornik",
      "Jason Lin",
      "Sicheng Li",
      "Diego Antognini",
      "Te I",
      "Xiaodan Song",
      "Matt Miller",
      "Uday Kalra",
      "Adam Raveret",
      "Oscar Akerlund",
      "Felix Wu",
      "Andrew Nystrom",
      "Namrata Godbole",
      "Tianqi Liu",
      "Hannah DeBalsi",
      "Jewel Zhao",
      "Buhuang Liu",
      "Avi Caciularu",
      "Lauren Lax",
      "Urvashi Khandelwal",
      "Victoria Langston",
      "Eric Bailey",
      "Silvio Lattanzi",
      "Yufei Wang",
      "Neel Kovelamudi",
      "Sneha Mondal",
      "Guru Guruganesh",
      "Nan Hua",
      "Ofir Roval",
      "Pawe\u0142 Weso\u0142owski",
      "Rishikesh Ingale",
      "Jonathan Halcrow",
      "Tim Sohn",
      "Christof Angermueller",
      "Bahram Raad",
      "Eli Stickgold",
      "Eva Lu",
      "Alec Kosik",
      "Jing Xie",
      "Timothy Lillicrap",
      "Austin Huang",
      "Lydia Lihui Zhang",
      "Dominik Paulus",
      "Clement Farabet",
      "Alex Wertheim",
      "Bing Wang",
      "Rishabh Joshi",
      "Chu-ling Ko",
      "Yonghui Wu",
      "Shubham Agrawal",
      "Lily Lin",
      "XiangHai Sheng",
      "Peter Sung",
      "Tyler Breland-King",
      "Christina Butterfield",
      "Swapnil Gawde",
      "Sumeet Singh",
      "Qiao Zhang",
      "Raj Apte",
      "Shilpa Shetty",
      "Adrian Hutter",
      "Tao Li",
      "Elizabeth Salesky",
      "Federico Lebron",
      "Jonni Kanerva",
      "Michela Paganini",
      "Arthur Nguyen",
      "Rohith Vallu",
      "Jan-Thorsten Peter",
      "Sarmishta Velury",
      "David Kao",
      "Jay Hoover",
      "Anna Bortsova",
      "Colton Bishop",
      "Shoshana Jakobovits",
      "Alessandro Agostini",
      "Alekh Agarwal",
      "Chang Liu",
      "Charles Kwong",
      "Sasan Tavakkol",
      "Ioana Bica",
      "Alex Greve",
      "Anirudh GP",
      "Jake Marcus",
      "Le Hou",
      "Tom Duerig",
      "Rivka Moroshko",
      "Dave Lacey",
      "Andy Davis",
      "Julien Amelot",
      "Guohui Wang",
      "Frank Kim",
      "Theofilos Strinopoulos",
      "Hui Wan",
      "Charline Le Lan",
      "Shankar Krishnan",
      "Haotian Tang",
      "Peter Humphreys",
      "Junwen Bai",
      "Idan Heimlich Shtacher",
      "Diego Machado",
      "Chenxi Pang",
      "Ken Burke",
      "Dangyi Liu",
      "Renga Aravamudhan",
      "Yue Song",
      "Ed Hirst",
      "Abhimanyu Singh",
      "Brendan Jou",
      "Liang Bai",
      "Francesco Piccinno",
      "Chuyuan Kelly Fu",
      "Robin Alazard",
      "Barak Meiri",
      "Daniel Winter",
      "Charlie Chen",
      "Mingda Zhang",
      "Jens Heitkaemper",
      "John Lambert",
      "Jinhyuk Lee",
      "Alexander Fr\u00f6mmgen",
      "Sergey Rogulenko",
      "Pranav Nair",
      "Paul Niemczyk",
      "Anton Bulyenov",
      "Bibo Xu",
      "Hadar Shemtov",
      "Morteza Zadimoghaddam",
      "Serge Toropov",
      "Mateo Wirth",
      "Hanjun Dai",
      "Sreenivas Gollapudi",
      "Daniel Zheng",
      "Alex Kurakin",
      "Chansoo Lee",
      "Kalesha Bullard",
      "Nicolas Serrano",
      "Ivana Balazevic",
      "Yang Li",
      "Johan Schalkwyk",
      "Mark Murphy",
      "Mingyang Zhang",
      "Kevin Sequeira",
      "Romina Datta",
      "Nishant Agrawal",
      "Charles Sutton",
      "Nithya Attaluri",
      "Mencher Chiang",
      "Wael Farhan",
      "Gregory Thornton",
      "Kate Lin",
      "Travis Choma",
      "Hung Nguyen",
      "Kingshuk Dasgupta",
      "Dirk Robinson",
      "Iulia Com\u015fa",
      "Michael Riley",
      "Arjun Pillai",
      "Basil Mustafa",
      "Ben Golan",
      "Amir Zandieh",
      "Jean-Baptiste Lespiau",
      "Billy Porter",
      "David Ross",
      "Sujeevan Rajayogam",
      "Mohit Agarwal",
      "Subhashini Venugopalan",
      "Bobak Shahriari",
      "Qiqi Yan",
      "Hao Xu",
      "Taylor Tobin",
      "Pavel Dubov",
      "Hongzhi Shi",
      "Adri\u00e0 Recasens",
      "Anton Kovsharov",
      "Sebastian Borgeaud",
      "Lucio Dery",
      "Shanthal Vasanth",
      "Elena Gribovskaya",
      "Linhai Qiu",
      "Mahdis Mahdieh",
      "Wojtek Skut",
      "Elizabeth Nielsen",
      "CJ Zheng",
      "Adams Yu",
      "Carrie Grimes Bostock",
      "Shaleen Gupta",
      "Aaron Archer",
      "Chris Rawles",
      "Elinor Davies",
      "Alexey Svyatkovskiy",
      "Tomy Tsai",
      "Yoni Halpern",
      "Christian Reisswig",
      "Bartek Wydrowski",
      "Bo Chang",
      "Joan Puigcerver",
      "Mor Hazan Taege",
      "Jian Li",
      "Eva Schnider",
      "Xinjian Li",
      "Dragos Dena",
      "Yunhan Xu",
      "Umesh Telang",
      "Tianze Shi",
      "Heiga Zen",
      "Kyle Kastner",
      "Yeongil Ko",
      "Neesha Subramaniam",
      "Aviral Kumar",
      "Pete Blois",
      "Zhuyun Dai",
      "John Wieting",
      "Yifeng Lu",
      "Yoel Zeldes",
      "Tian Xie",
      "Anja Hauth",
      "Alexandru \u0162ifrea",
      "Yuqi Li",
      "Sam El-Husseini",
      "Dan Abolafia",
      "Howard Zhou",
      "Wen Ding",
      "Sahra Ghalebikesabi",
      "Carlos Gu\u00eda",
      "Andrii Maksai",
      "\u00c1goston Weisz",
      "Sercan Arik",
      "Nick Sukhanov",
      "Aga \u015awietlik",
      "Xuhui Jia",
      "Luo Yu",
      "Weiyue Wang",
      "Mark Brand",
      "Dawn Bloxwich",
      "Sean Kirmani",
      "Zhe Chen",
      "Alec Go",
      "Pablo Sprechmann",
      "Nithish Kannen",
      "Alen Carin",
      "Paramjit Sandhu",
      "Isabel Edkins",
      "Leslie Nooteboom",
      "Jai Gupta",
      "Loren Maggiore",
      "Javad Azizi",
      "Yael Pritch",
      "Pengcheng Yin",
      "Mansi Gupta",
      "Danny Tarlow",
      "Duncan Smith",
      "Desi Ivanov",
      "Mohammad Babaeizadeh",
      "Ankita Goel",
      "Satish Kambala",
      "Grace Chu",
      "Matej Kastelic",
      "Michelle Liu",
      "Hagen Soltau",
      "Austin Stone",
      "Shivani Agrawal",
      "Min Kim",
      "Kedar Soparkar",
      "Srinivas Tadepalli",
      "Oskar Bunyan",
      "Rachel Soh",
      "Arvind Kannan",
      "DY Kim",
      "Blake JianHang Chen",
      "Afief Halumi",
      "Sudeshna Roy",
      "Yulong Wang",
      "Olcan Sercinoglu",
      "Gena Gibson",
      "Sijal Bhatnagar",
      "Motoki Sano",
      "Daniel von Dincklage",
      "Qingchun Ren",
      "Blagoj Mitrevski",
      "Mirek Ol\u0161\u00e1k",
      "Jennifer She",
      "Carl Doersch",
      "Jilei",
      "Wang",
      "Bingyuan Liu",
      "Qijun Tan",
      "Tamar Yakar",
      "Tris Warkentin",
      "Alex Ramirez",
      "Carl Lebsack",
      "Josh Dillon",
      "Rajiv Mathews",
      "Tom Cobley",
      "Zelin Wu",
      "Zhuoyuan Chen",
      "Jon Simon",
      "Swaroop Nath",
      "Tara Sainath",
      "Alexei Bendebury",
      "Ryan Julian",
      "Bharath Mankalale",
      "Daria \u0106urko",
      "Paulo Zacchello",
      "Adam R. Brown",
      "Kiranbir Sodhia",
      "Heidi Howard",
      "Sergi Caelles",
      "Abhinav Gupta",
      "Gareth Evans",
      "Anna Bulanova",
      "Lesley Katzen",
      "Roman Goldenberg",
      "Anton Tsitsulin",
      "Joe Stanton",
      "Benoit Schillings",
      "Vitaly Kovalev",
      "Corey Fry",
      "Rushin Shah",
      "Kuo Lin",
      "Shyam Upadhyay",
      "Cheng Li",
      "Soroush Radpour",
      "Marcello Maggioni",
      "Jing Xiong",
      "Lukas Haas",
      "Jenny Brennan",
      "Aishwarya Kamath",
      "Nikolay Savinov",
      "Arsha Nagrani",
      "Trevor Yacovone",
      "Ryan Kappedal",
      "Kostas Andriopoulos",
      "Li Lao",
      "YaGuang Li",
      "Grigory Rozhdestvenskiy",
      "Kazuma Hashimoto",
      "Andrew Audibert",
      "Sophia Austin",
      "Daniel Rodriguez",
      "Anian Ruoss",
      "Garrett Honke",
      "Deep Karkhanis",
      "Xi Xiong",
      "Qing Wei",
      "James Huang",
      "Zhaoqi Leng",
      "Vittal Premachandran",
      "Stan Bileschi",
      "Georgios Evangelopoulos",
      "Thomas Mensink",
      "Jay Pavagadhi",
      "Denis Teplyashin",
      "Paul Chang",
      "Linting Xue",
      "Garrett Tanzer",
      "Sally Goldman",
      "Kaushal Patel",
      "Shixin Li",
      "Jeremy Wiesner",
      "Ivy Zheng",
      "Ian Stewart-Binks",
      "Jie Han",
      "Zhi Li",
      "Liangchen Luo",
      "Karel Lenc",
      "Mario Lu\u010di\u0107",
      "Fuzhao Xue",
      "Ryan Mullins",
      "Alexey Guseynov",
      "Chung-Ching Chang",
      "Isaac Galatzer-Levy",
      "Adam Zhang",
      "Garrett Bingham",
      "Grace Hu",
      "Ale Hartman",
      "Yue Ma",
      "Jordan Griffith",
      "Alex Irpan",
      "Carey Radebaugh",
      "Summer Yue",
      "Lijie Fan",
      "Victor Ungureanu",
      "Christina Sorokin",
      "Hannah Teufel",
      "Peiran Li",
      "Rohan Anil",
      "Dimitris Paparas",
      "Todd Wang",
      "Chu-Cheng Lin",
      "Hui Peng",
      "Megan Shum",
      "Goran Petrovic",
      "Demetra Brady",
      "Richard Nguyen",
      "Klaus Macherey",
      "Zhihao Li",
      "Harman Singh",
      "Madhavi Yenugula",
      "Mariko Iinuma",
      "Xinyi Chen",
      "Kavya Kopparapu",
      "Alexey Stern",
      "Shachi Dave",
      "Chandu Thekkath",
      "Florence Perot",
      "Anurag Kumar",
      "Fangda Li",
      "Yang Xiao",
      "Matthew Bilotti",
      "Mohammad Hossein Bateni",
      "Isaac Noble",
      "Lisa Lee",
      "Amelio V\u00e1zquez-Reina",
      "Julian Salazar",
      "Xiaomeng Yang",
      "Boyu Wang",
      "Ela Gruzewska",
      "Anand Rao",
      "Sindhu Raghuram",
      "Zheng Xu",
      "Eyal Ben-David",
      "Jieru Mei",
      "Sid Dalmia",
      "Zhaoyi Zhang",
      "Yuchen Liu",
      "Gagan Bansal",
      "Helena Pankov",
      "Steven Schwarcz",
      "Andrea Burns",
      "Christine Chan",
      "Sumit Sanghai",
      "Ricky Liang",
      "Ethan Liang",
      "Antoine He",
      "Amy Stuart",
      "Arun Narayanan",
      "Yukun Zhu",
      "Christian Frank",
      "Bahar Fatemi",
      "Amit Sabne",
      "Oran Lang",
      "Indro Bhattacharya",
      "Shane Settle",
      "Maria Wang",
      "Brendan McMahan",
      "Andrea Tacchetti",
      "Livio Baldini Soares",
      "Majid Hadian",
      "Serkan Cabi",
      "Timothy Chung",
      "Nikita Putikhin",
      "Gang Li",
      "Jeremy Chen",
      "Austin Tarango",
      "Henryk Michalewski",
      "Mehran Kazemi",
      "Hussain Masoom",
      "Hila Sheftel",
      "Rakesh Shivanna",
      "Archita Vadali",
      "Ramona Comanescu",
      "Doug Reid",
      "Joss Moore",
      "Arvind Neelakantan",
      "Micha\u00ebl Sander",
      "Jonathan Herzig",
      "Aviv Rosenberg",
      "Mostafa Dehghani",
      "JD Choi",
      "Michael Fink",
      "Reid Hayes",
      "Eric Ge",
      "Shitao Weng",
      "Chia-Hua Ho",
      "John Karro",
      "Kalpesh Krishna",
      "Lam Nguyen Thiet",
      "Amy Skerry-Ryan",
      "Daniel Eppens",
      "Marco Andreetto",
      "Navin Sarma",
      "Silvano Bonacina",
      "Burcu Karagol Ayan",
      "Megha Nawhal",
      "Zhihao Shan",
      "Mike Dusenberry",
      "Shantanu Thakoor",
      "Sagar Gubbi",
      "Duc Dung Nguyen",
      "Reut Tsarfaty",
      "Samuel Albanie",
      "Jovana Mitrovi\u0107",
      "Meet Gandhi",
      "Bo-Juen Chen",
      "Alessandro Epasto",
      "Georgi Stephanov",
      "Ye Jin",
      "Samuel Gehman",
      "Aida Amini",
      "Jack Weber",
      "Feryal Behbahani",
      "Shawn Xu",
      "Miltos Allamanis",
      "Xi Chen",
      "Myle Ott",
      "Claire Sha",
      "Michal Jastrzebski",
      "Hang Qi",
      "David Greene",
      "Xinyi Wu",
      "Abodunrinwa Toki",
      "Daniel Vlasic",
      "Jane Shapiro",
      "Ragha Kotikalapudi",
      "Zhe Shen",
      "Takaaki Saeki",
      "Sirui Xie",
      "Albin Cassirer",
      "Shikhar Bharadwaj",
      "Tatsuya Kiyono",
      "Srinadh Bhojanapalli",
      "Elan Rosenfeld",
      "Sam Ritter",
      "Jieming Mao",
      "Jo\u00e3o Gabriel Oliveira",
      "Zoltan Egyed",
      "Bernd Bandemer",
      "Emilio Parisotto",
      "Keisuke Kinoshita",
      "Juliette Pluto",
      "Petros Maniatis",
      "Steve Li",
      "Yaohui Guo",
      "Golnaz Ghiasi",
      "Jean Tarbouriech",
      "Srimon Chatterjee",
      "Julie Jin",
      "Katrina",
      "Xu",
      "Jennimaria Palomaki",
      "S\u00e9b Arnold",
      "Madhavi Sewak",
      "Federico Piccinini",
      "Mohit Sharma",
      "Ben Albrecht",
      "Sean Purser-haskell",
      "Ashwin Vaswani",
      "Chongyan Chen",
      "Matheus Wisniewski",
      "Qin Cao",
      "John Aslanides",
      "Nguyet Minh Phu",
      "Maximilian Sieb",
      "Lauren Agubuzu",
      "Anne Zheng",
      "Daniel Sohn",
      "Marco Selvi",
      "Anders Andreassen",
      "Krishan Subudhi",
      "Prem Eruvbetine",
      "Oliver Woodman",
      "Tomas Mery",
      "Sebastian Krause",
      "Xiaoqi Ren",
      "Xiao Ma",
      "Jincheng Luo",
      "Dawn Chen",
      "Wei Fan",
      "Henry Griffiths",
      "Christian Schuler",
      "Alice Li",
      "Shujian Zhang",
      "Jean-Michel Sarr",
      "Shixin Luo",
      "Riccardo Patana",
      "Matthew Watson",
      "Dani Naboulsi",
      "Michael Collins",
      "Sailesh Sidhwani",
      "Emiel Hoogeboom",
      "Sharon Silver",
      "Emily Caveness",
      "Xiaokai Zhao",
      "Mikel Rodriguez",
      "Maxine Deines",
      "Libin Bai",
      "Patrick Griffin",
      "Marco Tagliasacchi",
      "Emily Xue",
      "Spandana Raj Babbula",
      "Bo Pang",
      "Nan Ding",
      "Gloria Shen",
      "Elijah Peake",
      "Remi Crocker",
      "Shubha Srinivas Raghvendra",
      "Danny Swisher",
      "Woohyun Han",
      "Richa Singh",
      "Ling Wu",
      "Vladimir Pchelin",
      "Tsendsuren Munkhdalai",
      "Dana Alon",
      "Geoff Bacon",
      "Efren Robles",
      "Jannis Bulian",
      "Melvin Johnson",
      "George Powell",
      "Felipe Tiengo Ferreira",
      "Yaoyiran Li",
      "Frederik Benzing",
      "Mihajlo Velimirovi\u0107",
      "Hubert Soyer",
      "William Kong",
      "Tony",
      "Nguy\u00ean",
      "Zhen Yang",
      "Jeremiah Liu",
      "Joost van Amersfoort",
      "Daniel Gillick",
      "Baochen Sun",
      "Nathalie Rauschmayr",
      "Katie Zhang",
      "Serena Zhan",
      "Tao Zhou",
      "Alexey Frolov",
      "Chengrun Yang",
      "Denis Vnukov",
      "Louis Rouillard",
      "Hongji Li",
      "Amol Mandhane",
      "Nova Fallen",
      "Rajesh Venkataraman",
      "Clara Huiyi Hu",
      "Jennifer Brennan",
      "Jenny Lee",
      "Jerry Chang",
      "Martin Sundermeyer",
      "Zhufeng Pan",
      "Rosemary Ke",
      "Simon Tong",
      "Alex Fabrikant",
      "William Bono",
      "Jindong Gu",
      "Ryan Foley",
      "Yiran Mao",
      "Manolis Delakis",
      "Dhruva Bhaswar",
      "Roy Frostig",
      "Nick Li",
      "Avital Zipori",
      "Cath Hope",
      "Olga Kozlova",
      "Swaroop Mishra",
      "Josip Djolonga",
      "Craig Schiff",
      "Majd Al Merey",
      "Eleftheria Briakou",
      "Peter Morgan",
      "Andy Wan",
      "Avinatan Hassidim",
      "RJ Skerry-Ryan",
      "Kuntal Sengupta",
      "Mary Jasarevic",
      "Praveen Kallakuri",
      "Paige Kunkle",
      "Hannah Brennan",
      "Tom Lieber",
      "Hassan Mansoor",
      "Julian Walker",
      "Bing Zhang",
      "Annie Xie",
      "Goran \u017du\u017ei\u0107",
      "Adaeze Chukwuka",
      "Alex Druinsky",
      "Donghyun Cho",
      "Rui Yao",
      "Ferjad Naeem",
      "Shiraz Butt",
      "Eunyoung Kim",
      "Zhipeng Jia",
      "Mandy Jordan",
      "Adam Lelkes",
      "Mark Kurzeja",
      "Sophie Wang",
      "James Zhao",
      "Andrew Over",
      "Abhishek Chakladar",
      "Marcel Prasetya",
      "Neha Jha",
      "Sriram Ganapathy",
      "Yale Cong",
      "Prakash Shroff",
      "Carl Saroufim",
      "Sobhan Miryoosefi",
      "Mohamed Hammad",
      "Tajwar Nasir",
      "Weijuan Xi",
      "Yang Gao",
      "Young Maeng",
      "Ben Hora",
      "Chin-Yi Cheng",
      "Parisa Haghani",
      "Yoad Lewenberg",
      "Caden Lu",
      "Martin Matysiak",
      "Naina Raisinghani",
      "Huiyu Wang",
      "Lexi Baugher",
      "Rahul Sukthankar",
      "Minh Giang",
      "John Schultz",
      "Noah Fiedel",
      "Minmin Chen",
      "Cheng-Chun Lee",
      "Tapomay Dey",
      "Hao Zheng",
      "Shachi Paul",
      "Celine Smith",
      "Andy Ly",
      "Yicheng Wang",
      "Rishabh Bansal",
      "Bartek Perz",
      "Susanna Ricco",
      "Stasha Blank",
      "Vaishakh Keshava",
      "Deepak Sharma",
      "Marvin Chow",
      "Kunal Lad",
      "Komal Jalan",
      "Simon Osindero",
      "Craig Swanson",
      "Jacob Scott",
      "Anastasija Ili\u0107",
      "Xiaowei Li",
      "Siddhartha Reddy Jonnalagadda",
      "Afzal Shama Soudagar",
      "Yan Xiong",
      "Bat-Orgil Batsaikhan",
      "Daniel Jarrett",
      "Naveen Kumar",
      "Maulik Shah",
      "Matt Lawlor",
      "Austin Waters",
      "Mark Graham",
      "Rhys May",
      "Sabela Ramos",
      "Sandra Lefdal",
      "Zeynep Cankara",
      "Nacho Cano",
      "Brendan O'Donoghue",
      "Jed Borovik",
      "Frederick Liu",
      "Jordan Grimstad",
      "Mahmoud Alnahlawi",
      "Katerina Tsihlas",
      "Tom Hudson",
      "Nikolai Grigorev",
      "Yiling Jia",
      "Terry Huang",
      "Tobenna Peter Igwe",
      "Sergei Lebedev",
      "Xiaodan Tang",
      "Igor Krivokon",
      "Frankie Garcia",
      "Melissa Tan",
      "Eric Jia",
      "Peter Stys",
      "Shikhar Vashishth",
      "Yu Liang",
      "Balaji Venkatraman",
      "Chenjie Gu",
      "Anastasios Kementsietsidis",
      "Chen Zhu",
      "Junehyuk Jung",
      "Yunfei Bai",
      "Mohammad Javad Hosseini",
      "Faruk Ahmed",
      "Aditya Gupta",
      "Xin Yuan",
      "Shereen Ashraf",
      "Shitij Nigam",
      "Gautam Vasudevan",
      "Pranjal Awasthi",
      "Adi Mayrav Gilady",
      "Zelda Mariet",
      "Ramy Eskander",
      "Haiguang Li",
      "Hexiang Hu",
      "Guillermo Garrido",
      "Philippe Schlattner",
      "George Zhang",
      "Rohun Saxena",
      "Petar Devi\u0107",
      "Kritika Muralidharan",
      "Ashwin Murthy",
      "Yiqian Zhou",
      "Min Choi",
      "Arissa Wongpanich",
      "Zhengdong Wang",
      "Premal Shah",
      "Yuntao Xu",
      "Yiling Huang",
      "Stephen Spencer",
      "Alice Chen",
      "James Cohan",
      "Junjie Wang",
      "Jonathan Tompson",
      "Junru Wu",
      "Ruba Haroun",
      "Haiqiong Li",
      "Blanca Huergo",
      "Fan Yang",
      "Tongxin Yin",
      "James Wendt",
      "Michael Bendersky",
      "Rahma Chaabouni",
      "Javier Snaider",
      "Johan Ferret",
      "Abhishek Jindal",
      "Tara Thompson",
      "Andrew Xue",
      "Will Bishop",
      "Shubham Milind Phal",
      "Archit Sharma",
      "Yunhsuan Sung",
      "Prabakar Radhakrishnan",
      "Mo Shomrat",
      "Reeve Ingle",
      "Roopali Vij",
      "Justin Gilmer",
      "Mihai Dorin Istin",
      "Sam Sobell",
      "Yang Lu",
      "Emily Nottage",
      "Dorsa Sadigh",
      "Jeremiah Willcock",
      "Tingnan Zhang",
      "Steve Xu",
      "Sasha Brown",
      "Katherine Lee",
      "Gary Wang",
      "Yun Zhu",
      "Yi Tay",
      "Cheolmin Kim",
      "Audrey Gutierrez",
      "Abhanshu Sharma",
      "Yongqin Xian",
      "Sungyong Seo",
      "Claire Cui",
      "Elena Pochernina",
      "Cip Baetu",
      "Krzysztof Jastrz\u0119bski",
      "Mimi Ly",
      "Mohamed Elhawaty",
      "Dan Suh",
      "Eren Sezener",
      "Pidong Wang",
      "Nancy Yuen",
      "George Tucker",
      "Jiahao Cai",
      "Zuguang Yang",
      "Cindy Wang",
      "Alex Muzio",
      "Hai Qian",
      "Jae Yoo",
      "Derek Lockhart",
      "Kevin R. McKee",
      "Mandy Guo",
      "Malika Mehrotra",
      "Artur Mendon\u00e7a",
      "Sanket Vaibhav Mehta",
      "Sherry Ben",
      "Chetan Tekur",
      "Jiaqi Mu",
      "Muye Zhu",
      "Victoria Krakovna",
      "Hongrae Lee",
      "AJ Maschinot",
      "S\u00e9bastien Cevey",
      "HyunJeong Choe",
      "Aijun Bai",
      "Hansa Srinivasan",
      "Derek Gasaway",
      "Nick Young",
      "Patrick Siegler",
      "Dan Holtmann-Rice",
      "Vihari Piratla",
      "Kate Baumli",
      "Roey Yogev",
      "Alex Hofer",
      "Hado van Hasselt",
      "Svetlana Grant",
      "Yuri Chervonyi",
      "David Silver",
      "Andrew Hogue",
      "Ayushi Agarwal",
      "Kathie Wang",
      "Preeti Singh",
      "Four Flynn",
      "Josh Lipschultz",
      "Robert David",
      "Lizzetth Bellot",
      "Yao-Yuan Yang",
      "Long Le",
      "Filippo Graziano",
      "Kate Olszewska",
      "Kevin Hui",
      "Akanksha Maurya",
      "Nikos Parotsidis",
      "Weijie Chen",
      "Tayo Oguntebi",
      "Joe Kelley",
      "Anirudh Baddepudi",
      "Johannes Mauerer",
      "Gregory Shaw",
      "Alex Siegman",
      "Lin Yang",
      "Shravya Shetty",
      "Subhrajit Roy",
      "Yunting Song",
      "Wojciech Stokowiec",
      "Ryan Burnell",
      "Omkar Savant",
      "Robert Busa-Fekete",
      "Jin Miao",
      "Samrat Ghosh",
      "Liam MacDermed",
      "Phillip Lippe",
      "Mikhail Dektiarev",
      "Zach Behrman",
      "Fabian Mentzer",
      "Kelvin Nguyen",
      "Meng Wei",
      "Siddharth Verma",
      "Chris Knutsen",
      "Sudeep Dasari",
      "Zhipeng Yan",
      "Petr Mitrichev",
      "Xingyu Wang",
      "Virat Shejwalkar",
      "Jacob Austin",
      "Srinivas Sunkara",
      "Navneet Potti",
      "Yan Virin",
      "Christian Wright",
      "Ga\u00ebl Liu",
      "Oriana Riva",
      "Etienne Pot",
      "Greg Kochanski",
      "Quoc Le",
      "Gargi Balasubramaniam",
      "Arka Dhar",
      "Yuguo Liao",
      "Adam Bloniarz",
      "Divyansh Shukla",
      "Elizabeth Cole",
      "Jong Lee",
      "Sheng Zhang",
      "Sushant Kafle",
      "Siddharth Vashishtha",
      "Parsa Mahmoudieh",
      "Grace Chen",
      "Raphael Hoffmann",
      "Pranesh Srinivasan",
      "Agustin Dal Lago",
      "Yoav Ben Shalom",
      "Zi Wang",
      "Michael Elabd",
      "Anuj Sharma",
      "Junhyuk Oh",
      "Suraj Kothawade",
      "Maigo Le",
      "Marianne Monteiro",
      "Shentao Yang",
      "Kaiz Alarakyia",
      "Robert Geirhos",
      "Diana Mincu",
      "H\u00e5vard Garnes",
      "Hayato Kobayashi",
      "Soroosh Mariooryad",
      "Kacper Krasowiak",
      "Zhixin",
      "Lai",
      "Shibl Mourad",
      "Mingqiu Wang",
      "Fan Bu",
      "Ophir Aharoni",
      "Guanjie Chen",
      "Abhimanyu Goyal",
      "Vadim Zubov",
      "Ankur Bapna",
      "Elahe Dabir",
      "Nisarg Kothari",
      "Kay Lamerigts",
      "Nicola De Cao",
      "Jeremy Shar",
      "Christopher Yew",
      "Nitish Kulkarni",
      "Dre Mahaarachchi",
      "Mandar Joshi",
      "Zhenhai Zhu",
      "Jared Lichtarge",
      "Yichao Zhou",
      "Hannah Muckenhirn",
      "Vittorio Selo",
      "Oriol Vinyals",
      "Peter Chen",
      "Anthony Brohan",
      "Vaibhav Mehta",
      "Sarah Cogan",
      "Ruth Wang",
      "Ty Geri",
      "Wei-Jen Ko",
      "Wei Chen",
      "Fabio Viola",
      "Keshav Shivam",
      "Lisa Wang",
      "Madeleine Clare Elish",
      "Raluca Ada Popa",
      "S\u00e9bastien Pereira",
      "Jianqiao Liu",
      "Raphael Koster",
      "Donnie Kim",
      "Gufeng Zhang",
      "Sayna Ebrahimi",
      "Partha Talukdar",
      "Yanyan Zheng",
      "Petra Poklukar",
      "Ales Mikhalap",
      "Dale Johnson",
      "Anitha Vijayakumar",
      "Mark Omernick",
      "Matt Dibb",
      "Ayush Dubey",
      "Qiong Hu",
      "Apurv Suman",
      "Vaibhav Aggarwal",
      "Ilya Kornakov",
      "Fei Xia",
      "Wing Lowe",
      "Alexey Kolganov",
      "Ted Xiao",
      "Vitaly Nikolaev",
      "Steven Hemingray",
      "Bonnie Li",
      "Joana Iljazi",
      "Miko\u0142aj Rybi\u0144ski",
      "Ballie Sandhu",
      "Peggy Lu",
      "Thang Luong",
      "Rodolphe Jenatton",
      "Vineetha Govindaraj",
      "Hui",
      "Li",
      "Gabriel Dulac-Arnold",
      "Wonpyo Park",
      "Henry Wang",
      "Abhinit Modi",
      "Jean Pouget-Abadie",
      "Kristina Greller",
      "Rahul Gupta",
      "Robert Berry",
      "Prajit Ramachandran",
      "Jinyu Xie",
      "Liam McCafferty",
      "Jianling Wang",
      "Kilol Gupta",
      "Hyeontaek Lim",
      "Bla\u017e Bratani\u010d",
      "Andy Brock",
      "Ilia Akolzin",
      "Jim Sproch",
      "Dan Karliner",
      "Duhyeon Kim",
      "Adrian Goedeckemeyer",
      "Noam Shazeer",
      "Cordelia Schmid",
      "Daniele Calandriello",
      "Parul Bhatia",
      "Krzysztof Choromanski",
      "Ceslee Montgomery",
      "Dheeru Dua",
      "Ana Ramalho",
      "Helen King",
      "Yue Gao",
      "Lynn Nguyen",
      "David Lindner",
      "Divya Pitta",
      "Oleaser Johnson",
      "Khalid Salama",
      "Diego Ardila",
      "Michael Han",
      "Erin Farnese",
      "Seth Odoom",
      "Ziyue Wang",
      "Xiangzhuo Ding",
      "Norman Rink",
      "Ray Smith",
      "Harshal Tushar Lehri",
      "Eden Cohen",
      "Neera Vats",
      "Tong He",
      "Parthasarathy Gopavarapu",
      "Adam Paszke",
      "Miteyan Patel",
      "Wouter Van Gansbeke",
      "Lucia Loher",
      "Luis Castro",
      "Maria Voitovich",
      "Tamara von Glehn",
      "Nelson George",
      "Simon Niklaus",
      "Zach Eaton-Rosen",
      "Nemanja Raki\u0107evi\u0107",
      "Erik Jue",
      "Sagi Perel",
      "Carrie Zhang",
      "Yuval Bahat",
      "Ang\u00e9line Pouget",
      "Zhi Xing",
      "Fantine Huot",
      "Ashish Shenoy",
      "Taylor Bos",
      "Vincent Coriou",
      "Bryan Richter",
      "Natasha Noy",
      "Yaqing Wang",
      "Santiago Ontanon",
      "Siyang Qin",
      "Gleb Makarchuk",
      "Demis Hassabis",
      "Zhuowan Li",
      "Mandar Sharma",
      "Kumaran Venkatesan",
      "Iurii Kemaev",
      "Roxanne Daniel",
      "Shiyu Huang",
      "Saloni Shah",
      "Octavio Ponce",
      "Warren",
      "Chen",
      "Manaal Faruqui",
      "Jialin Wu",
      "Slavica Anda\u010di\u0107",
      "Szabolcs Payrits",
      "Daniel McDuff",
      "Tom Hume",
      "Yuan Cao",
      "MH Tessler",
      "Qingze Wang",
      "Yinan Wang",
      "Ivor Rendulic",
      "Eirikur Agustsson",
      "Matthew Johnson",
      "Tanya Lando",
      "Andrew Howard",
      "Sri Gayatri Sundara Padmanabhan",
      "Mayank Daswani",
      "Andrea Banino",
      "Michael Kilgore",
      "Jonathan Heek",
      "Ziwei Ji",
      "Alvaro Caceres",
      "Conglong Li",
      "Nora Kassner",
      "Alexey Vlaskin",
      "Zeyu Liu",
      "Alex Grills",
      "Yanhan Hou",
      "Roykrong Sukkerd",
      "Gowoon Cheon",
      "Nishita Shetty",
      "Larisa Markeeva",
      "Piotr Stanczyk",
      "Tejas Iyer",
      "Yuan Gong",
      "Shawn Gao",
      "Keerthana Gopalakrishnan",
      "Tim Blyth",
      "Malcolm Reynolds",
      "Avishkar Bhoopchand",
      "Misha Bilenko",
      "Dero Gharibian",
      "Vicky Zayats",
      "Aleksandra Faust",
      "Abhinav Singh",
      "Min Ma",
      "Hongyang Jiao",
      "Sudheendra Vijayanarasimhan",
      "Lora Aroyo",
      "Vikas Yadav",
      "Sarah Chakera",
      "Ashwin Kakarla",
      "Vilobh Meshram",
      "Karol Gregor",
      "Gabriela Botea",
      "Evan Senter",
      "Dawei Jia",
      "Geza Kovacs",
      "Neha Sharma",
      "Sebastien Baur",
      "Kai Kang",
      "Yifan He",
      "Lin Zhuo",
      "Marija Kostelac",
      "Itay Laish",
      "Songyou Peng",
      "Louis O'Bryan",
      "Daniel Kasenberg",
      "Girish Ramchandra Rao",
      "Edouard Leurent",
      "Biao Zhang",
      "Sage Stevens",
      "Ana Salazar",
      "Ye Zhang",
      "Ivan Lobov",
      "Jake Walker",
      "Allen Porter",
      "Morgan Redshaw",
      "Han Ke",
      "Abhishek Rao",
      "Alex Lee",
      "Hoi Lam",
      "Michael Moffitt",
      "Jaeyoun Kim",
      "Siyuan Qiao",
      "Terry Koo",
      "Robert Dadashi",
      "Xinying Song",
      "Mukund Sundararajan",
      "Peng Xu",
      "Chizu Kawamoto",
      "Yan Zhong",
      "Clara Barbu",
      "Apoorv Reddy",
      "Mauro Verzetti",
      "Leon Li",
      "George Papamakarios",
      "Hanna Klimczak-Pluci\u0144ska",
      "Mary Cassin",
      "Koray Kavukcuoglu",
      "Rigel Swavely",
      "Alain Vaucher",
      "Jeffrey Zhao",
      "Ross Hemsley",
      "Michael Tschannen",
      "Heming Ge",
      "Gaurav Menghani",
      "Yang Yu",
      "Natalie Ha",
      "Wei He",
      "Xiao Wu",
      "Maggie Song",
      "Rachel Sterneck",
      "Stefan Zinke",
      "Dan A. Calian",
      "Annie Marsden",
      "Alejandro Cruzado Ruiz",
      "Matteo Hessel",
      "Almog Gueta",
      "Benjamin Lee",
      "Brian Farris",
      "Manish Gupta",
      "Yunjie Li",
      "Mohammad Saleh",
      "Vedant Misra",
      "Kefan Xiao",
      "Piermaria Mendolicchio",
      "Gavin Buttimore",
      "Varvara Krayvanova",
      "Nigamaa Nayakanti",
      "Matthew Wiethoff",
      "Yash Pande",
      "Azalia Mirhoseini",
      "Ni Lao",
      "Jasmine Liu",
      "Yiqing Hua",
      "Angie Chen",
      "Yury Malkov",
      "Dmitry Kalashnikov",
      "Shubham Gupta",
      "Kartik Audhkhasi",
      "Yuexiang Zhai",
      "Sudhindra Kopalle",
      "Prateek Jain",
      "Eran Ofek",
      "Clemens Meyer",
      "Khuslen Baatarsukh",
      "Hana Strej\u010dek",
      "Jun Qian",
      "James Freedman",
      "Ricardo Figueira",
      "Michal Sokolik",
      "Olivier Bachem",
      "Raymond Lin",
      "Dia Kharrat",
      "Chris Hidey",
      "Pingmei Xu",
      "Dennis Duan",
      "Yin Li",
      "Muge Ersoy",
      "Richard Everett",
      "Kevin Cen",
      "Rebeca Santamaria-Fernandez",
      "Amir Taubenfeld",
      "Ian Mackinnon",
      "Linda Deng",
      "Polina Zablotskaia",
      "Shashank Viswanadha",
      "Shivanker Goel",
      "Damion Yates",
      "Yunxiao Deng",
      "Peter Choy",
      "Mingqing Chen",
      "Abhishek Sinha",
      "Alex Mossin",
      "Yiming Wang",
      "Arthur Szlam",
      "Susan Hao",
      "Paul Kishan Rubenstein",
      "Metin Toksoz-Exley",
      "Miranda Aperghis",
      "Yin Zhong",
      "Junwhan Ahn",
      "Michael Isard",
      "Olivier Lacombe",
      "Florian Luisier",
      "Chrysovalantis Anastasiou",
      "Yogesh Kalley",
      "Utsav Prabhu",
      "Emma Dunleavy",
      "Shaan Bijwadia",
      "Justin Mao-Jones",
      "Kelly Chen",
      "Rama Pasumarthi",
      "Emily Wood",
      "Adil Dostmohamed",
      "Nate Hurley",
      "Jiri Simsa",
      "Alicia Parrish",
      "Mantas Pajarskas",
      "Matt Harvey",
      "Ondrej Skopek",
      "Yony Kochinski",
      "Javier Rey",
      "Verena Rieser",
      "Denny Zhou",
      "Sun Jae Lee",
      "Trilok Acharya",
      "Guowang Li",
      "Joe Jiang",
      "Xiaofan Zhang",
      "Bryant Gipson",
      "Ethan Mahintorabi",
      "Marco Gelmi",
      "Nima Khajehnouri",
      "Angel Yeh",
      "Kayi Lee",
      "Loic Matthey",
      "Leslie Baker",
      "Trang Pham",
      "Han Fu",
      "Alex Pak",
      "Prakhar Gupta",
      "Cristina Vasconcelos",
      "Adam Sadovsky",
      "Brian Walker",
      "Sissie Hsiao",
      "Patrik Zochbauer",
      "Andreea Marzoca",
      "Noam Velan",
      "Junhao Zeng",
      "Gilles Baechler",
      "Danny Driess",
      "Divya Jain",
      "Yanping Huang",
      "Lizzie Tao",
      "John Maggs",
      "Nir Levine",
      "Jon Schneider",
      "Erika Gemzer",
      "Samuel Petit",
      "Shan Han",
      "Zach Fisher",
      "Dustin Zelle",
      "Courtney Biles",
      "Eugene Ie",
      "Asya Fadeeva",
      "Casper Liu",
      "Juliana Vicente Franco",
      "Adrian Collister",
      "Hao Zhang",
      "Renshen Wang",
      "Ruizhe Zhao",
      "Leandro Kieliger",
      "Kurt Shuster",
      "Rui Zhu",
      "Boqing Gong",
      "Lawrence Chan",
      "Ruoxi Sun",
      "Sujoy Basu",
      "Roland Zimmermann",
      "Jamie Hayes",
      "Abhishek Bapna",
      "Jasper Snoek",
      "Weel Yang",
      "Puranjay Datta",
      "Jad Al Abdallah",
      "Kevin Kilgour",
      "Lu Li",
      "SQ Mah",
      "Yennie Jun",
      "Morgane Rivi\u00e8re",
      "Abhijit Karmarkar",
      "Tammo Spalink",
      "Tao Huang",
      "Lucas Gonzalez",
      "Duc-Hieu Tran",
      "Averi Nowak",
      "John Palowitch",
      "Martin Chadwick",
      "Ellie Talius",
      "Harsh Mehta",
      "Thibault Sellam",
      "Philipp Fr\u00e4nken",
      "Massimo Nicosia",
      "Kyle He",
      "Aditya Kini",
      "David Amos",
      "Sugato Basu",
      "Harrison Jobe",
      "Eleni Shaw",
      "Qiantong Xu",
      "Colin Evans",
      "Daisuke Ikeda",
      "Chaochao Yan",
      "Larry Jin",
      "Lun Wang",
      "Sachin Yadav",
      "Ilia Labzovsky",
      "Ramesh Sampath",
      "Ada Ma",
      "Candice Schumann",
      "Aditya Siddhant",
      "Rohin Shah",
      "John Youssef",
      "Rishabh Agarwal",
      "Natalie Dabney",
      "Alessio Tonioni",
      "Moran Ambar",
      "Jing Li",
      "Isabelle Guyon",
      "Benny Li",
      "David Soergel",
      "Boya Fang",
      "Georgi Karadzhov",
      "Cristian Udrescu",
      "Trieu Trinh",
      "Vikas Raunak",
      "Seb Noury",
      "Dee Guo",
      "Sonal Gupta",
      "Mara Finkelstein",
      "Denis Petek",
      "Lihao Liang",
      "Greg Billock",
      "Pei Sun",
      "David Wood",
      "Yiwen Song",
      "Xiaobin Yu",
      "Tatiana Matejovicova",
      "Regev Cohen",
      "Kalyan Andra",
      "David D'Ambrosio",
      "Zhiwei Deng",
      "Vincent Nallatamby",
      "Ebrahim Songhori",
      "Rumen Dangovski",
      "Andrew Lampinen",
      "Pankil Botadra",
      "Adam Hillier",
      "Jiawei Cao",
      "Nagabhushan Baddi",
      "Adhi Kuncoro",
      "Toshihiro Yoshino",
      "Ankit Bhagatwala",
      "Marc\u00e1urelio Ranzato",
      "Rylan Schaeffer",
      "Tianlin Liu",
      "Shuai Ye",
      "Obaid Sarvana",
      "John Nham",
      "Chenkai Kuang",
      "Isabel Gao",
      "Jinoo Baek",
      "Shubham Mittal",
      "Ayzaan Wahid",
      "Anita Gergely",
      "Bin Ni",
      "Josh Feldman",
      "Carrie Muir",
      "Pascal Lamblin",
      "Wolfgang Macherey",
      "Ethan Dyer",
      "Logan Kilpatrick",
      "V\u00edctor Campos",
      "Mukul Bhutani",
      "Stanislav Fort",
      "Yanif Ahmad",
      "Aliaksei Severyn",
      "Kleopatra Chatziprimou",
      "Oleksandr Ferludin",
      "Mason Dimarco",
      "Aditya Kusupati",
      "Joe Heyward",
      "Dan Bahir",
      "Kevin Villela",
      "Katie Millican",
      "Dror Marcus",
      "Sanaz Bahargam",
      "Caglar Unlu",
      "Nicholas Roth",
      "Zichuan Wei",
      "Siddharth Gopal",
      "Deepanway Ghoshal",
      "Edward Lee",
      "Sharon Lin",
      "Jennie Lees",
      "Dayeong Lee",
      "Anahita Hosseini",
      "Connie Fan",
      "Seth Neel",
      "Marcus Wu",
      "Yasemin Altun",
      "Honglong Cai",
      "Enrique Piqueras",
      "Josh Woodward",
      "Alessandro Bissacco",
      "Salem Haykal",
      "Mahyar Bordbar",
      "Prasha Sundaram",
      "Sarah Hodkinson",
      "Daniel Toyama",
      "George Polovets",
      "Austin Myers",
      "Anu Sinha",
      "Tomer Levinboim",
      "Kashyap Krishnakumar",
      "Rachita Chhaparia",
      "Tatiana Sholokhova",
      "Nitesh Bharadwaj Gundavarapu",
      "Ganesh Jawahar",
      "Haroon Qureshi",
      "Jieru Hu",
      "Nikola Momchev",
      "Matthew Rahtz",
      "Renjie Wu",
      "Aishwarya P S",
      "Kedar Dhamdhere",
      "Meiqi Guo",
      "Umang Gupta",
      "Ali Eslami",
      "Mariano Schain",
      "Michiel Blokzijl",
      "David Welling",
      "Dave Orr",
      "Levent Bolelli",
      "Nicolas Perez-Nieves",
      "Mikhail Sirotenko",
      "Aman Prasad",
      "Arjun Kar",
      "Borja De Balle Pigem",
      "Tayfun Terzi",
      "Gell\u00e9rt Weisz",
      "Dipankar Ghosh",
      "Aditi Mavalankar",
      "Dhruv Madeka",
      "Kaspar Daugaard",
      "Hartwig Adam",
      "Viraj Shah",
      "Dana Berman",
      "Maggie Tran",
      "Steven Baker",
      "Ewa Andrejczuk",
      "Grishma Chole",
      "Ganna Raboshchuk",
      "Mahdi Mirzazadeh",
      "Thais Kagohara",
      "Shimu Wu",
      "Christian Schallhart",
      "Bernett Orlando",
      "Chen Wang",
      "Alban Rrustemi",
      "Hao Xiong",
      "Hao Liu",
      "Arpi Vezer",
      "Nolan Ramsden",
      "Shuo-yiin Chang",
      "Sidharth Mudgal",
      "Yan Li",
      "Nino Vieillard",
      "Yedid Hoshen",
      "Farooq Ahmad",
      "Ambrose Slone",
      "Amy Hua",
      "Natan Potikha",
      "Mirko Rossini",
      "Jon Stritar",
      "Sushant Prakash",
      "Zifeng Wang",
      "Xuanyi Dong",
      "Alireza Nazari",
      "Efrat Nehoran",
      "Kaan Tekelioglu",
      "Yinxiao Li",
      "Kartikeya Badola",
      "Tom Funkhouser",
      "Yuanzhen Li",
      "Varun Yerram",
      "Ramya Ganeshan",
      "Daniel Formoso",
      "Karol Langner",
      "Tian Shi",
      "Huijian Li",
      "Yumeya Yamamori",
      "Amayika Panda",
      "Alaa Saade",
      "Angelo Scorza Scarpati",
      "Chris Breaux",
      "CJ Carey",
      "Zongwei Zhou",
      "Cho-Jui Hsieh",
      "Sophie Bridgers",
      "Alena Butryna",
      "Nishesh Gupta",
      "Vaibhav Tulsyan",
      "Sanghyun Woo",
      "Evgenii Eltyshev",
      "Will Grathwohl",
      "Chanel Parks",
      "Seth Benjamin",
      "Rina Panigrahy",
      "Shenil Dodhia",
      "Daniel De Freitas",
      "Chris Sauer",
      "Will Song",
      "Ferran Alet",
      "Jackson Tolins",
      "Cosmin Paduraru",
      "Xingyi Zhou",
      "Brian Albert",
      "Zizhao Zhang",
      "Lei Shu",
      "Mudit Bansal",
      "Sarah Nguyen",
      "Amir Globerson",
      "Owen Xiao",
      "James Manyika",
      "Tom Hennigan",
      "Rong Rong",
      "Josip Matak",
      "Anton Bakalov",
      "Ankur Sharma",
      "Danila Sinopalnikov",
      "Andrew Pierson",
      "Stephen Roller",
      "Geoff Brown",
      "Mingcen Gao",
      "Toshiyuki Fukuzawa",
      "Amin Ghafouri",
      "Kenny Vassigh",
      "Iain Barr",
      "Zhicheng Wang",
      "Anna Korsun",
      "Rajesh Jayaram",
      "Lijie Ren",
      "Tim Zaman",
      "Samira Khan",
      "Yana Lunts",
      "Dan Deutsch",
      "Dave Uthus",
      "Nitzan Katz",
      "Masha Samsikova",
      "Amr Khalifa",
      "Nikhil Sethi",
      "Jiao Sun",
      "Luming Tang",
      "Uri Alon",
      "Xianghong Luo",
      "Dian Yu",
      "Abhishek Nayyar",
      "Bryce Petrini",
      "Will Truong",
      "Vincent Hellendoorn",
      "Nikolai Chinaev",
      "Chris Alberti",
      "Wei Wang",
      "Jingcao Hu",
      "Vahab Mirrokni",
      "Ananth Balashankar",
      "Avia Aharon",
      "Aahil Mehta",
      "Ahmet Iscen",
      "Joseph Kready",
      "Lucas Manning",
      "Anhad Mohananey",
      "Yuankai Chen",
      "Anshuman Tripathi",
      "Allen Wu",
      "Igor Petrovski",
      "Dawsen Hwang",
      "Martin Baeuml",
      "Shreyas Chandrakaladharan",
      "Yuan Liu",
      "Rey Coaguila",
      "Maxwell Chen",
      "Sally Ma",
      "Pouya Tafti",
      "Susheel Tatineni",
      "Terry Spitz",
      "Jiayu Ye",
      "Paul Vicol",
      "Mihaela Rosca",
      "Adri\u00e0 Puigdom\u00e8nech",
      "Zohar Yahav",
      "Sanjay Ghemawat",
      "Hanzhao Lin",
      "Phoebe Kirk",
      "Zaid Nabulsi",
      "Sergey Brin",
      "Bernd Bohnet",
      "Ken Caluwaerts",
      "Aditya Srikanth Veerubhotla",
      "Dan Zheng",
      "Zihang Dai",
      "Petre Petrov",
      "Yichong Xu",
      "Ramin Mehran",
      "Zhuo Xu",
      "Luisa Zintgraf",
      "Jiho Choi",
      "Spurthi Amba Hombaiah",
      "Romal Thoppilan",
      "Sashank Reddi",
      "Lukasz Lew",
      "Li Li",
      "Kellie Webster",
      "KP Sawhney",
      "Lampros Lamprou",
      "Siamak Shakeri",
      "Mayank Lunayach",
      "Jianmin Chen",
      "Sumit Bagri",
      "Alex Salcianu",
      "Ying Chen",
      "Yani Donchev",
      "Charlotte Magister",
      "Signe N\u00f8rly",
      "Vitor Rodrigues",
      "Tomas Izo",
      "Hila Noga",
      "Joe Zou",
      "Thomas K\u00f6ppe",
      "Wenxuan Zhou",
      "Kenton Lee",
      "Xiangzhu Long",
      "Danielle Eisenbud",
      "Anthony Chen",
      "Connor Schenck",
      "Chi Ming To",
      "Peilin Zhong",
      "Emanuel Taropa",
      "Minh Truong",
      "Omer Levy",
      "Danilo Martins",
      "Zhiyuan Zhang",
      "Christopher Semturs",
      "Kelvin Zhang",
      "Alex Yakubovich",
      "Pol Moreno",
      "Lara McConnaughey",
      "Di Lu",
      "Sam Redmond",
      "Lotte Weerts",
      "Yonatan Bitton",
      "Tiziana Refice",
      "Nicolas Lacasse",
      "Arthur Conmy",
      "Corentin Tallec",
      "Julian Odell",
      "Hannah Forbes-Pollard",
      "Arkadiusz Socala",
      "Jonathan Hoech",
      "Pushmeet Kohli",
      "Alanna Walton",
      "Rui Wang",
      "Mikita Sazanovich",
      "Kexin Zhu",
      "Andrei Kapishnikov",
      "Rich Galt",
      "Matthew Denton",
      "Ben Murdoch",
      "Caitlin Sikora",
      "Kareem Mohamed",
      "Wei Wei",
      "Uri First",
      "Tim McConnell",
      "Luis C. Cobo",
      "James Qin",
      "Thi Avrahami",
      "Daniel Balle",
      "Yu Watanabe",
      "Annie Louis",
      "Adam Kraft",
      "Setareh Ariafar",
      "Yiming Gu",
      "Eug\u00e9nie Rives",
      "Charles Yoon",
      "Andrei Rusu",
      "James Cobon-Kerr",
      "Chris Hahn",
      "Jiaming Luo",
      "Yuvein",
      "Zhu",
      "Niharika Ahuja",
      "Rodrigo Benenson",
      "Rapha\u00ebl Lopez Kaufman",
      "Honglin Yu",
      "Lloyd Hightower",
      "Junlin Zhang",
      "Darren Ni",
      "Lisa Anne Hendricks",
      "Gabby Wang",
      "Gal Yona",
      "Lalit Jain",
      "Pablo Barrio",
      "Surya Bhupatiraju",
      "Siva Velusamy",
      "Allan Dafoe",
      "Sebastian Riedel",
      "Tara Thomas",
      "Zhe Yuan",
      "Mathias Bellaiche",
      "Sheena Panthaplackel",
      "Klemen Kloboves",
      "Sarthak Jauhari",
      "Canfer Akbulut",
      "Todor Davchev",
      "Evgeny Gladchenko",
      "David Madras",
      "Aleksandr Chuklin",
      "Tyrone Hill",
      "Quan Yuan",
      "Mukundan Madhavan",
      "Luke Leonhard",
      "Dylan Scandinaro",
      "Qihang Chen",
      "Ning Niu",
      "Arthur Douillard",
      "Bogdan Damoc",
      "Yasumasa Onoe",
      "Fabian Pedregosa",
      "Fred Bertsch",
      "Chas Leichner",
      "Joseph Pagadora",
      "Jonathan Malmaud",
      "Sameera Ponda",
      "Andy Twigg",
      "Oleksii Duzhyi",
      "Jingwei Shen",
      "Miaosen Wang",
      "Roopal Garg",
      "Jing Chen",
      "Utku Evci",
      "Jonathan Lee",
      "Leon Liu",
      "Koji Kojima",
      "Masa Yamaguchi",
      "Arunkumar Rajendran",
      "AJ Piergiovanni",
      "Vinodh Kumar Rajendran",
      "Marco Fornoni",
      "Gabriel Ibagon",
      "Harry Ragan",
      "Sadh MNM Khan",
      "John Blitzer",
      "Andrew Bunner",
      "Guan Sun",
      "Takahiro Kosakai",
      "Scott Lundberg",
      "Ndidi Elue",
      "Kelvin Guu",
      "SK Park",
      "Jane Park",
      "Arunachalam Narayanaswamy",
      "Chengda Wu",
      "Jayaram Mudigonda",
      "Trevor Cohn",
      "Hairong Mu",
      "Ravi Kumar",
      "Laura Graesser",
      "Yichi Zhang",
      "Richard Killam",
      "Vincent Zhuang",
      "Mai Gim\u00e9nez",
      "Wael Al Jishi",
      "Ruy Ley-Wild",
      "Alex Zhai",
      "Kazuki Osawa",
      "Diego Cedillo",
      "Jialu Liu",
      "Mayank Upadhyay",
      "Marcin Sieniek",
      "Roshan Sharma",
      "Tom Paine",
      "Anelia Angelova",
      "Sravanti Addepalli",
      "Carolina Parada",
      "Kingshuk Majumder",
      "Avery Lamp",
      "Sanjiv Kumar",
      "Xiang Deng",
      "Artiom Myaskovsky",
      "Tea Saboli\u0107",
      "Jeffrey Dudek",
      "Sarah York",
      "F\u00e9lix de Chaumont Quitry",
      "Jiazhong Nie",
      "Dee Cattle",
      "Alok Gunjan",
      "Bilal Piot",
      "Waleed Khawaja",
      "Seojin Bang",
      "Simon Wang",
      "Siavash Khodadadeh",
      "Raghavender R",
      "Praynaa Rawlani",
      "Richard Powell",
      "Kevin Lee",
      "Johannes Griesser",
      "GS Oh",
      "Cesar Magalhaes",
      "Yujia Li",
      "Simon Tokumine",
      "Hadas Natalie Vogel",
      "Dennis Hsu",
      "Arturo BC",
      "Disha Jindal",
      "Matan Cohen",
      "Zi Yang",
      "Junwei Yuan",
      "Dario de Cesare",
      "Tony Bruguier",
      "Jun Xu",
      "Monica Roy",
      "Alon Jacovi",
      "Dan Belov",
      "Rahul Arya",
      "Phoenix Meadowlark",
      "Shlomi Cohen-Ganor",
      "Wenting Ye",
      "Patrick Morris-Suzuki",
      "Praseem Banzal",
      "Gan Song",
      "Pranavaraj Ponnuramu",
      "Fred Zhang",
      "George Scrivener",
      "Salah Zaiem",
      "Alif Raditya Rochman",
      "Kehang Han",
      "Badih Ghazi",
      "Kate Lee",
      "Shahar Drath",
      "Daniel Suo",
      "Antonious Girgis",
      "Pradeep Shenoy",
      "Duy Nguyen",
      "Douglas Eck",
      "Somit Gupta",
      "Le Yan",
      "Joao Carreira",
      "Anmol Gulati",
      "Ruoxin Sang",
      "Daniil Mirylenka",
      "Emma Cooney",
      "Edward Chou",
      "Mingyang Ling",
      "Cindy Fan",
      "Ben Coleman",
      "Guilherme Tubone",
      "Ravin Kumar",
      "Jason Baldridge",
      "Felix Hernandez-Campos",
      "Angeliki Lazaridou",
      "James Besley",
      "Itay Yona",
      "Neslihan Bulut",
      "Quentin Wellens",
      "AJ Pierigiovanni",
      "Jasmine George",
      "Richard Green",
      "Pu Han",
      "Connie Tao",
      "Geoff Clark",
      "Chong You",
      "Abbas Abdolmaleki",
      "Justin Fu",
      "Tongzhou Chen",
      "Ashwin Chaugule",
      "Angad Chandorkar",
      "Altaf Rahman",
      "Will Thompson",
      "Penporn Koanantakool",
      "Mike Bernico",
      "Jie Ren",
      "Andrey Vlasov",
      "Sergei Vassilvitskii",
      "Maciej Kula",
      "Yizhong Liang",
      "Dahun Kim",
      "Yangsibo Huang",
      "Chengxi Ye",
      "Dmitry Lepikhin",
      "Wesley Helmholz"
    ],
    "summary": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incre...",
    "published": "Jul 07",
    "pdf_url": "https://arxiv.org/pdf/2507.06261v6",
    "arxiv_url": "http://arxiv.org/abs/2507.06261v6",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman"
    ]
  },
  {
    "title": "MedVAL: Toward Expert-Level Medical Text Validation with Language Models",
    "authors": [
      "Asad Aali",
      "Vasiliki Bikia",
      "Maya Varma",
      "Nicole Chiou",
      "Sophie Ostmeier",
      "Arnav Singhvi",
      "Magdalini Paschali",
      "Ashwin Kumar",
      "Andrew Johnston",
      "Karimar Amador-Martinez",
      "Eduardo Juan Perez Guerrero",
      "Paola Naovi Cruz Rivera",
      "Sergios Gatidis",
      "Christian Bluethgen",
      "Eduardo Pontes Reis",
      "Eddy D. Zandee van Rilland",
      "Poonam Laxmappa Hosamani",
      "Kevin R Keet",
      "Minjoung Go",
      "Evelyn Ling",
      "David B. Larson",
      "Curtis Langlotz",
      "Roxana Daneshjou",
      "Jason Hom",
      "Sanmi Koyejo",
      "Emily Alsentzer",
      "Akshay S. Chaudhari"
    ],
    "summary": "With the growing use of language models (LMs) in clinical environments, there is an immediate need to evaluate the accuracy and safety of LM-generated medical text. Currently, such evaluation relies solely on manual physician review. However, detecting errors in LM-generated text is challenging beca...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.03152v4",
    "arxiv_url": "http://arxiv.org/abs/2507.03152v4",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users",
    "authors": [
      "Almog Hilel",
      "Idan Shenfeld",
      "Jacob Andreas",
      "Leshem Choshen"
    ],
    "summary": "We describe a vulnerability in language models (LMs) trained with user feedback, whereby a single user can persistently alter LM knowledge and behavior given only the ability to provide prompts and upvote / downvote feedback on LM outputs. To implement the attack, the attacker prompts the LM to stoc...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.02850v2",
    "arxiv_url": "http://arxiv.org/abs/2507.02850v2",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Generalizing Verifiable Instruction Following",
    "authors": [
      "Valentina Pyatkin",
      "Saumya Malik",
      "Victoria Graf",
      "Hamish Ivison",
      "Shengyi Huang",
      "Pradeep Dasigi",
      "Nathan Lambert",
      "Hannaneh Hajishirzi"
    ],
    "summary": "A crucial factor for successful human and AI interaction is the ability of language models or chatbots to follow human instructions precisely. A common feature of instructions are output constraints like ``only answer with yes or no\" or ``mention the word `abrakadabra' at least 3 times\" that the use...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.02833v3",
    "arxiv_url": "http://arxiv.org/abs/2507.02833v3",
    "queried_author": "Hamish Ivison",
    "matching_authors": [
      "Hamish Ivison",
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
    "authors": [
      "Yuxuan Zhu",
      "Tengjun Jin",
      "Yada Pruksachatkun",
      "Andy Zhang",
      "Shu Liu",
      "Sasha Cui",
      "Sayash Kapoor",
      "Shayne Longpre",
      "Kevin Meng",
      "Rebecca Weiss",
      "Fazl Barez",
      "Rahul Gupta",
      "Jwala Dhamala",
      "Jacob Merizian",
      "Mario Giulianelli",
      "Harry Coppock",
      "Cozmin Ududec",
      "Jasjeet Sekhon",
      "Jacob Steinhardt",
      "Antony Kellermann",
      "Sarah Schwettmann",
      "Matei Zaharia",
      "Ion Stoica",
      "Percy Liang",
      "Daniel Kang"
    ],
    "summary": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task ou...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.02825v5",
    "arxiv_url": "http://arxiv.org/abs/2507.02825v5",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Understanding and Improving Length Generalization in Recurrent Models",
    "authors": [
      "Ricardo Buitrago Ruiz",
      "Albert Gu"
    ],
    "summary": "Recently, recurrent models such as state space models and linear attention have become popular due to their linear complexity in the sequence length. Thanks to their recurrent nature, in principle they can process arbitrarily long sequences, but their performance sometimes drops considerably beyond ...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.02782v2",
    "arxiv_url": "http://arxiv.org/abs/2507.02782v2",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu"
    ]
  },
  {
    "title": "Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards",
    "authors": [
      "Shirley Wu",
      "Parth Sarthi",
      "Shiyu Zhao",
      "Aaron Lee",
      "Herumb Shandilya",
      "Adrian Mladenic Grobelnik",
      "Nurendra Choudhary",
      "Eddie Huang",
      "Karthik Subbian",
      "Linjun Zhang",
      "Diyi Yang",
      "James Zou",
      "Jure Leskovec"
    ],
    "summary": "Compound AI systems integrating multiple components, such as Large Language Models, specialized tools, and traditional machine learning models, are increasingly deployed to solve complex real-world tasks. However, optimizing compound systems remains challenging due to their non-differentiable struct...",
    "published": "Jul 03",
    "pdf_url": "https://arxiv.org/pdf/2507.03041v3",
    "arxiv_url": "http://arxiv.org/abs/2507.03041v3",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Challenges for AI in Multimodal STEM Assessments: a Human-AI Comparison",
    "authors": [
      "Aymeric de Chillaz",
      "Anna Sotnikova",
      "Patrick Jermann",
      "Antoine Bosselut"
    ],
    "summary": "Generative AI systems have rapidly advanced, with multimodal input capabilities enabling reasoning beyond text-based tasks. In education, these advancements could influence assessment design and question answering, presenting both opportunities and challenges. To investigate these effects, we introd...",
    "published": "Jul 02",
    "pdf_url": "https://arxiv.org/pdf/2507.03013v1",
    "arxiv_url": "http://arxiv.org/abs/2507.03013v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks",
    "authors": [
      "Xinxi Lyu",
      "Michael Duan",
      "Rulin Shao",
      "Pang Wei Koh",
      "Sewon Min"
    ],
    "summary": "Retrieval-augmented Generation (RAG) has primarily been studied in limited settings, such as factoid question answering; more challenging, reasoning-intensive benchmarks have seen limited success from minimal RAG. In this work, we challenge this prevailing view on established, reasoning-intensive be...",
    "published": "Jul 02",
    "pdf_url": "https://arxiv.org/pdf/2507.01297v2",
    "arxiv_url": "http://arxiv.org/abs/2507.01297v2",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh"
    ]
  },
  {
    "title": "SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks",
    "authors": [
      "Yilun Zhao",
      "Kaiyan Zhang",
      "Tiansheng Hu",
      "Sihong Wu",
      "Ronan Le Bras",
      "Taira Anderson",
      "Jonathan Bragg",
      "Joseph Chee Chang",
      "Jesse Dodge",
      "Matt Latzke",
      "Yixin Liu",
      "Charles McGrady",
      "Xiangru Tang",
      "Zihang Wang",
      "Chen Zhao",
      "Hannaneh Hajishirzi",
      "Doug Downey",
      "Arman Cohan"
    ],
    "summary": "We present SciArena, an open and collaborative platform for evaluating foundation models on scientific literature tasks. Unlike traditional benchmarks for scientific literature understanding and synthesis, SciArena engages the research community directly, following the Chatbot Arena evaluation appro...",
    "published": "Jul 01",
    "pdf_url": "https://arxiv.org/pdf/2507.01001v1",
    "arxiv_url": "http://arxiv.org/abs/2507.01001v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Jesse Dodge"
    ]
  },
  {
    "title": "La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America",
    "authors": [
      "Mar\u00eda Grandury",
      "Javier Aula-Blasco",
      "J\u00falia Falc\u00e3o",
      "Cl\u00e9mentine Fourrier",
      "Miguel Gonz\u00e1lez",
      "Gonzalo Mart\u00ednez",
      "Gonzalo Santamar\u00eda",
      "Rodrigo Agerri",
      "Nuria Aldama",
      "Luis Chiruzzo",
      "Javier Conde",
      "Helena G\u00f3mez",
      "Marta Guerrero",
      "Guido Ivetta",
      "Natalia L\u00f3pez",
      "Flor Miriam Plaza-del-Arco",
      "Mar\u00eda Teresa Mart\u00edn-Valdivia",
      "Helena Montoro",
      "Carmen Mu\u00f1oz",
      "Pedro Reviriego",
      "Leire Rosado",
      "Alejandro Vaca",
      "Mar\u00eda Estrella Vallecillo-Rodr\u00edguez",
      "Jorge Vallego",
      "Irune Zubiaga"
    ],
    "summary": "Leaderboards showcase the current capabilities and limitations of Large Language Models (LLMs). To motivate the development of LLMs that represent the linguistic and cultural diversity of the Spanish-speaking community, we present La Leaderboard, the first open-source leaderboard to evaluate generat...",
    "published": "Jul 01",
    "pdf_url": "https://arxiv.org/pdf/2507.00999v1",
    "arxiv_url": "http://arxiv.org/abs/2507.00999v1",
    "queried_author": "Cl\u00e9mentine Fourrier",
    "matching_authors": [
      "Cl\u00e9mentine Fourrier"
    ]
  },
  {
    "title": "LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing",
    "authors": [
      "Daniel Fein",
      "Sebastian Russo",
      "Violet Xiang",
      "Kabir Jolly",
      "Rafael Rafailov",
      "Nick Haber"
    ],
    "summary": "Evaluating creative writing generated by large language models (LLMs) remains challenging because open-ended narratives lack ground truths. Without performant automated evaluation methods, off-the-shelf (OTS) language models are employed as zero-shot judges, yet their reliability is unclear in this ...",
    "published": "Jul 01",
    "pdf_url": "https://arxiv.org/pdf/2507.00769v1",
    "arxiv_url": "http://arxiv.org/abs/2507.00769v1",
    "queried_author": "Rafael Rafailov",
    "matching_authors": [
      "Rafael Rafailov"
    ]
  },
  {
    "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning",
    "authors": [
      "Maggie Huan",
      "Yuetai Li",
      "Tuney Zheng",
      "Xiaoyu Xu",
      "Seungone Kim",
      "Minxin Du",
      "Radha Poovendran",
      "Graham Neubig",
      "Xiang Yue"
    ],
    "summary": "Math reasoning has become the poster child of progress in large language models (LLMs), with new models rapidly surpassing human-level performance on benchmarks like MATH and AIME. But as math leaderboards improve week by week, it is worth asking: do these gains reflect broader problem-solving abili...",
    "published": "Jul 01",
    "pdf_url": "https://arxiv.org/pdf/2507.00432v2",
    "arxiv_url": "http://arxiv.org/abs/2507.00432v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Seungone Kim"
    ]
  },
  {
    "title": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context",
    "authors": [
      "Joongwon Kim",
      "Anirudh Goyal",
      "Liang Tan",
      "Hannaneh Hajishirzi",
      "Srinivasan Iyer",
      "Tianlu Wang"
    ],
    "summary": "We introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms, explicitly leveraging self-reflection, backtracking, and exploration in their outputs. Recently, training large language models (LLMs) via reinforcement learnin...",
    "published": "Jul 01",
    "pdf_url": "https://arxiv.org/pdf/2507.00417v1",
    "arxiv_url": "http://arxiv.org/abs/2507.00417v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Linearly Decoding Refused Knowledge in Aligned Language Models",
    "authors": [
      "Aryan Shrivastava",
      "Ari Holtzman"
    ],
    "summary": "Most commonly used language models (LMs) are instruction-tuned and aligned using a combination of fine-tuning and reinforcement learning, causing them to refuse users requests deemed harmful by the model. However, jailbreak prompts can often bypass these refusal mechanisms and elicit harmful respons...",
    "published": "Jun 30",
    "pdf_url": "https://arxiv.org/pdf/2507.00239v1",
    "arxiv_url": "http://arxiv.org/abs/2507.00239v1",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "Prompting as Scientific Inquiry",
    "authors": [
      "Ari Holtzman",
      "Chenhao Tan"
    ],
    "summary": "Prompting is the primary method by which we study and control large language models. It is also one of the most powerful: nearly every major capability attributed to LLMs-few-shot learning, chain-of-thought, constitutional AI-was first unlocked through prompting. Yet prompting is rarely treated as s...",
    "published": "Jun 30",
    "pdf_url": "https://arxiv.org/pdf/2507.00163v2",
    "arxiv_url": "http://arxiv.org/abs/2507.00163v2",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions",
    "authors": [
      "Xianzhe Fan",
      "Xuhui Zhou",
      "Chuanyang Jin",
      "Kolby Nottingham",
      "Hao Zhu",
      "Maarten Sap"
    ],
    "summary": "Humans continuously infer the states, goals, and behaviors of others by perceiving their surroundings in dynamic, real-world social interactions. However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based scenarios, which have a significant gap compared to real interactions. We p...",
    "published": "Jun 29",
    "pdf_url": "https://arxiv.org/pdf/2506.23046v3",
    "arxiv_url": "http://arxiv.org/abs/2506.23046v3",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds",
    "authors": [
      "Edward Chen",
      "Sang T. Truong",
      "Natalie Dullerud",
      "Sanmi Koyejo",
      "Carlos Guestrin"
    ],
    "summary": "High-stakes decision-making involves navigating multiple competing objectives with expensive evaluations. For instance, in brachytherapy, clinicians must balance maximizing tumor coverage (e.g., an aspirational target or soft bound of >95% coverage) against strict organ dose limits (e.g., a non-nego...",
    "published": "Jun 27",
    "pdf_url": "https://arxiv.org/pdf/2506.21887v1",
    "arxiv_url": "http://arxiv.org/abs/2506.21887v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Can Gradient Descent Simulate Prompting?",
    "authors": [
      "Eric Zhang",
      "Leshem Choshen",
      "Jacob Andreas"
    ],
    "summary": "There are two primary ways of incorporating new information into a language model (LM): changing its prompt or changing its parameters, e.g. via fine-tuning. Parameter updates incur no long-term storage cost for model changes. However, for many model updates, prompting is significantly more effectiv...",
    "published": "Jun 26",
    "pdf_url": "https://arxiv.org/pdf/2506.20989v1",
    "arxiv_url": "http://arxiv.org/abs/2506.20989v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language",
    "authors": [
      "Guilherme Penedo",
      "Hynek Kydl\u00ed\u010dek",
      "Vinko Sabol\u010dec",
      "Bettina Messmer",
      "Negar Foroutan",
      "Amir Hossein Kargaran",
      "Colin Raffel",
      "Martin Jaggi",
      "Leandro Von Werra",
      "Thomas Wolf"
    ],
    "summary": "Pre-training state-of-the-art large language models (LLMs) requires vast amounts of clean and diverse text data. While the open development of large high-quality English pre-training datasets has seen substantial recent progress, training performant multilingual LLMs remains a challenge, in large pa...",
    "published": "Jun 26",
    "pdf_url": "https://arxiv.org/pdf/2506.20920v1",
    "arxiv_url": "http://arxiv.org/abs/2506.20920v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas",
    "authors": [
      "Chenglei Si",
      "Tatsunori Hashimoto",
      "Diyi Yang"
    ],
    "summary": "Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert...",
    "published": "Jun 25",
    "pdf_url": "https://arxiv.org/pdf/2506.20803v1",
    "arxiv_url": "http://arxiv.org/abs/2506.20803v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Multiple Streams of Knowledge Retrieval: Enriching and Recalling in Transformers",
    "authors": [
      "Todd Nief",
      "David Reber",
      "Sean Richardson",
      "Ari Holtzman"
    ],
    "summary": "When an LLM learns a new fact during finetuning (e.g., new movie releases, newly elected pope, etc.), where does this information go? Are entities enriched with relation information, or do models recall information just-in-time before a prediction? Or, are ``all of the above'' true with LLMs impleme...",
    "published": "Jun 25",
    "pdf_url": "https://arxiv.org/pdf/2506.20746v2",
    "arxiv_url": "http://arxiv.org/abs/2506.20746v2",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "The Singapore Consensus on Global AI Safety Research Priorities",
    "authors": [
      "Yoshua Bengio",
      "Tegan Maharaj",
      "Luke Ong",
      "Stuart Russell",
      "Dawn Song",
      "Max Tegmark",
      "Lan Xue",
      "Ya-Qin Zhang",
      "Stephen Casper",
      "Wan Sie Lee",
      "S\u00f6ren Mindermann",
      "Vanessa Wilfred",
      "Vidhisha Balachandran",
      "Fazl Barez",
      "Michael Belinsky",
      "Imane Bello",
      "Malo Bourgon",
      "Mark Brakel",
      "Sim\u00e9on Campos",
      "Duncan Cass-Beggs",
      "Jiahao Chen",
      "Rumman Chowdhury",
      "Kuan Chua Seah",
      "Jeff Clune",
      "Juntao Dai",
      "Agnes Delaborde",
      "Nouha Dziri",
      "Francisco Eiras",
      "Joshua Engels",
      "Jinyu Fan",
      "Adam Gleave",
      "Noah Goodman",
      "Fynn Heide",
      "Johannes Heidecke",
      "Dan Hendrycks",
      "Cyrus Hodes",
      "Bryan Low Kian Hsiang",
      "Minlie Huang",
      "Sami Jawhar",
      "Wang Jingyu",
      "Adam Tauman Kalai",
      "Meindert Kamphuis",
      "Mohan Kankanhalli",
      "Subhash Kantamneni",
      "Mathias Bonde Kirk",
      "Thomas Kwa",
      "Jeffrey Ladish",
      "Kwok-Yan Lam",
      "Wan Lee Sie",
      "Taewhi Lee",
      "Xiaojian Li",
      "Jiajun Liu",
      "Chaochao Lu",
      "Yifan Mai",
      "Richard Mallah",
      "Julian Michael",
      "Nick Mo\u00ebs",
      "Simon M\u00f6ller",
      "Kihyuk Nam",
      "Kwan Yee Ng",
      "Mark Nitzberg",
      "Besmira Nushi",
      "Se\u00e1n O h\u00c9igeartaigh",
      "Alejandro Ortega",
      "Pierre Peign\u00e9",
      "James Petrie",
      "Benjamin Prud'Homme",
      "Reihaneh Rabbany",
      "Nayat Sanchez-Pi",
      "Sarah Schwettmann",
      "Buck Shlegeris",
      "Saad Siddiqui",
      "Aradhana Sinha",
      "Mart\u00edn Soto",
      "Cheston Tan",
      "Dong Ting",
      "William Tjhi",
      "Robert Trager",
      "Brian Tse",
      "Anthony Tung K. H.",
      "Vanessa Wilfred",
      "John Willes",
      "Denise Wong",
      "Wei Xu",
      "Rongwu Xu",
      "Yi Zeng",
      "HongJiang Zhang",
      "Djordje \u017dikeli\u0107"
    ],
    "summary": "Rapidly improving AI capabilities and autonomy hold significant promise of transformation, but are also driving vigorous debate on how to ensure that AI is safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem is therefore essential -- it helps people embrace AI with confidence...",
    "published": "Jun 25",
    "pdf_url": "https://arxiv.org/pdf/2506.20702v2",
    "arxiv_url": "http://arxiv.org/abs/2506.20702v2",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman"
    ]
  },
  {
    "title": "Report on NSF Workshop on Science of Safe AI",
    "authors": [
      "Rajeev Alur",
      "Greg Durrett",
      "Hadas Kress-Gazit",
      "Corina P\u0103s\u0103reanu",
      "Ren\u00e9 Vidal"
    ],
    "summary": "Recent advances in machine learning, particularly the emergence of foundation models, are leading to new opportunities to develop technology-based solutions to societal problems. However, the reasoning and inner workings of today's complex AI models are not transparent to the user, and there are no ...",
    "published": "Jun 24",
    "pdf_url": "https://arxiv.org/pdf/2506.22492v1",
    "arxiv_url": "http://arxiv.org/abs/2506.22492v1",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track",
    "authors": [
      "Rylan Schaeffer",
      "Joshua Kazdan",
      "Yegor Denisov-Blanch",
      "Brando Miranda",
      "Matthias Gerstgrasser",
      "Susan Zhang",
      "Andreas Haupt",
      "Isha Gupta",
      "Elyas Obbad",
      "Jesse Dodge",
      "Jessica Zosa Forde",
      "Francesco Orabona",
      "Sanmi Koyejo",
      "David Donoho"
    ],
    "summary": "Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and s...",
    "published": "Jun 24",
    "pdf_url": "https://arxiv.org/pdf/2506.19882v3",
    "arxiv_url": "http://arxiv.org/abs/2506.19882v3",
    "queried_author": "Jesse Dodge",
    "matching_authors": [
      "Jesse Dodge",
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Thought Anchors: Which LLM Reasoning Steps Matter?",
    "authors": [
      "Paul C. Bogdan",
      "Uzay Macar",
      "Neel Nanda",
      "Arthur Conmy"
    ],
    "summary": "Current frontier large-language models rely on reasoning to achieve state-of-the-art performance. Many existing interpretability are limited in this area, as standard methods have been designed to study single forward passes of a model rather than the multi-token computational steps that unfold duri...",
    "published": "Jun 23",
    "pdf_url": "https://arxiv.org/pdf/2506.19143v4",
    "arxiv_url": "http://arxiv.org/abs/2506.19143v4",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations",
    "authors": [
      "Brian Siyuan Zheng",
      "Alisa Liu",
      "Orevaoghene Ahia",
      "Jonathan Hayase",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "summary": "Modern tokenizers employ deterministic algorithms to map text into a single \"canonical\" token sequence, yet the same string can be encoded as many non-canonical tokenizations using the tokenizer vocabulary. In this work, we investigate the robustness of LMs to text encoded with non-canonical tokeniz...",
    "published": "Jun 23",
    "pdf_url": "https://arxiv.org/pdf/2506.19004v1",
    "arxiv_url": "http://arxiv.org/abs/2506.19004v1",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith",
      "Yejin Choi"
    ]
  },
  {
    "title": "OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization",
    "authors": [
      "Yiyou Sun",
      "Shawn Hu",
      "Georgia Zhou",
      "Ken Zheng",
      "Hannaneh Hajishirzi",
      "Nouha Dziri",
      "Dawn Song"
    ],
    "summary": "Recent large-scale language models (LLMs) with long Chain-of-Thought reasoning-such as DeepSeek-R1-have achieved impressive results on Olympiad-level mathematics benchmarks. However, they often rely on a narrow set of strategies and struggle with problems that require a novel way of thinking. To sys...",
    "published": "Jun 23",
    "pdf_url": "https://arxiv.org/pdf/2506.18880v1",
    "arxiv_url": "http://arxiv.org/abs/2506.18880v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Shrinking the Generation-Verification Gap with Weak Verifiers",
    "authors": [
      "Jon Saad-Falcon",
      "E. Kelly Buchanan",
      "Mayee F. Chen",
      "Tzu-Heng Huang",
      "Brendan McLaughlin",
      "Tanvir Bhathal",
      "Shang Zhu",
      "Ben Athiwaratkun",
      "Frederic Sala",
      "Scott Linderman",
      "Azalia Mirhoseini",
      "Christopher R\u00e9"
    ],
    "summary": "Verifiers can improve language model capabilities by scoring and ranking responses from generated candidates. Currently, high-quality verifiers are either unscalable (e.g., humans) or limited in utility (e.g., tools like Lean). While LM judges and reward models have become broadly useful as general-...",
    "published": "Jun 22",
    "pdf_url": "https://arxiv.org/pdf/2506.18203v2",
    "arxiv_url": "http://arxiv.org/abs/2506.18203v2",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors",
    "authors": [
      "Constantin Venhoff",
      "Iv\u00e1n Arcuschin",
      "Philip Torr",
      "Arthur Conmy",
      "Neel Nanda"
    ],
    "summary": "Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work ...",
    "published": "Jun 22",
    "pdf_url": "https://arxiv.org/pdf/2506.18167v4",
    "arxiv_url": "http://arxiv.org/abs/2506.18167v4",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "RoboArena: Distributed Real-World Evaluation of Generalist Robot Policies",
    "authors": [
      "Pranav Atreya",
      "Karl Pertsch",
      "Tony Lee",
      "Moo Jin Kim",
      "Arhan Jain",
      "Artur Kuramshin",
      "Clemens Eppner",
      "Cyrus Neary",
      "Edward Hu",
      "Fabio Ramos",
      "Jonathan Tremblay",
      "Kanav Arora",
      "Kirsty Ellis",
      "Luca Macesanu",
      "Marcel Torne Villasevil",
      "Matthew Leonard",
      "Meedeum Cho",
      "Ozgur Aslan",
      "Shivin Dass",
      "Jie Wang",
      "William Reger",
      "Xingfang Yuan",
      "Xuning Yang",
      "Abhishek Gupta",
      "Dinesh Jayaraman",
      "Glen Berseth",
      "Kostas Daniilidis",
      "Roberto Martin-Martin",
      "Youngwoon Lee",
      "Percy Liang",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "summary": "Comprehensive, unbiased, and comparable evaluation of modern generalist policies is uniquely challenging: existing approaches for robot benchmarking typically rely on heavy standardization, either by specifying fixed evaluation tasks and environments, or by hosting centralized ''robot challenges'', ...",
    "published": "Jun 22",
    "pdf_url": "https://arxiv.org/pdf/2506.18123v2",
    "arxiv_url": "http://arxiv.org/abs/2506.18123v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "LLM Probability Concentration: How Alignment Shrinks the Generative Horizon",
    "authors": [
      "Chenghao Yang",
      "Ari Holtzman"
    ],
    "summary": "Despite their impressive capabilities, aligned large language models (LLMs) often generate outputs that lack diversity. What drives this consistency in the generation? We investigate this phenomenon through the lens of probability concentration in the model's output distribution. To quantify this co...",
    "published": "Jun 22",
    "pdf_url": "https://arxiv.org/pdf/2506.17871v2",
    "arxiv_url": "http://arxiv.org/abs/2506.17871v2",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "In-Context Learning Strategies Emerge Rationally",
    "authors": [
      "Daniel Wurgaft",
      "Ekdeep Singh Lubana",
      "Core Francisco Park",
      "Hidenori Tanaka",
      "Gautam Reddy",
      "Noah D. Goodman"
    ],
    "summary": "Recent work analyzing in-context learning (ICL) has identified a broad set of strategies that describe model behavior in different experimental conditions. We aim to unify these findings by asking why a model learns these disparate strategies in the first place. Specifically, we start with the obser...",
    "published": "Jun 21",
    "pdf_url": "https://arxiv.org/pdf/2506.17859v2",
    "arxiv_url": "http://arxiv.org/abs/2506.17859v2",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman"
    ]
  },
  {
    "title": "Resource Rational Contractualism Should Guide AI Alignment",
    "authors": [
      "Sydney Levine",
      "Matija Franklin",
      "Tan Zhi-Xuan",
      "Secil Yanik Guyot",
      "Lionel Wong",
      "Daniel Kilov",
      "Yejin Choi",
      "Joshua B. Tenenbaum",
      "Noah Goodman",
      "Seth Lazar",
      "Iason Gabriel"
    ],
    "summary": "AI systems will soon have to navigate human environments and make decisions that affect people and other AI agents whose goals and values diverge. Contractualist alignment proposes grounding those decisions in agreements that diverse stakeholders would endorse under the right conditions, yet securin...",
    "published": "Jun 20",
    "pdf_url": "https://arxiv.org/pdf/2506.17434v1",
    "arxiv_url": "http://arxiv.org/abs/2506.17434v1",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman",
      "Yejin Choi"
    ]
  },
  {
    "title": "Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?",
    "authors": [
      "Adithya Bhaskar",
      "Alexander Wettig",
      "Tianyu Gao",
      "Yihe Dong",
      "Danqi Chen"
    ],
    "summary": "Language models handle increasingly long contexts for tasks such as book summarization, but this leads to growing memory costs for the key-value (KV) cache. Many prior works have proposed ways of discarding KVs from memory, but their approaches are tailored to favorable settings, obscuring caveats l...",
    "published": "Jun 20",
    "pdf_url": "https://arxiv.org/pdf/2506.17121v1",
    "arxiv_url": "http://arxiv.org/abs/2506.17121v1",
    "queried_author": "Alexander Wettig",
    "matching_authors": [
      "Alexander Wettig",
      "Danqi Chen"
    ]
  },
  {
    "title": "Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations",
    "authors": [
      "Ananth Agarwal",
      "Jasper Jian",
      "Christopher D. Manning",
      "Shikhar Murty"
    ],
    "summary": "Large Language Models (LLMs) exhibit a robust mastery of syntax when processing and generating text. While this suggests internalized understanding of hierarchical syntax and dependency relations, the precise mechanism by which they represent syntactic structure is an open area within interpretabili...",
    "published": "Jun 20",
    "pdf_url": "https://arxiv.org/pdf/2506.16678v2",
    "arxiv_url": "http://arxiv.org/abs/2506.16678v2",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "PPMI: Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases",
    "authors": [
      "Yubeen Bae",
      "Minchan Kim",
      "Jaejin Lee",
      "Sangbum Kim",
      "Jaehyung Kim",
      "Yejin Choi",
      "Niloofar Mireshghallah"
    ],
    "summary": "Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers,...",
    "published": "Jun 19",
    "pdf_url": "https://arxiv.org/pdf/2506.17336v3",
    "arxiv_url": "http://arxiv.org/abs/2506.17336v3",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
    "authors": [
      "Myke C. Cohen",
      "Zhe Su",
      "Hsien-Te Kao",
      "Daniel Nguyen",
      "Spencer Lynch",
      "Maarten Sap",
      "Svitlana Volkova"
    ],
    "summary": "This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated h...",
    "published": "Jun 19",
    "pdf_url": "https://arxiv.org/pdf/2506.15928v3",
    "arxiv_url": "http://arxiv.org/abs/2506.15928v3",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Approximating Language Model Training Data from Weights",
    "authors": [
      "John X. Morris",
      "Junjie Oscar Yin",
      "Woojeong Kim",
      "Vitaly Shmatikov",
      "Alexander M. Rush"
    ],
    "summary": "Modern language models often have open weights but closed training data. We formalize the problem of data approximation from model weights and propose several baselines and metrics. We develop a gradient-based approach that selects the highest-matching data from a large public text corpus and show i...",
    "published": "Jun 18",
    "pdf_url": "https://arxiv.org/pdf/2506.15553v1",
    "arxiv_url": "http://arxiv.org/abs/2506.15553v1",
    "queried_author": "Alexander M Rush",
    "matching_authors": [
      "Alexander M Rush",
      "Alexander M. Rush"
    ]
  },
  {
    "title": "ConLID: Supervised Contrastive Learning for Low-Resource Language Identification",
    "authors": [
      "Negar Foroutan",
      "Jakhongir Saydaliev",
      "Ye Eun Kim",
      "Antoine Bosselut"
    ],
    "summary": "Language identification (LID) is a critical step in curating multilingual LLM pretraining corpora from web crawls. While many studies on LID model training focus on collecting diverse training data to improve performance, low-resource languages -- often limited to single-domain data, such as the Bib...",
    "published": "Jun 18",
    "pdf_url": "https://arxiv.org/pdf/2506.15304v1",
    "arxiv_url": "http://arxiv.org/abs/2506.15304v1",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework",
    "authors": [
      "Shayan Talaei",
      "Meijin Li",
      "Kanu Grover",
      "James Kent Hippler",
      "Diyi Yang",
      "Amin Saberi"
    ],
    "summary": "Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants ...",
    "published": "Jun 17",
    "pdf_url": "https://arxiv.org/pdf/2506.14159v2",
    "arxiv_url": "http://arxiv.org/abs/2506.14159v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization",
    "authors": [
      "Chengyu Huang",
      "Tanya Goyal"
    ],
    "summary": "Recent research has attempted to associate preference optimization (PO) performance with the underlying preference datasets. In this work, our observation is that the differences between the preferred response $y^+$ and dispreferred response $y^-$ influence what LLMs can learn, which may not match t...",
    "published": "Jun 17",
    "pdf_url": "https://arxiv.org/pdf/2506.14157v1",
    "arxiv_url": "http://arxiv.org/abs/2506.14157v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "Sampling from Your Language Model One Byte at a Time",
    "authors": [
      "Jonathan Hayase",
      "Alisa Liu",
      "Noah A. Smith",
      "Sewoong Oh"
    ],
    "summary": "Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations, an issue known as the Prompt Boundary Problem (...",
    "published": "Jun 17",
    "pdf_url": "https://arxiv.org/pdf/2506.14123v2",
    "arxiv_url": "http://arxiv.org/abs/2506.14123v2",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers",
    "authors": [
      "Wooseok Seo",
      "Seungju Han",
      "Jaehun Jung",
      "Benjamin Newman",
      "Seungwon Lim",
      "Seungbeen Lee",
      "Ximing Lu",
      "Yejin Choi",
      "Youngjae Yu"
    ],
    "summary": "Fact verification is essential for ensuring the reliability of LLM applications. In this study, we evaluate 12 pre-trained LLMs and one specialized fact-verifier, including frontier LLMs and open-weight reasoning LLMs, using a collection of examples from 14 fact-checking benchmarks. We share three f...",
    "published": "Jun 16",
    "pdf_url": "https://arxiv.org/pdf/2506.13342v1",
    "arxiv_url": "http://arxiv.org/abs/2506.13342v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like Specialization",
    "authors": [
      "Badr AlKhamissi",
      "C. Nicol\u00f2 De Sabbata",
      "Greta Tuckute",
      "Zeming Chen",
      "Martin Schrimpf",
      "Antoine Bosselut"
    ],
    "summary": "Human cognitive behavior arises from the interaction of specialized brain networks dedicated to distinct functions, such as language, logic, and social reasoning. Inspired by this organization, we propose Mixture of Cognitive Reasoners (MiCRo): a modular, transformer-based architecture post-trained ...",
    "published": "Jun 16",
    "pdf_url": "https://arxiv.org/pdf/2506.13331v2",
    "arxiv_url": "http://arxiv.org/abs/2506.13331v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "The Butterfly Effect: Neural Network Training Trajectories Are Highly Sensitive to Initial Conditions",
    "authors": [
      "Devin Kwok",
      "G\u00fcl Sena Alt\u0131nta\u015f",
      "Colin Raffel",
      "David Rolnick"
    ],
    "summary": "Neural network training is inherently sensitive to initialization and the randomness induced by stochastic gradient descent. However, it is unclear to what extent such effects lead to meaningfully different networks, either in terms of the models' weights or the underlying functions that were learne...",
    "published": "Jun 16",
    "pdf_url": "https://arxiv.org/pdf/2506.13234v1",
    "arxiv_url": "http://arxiv.org/abs/2506.13234v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "ZINA: Multimodal Fine-grained Hallucination Detection and Editing",
    "authors": [
      "Yuiga Wada",
      "Kazuki Matsuda",
      "Komei Sugiura",
      "Graham Neubig"
    ],
    "summary": "Multimodal Large Language Models (MLLMs) often generate hallucinations, where the output deviates from the visual content. Given that these hallucinations can take diverse forms, detecting hallucinations at a fine-grained level is essential for comprehensive evaluation and analysis. To this end, we ...",
    "published": "Jun 16",
    "pdf_url": "https://arxiv.org/pdf/2506.13130v1",
    "arxiv_url": "http://arxiv.org/abs/2506.13130v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics",
    "authors": [
      "Jiarui Liu",
      "Yueqi Song",
      "Yunze Xiao",
      "Mingqian Zheng",
      "Lindia Tjuatja",
      "Jana Schaich Borg",
      "Mona Diab",
      "Maarten Sap"
    ],
    "summary": "As large language models (LLMs) are increasingly used in morally sensitive domains, it is crucial to understand how persona traits affect their moral reasoning and persuasive behavior. We present the first large-scale study of multi-dimensional persona effects in AI-AI debates over real-world moral ...",
    "published": "Jun 14",
    "pdf_url": "https://arxiv.org/pdf/2506.12657v1",
    "arxiv_url": "http://arxiv.org/abs/2506.12657v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "OpenUnlearning: Accelerating LLM Unlearning via Unified Benchmarking of Methods and Metrics",
    "authors": [
      "Vineeth Dorna",
      "Anmol Mekala",
      "Wenlong Zhao",
      "Andrew McCallum",
      "Zachary C. Lipton",
      "J. Zico Kolter",
      "Pratyush Maini"
    ],
    "summary": "Robust unlearning is crucial for safely deploying large language models (LLMs) in environments where data privacy, model safety, and regulatory compliance must be ensured. Yet the task is inherently challenging, partly due to difficulties in reliably measuring whether unlearning has truly occurred. ...",
    "published": "Jun 14",
    "pdf_url": "https://arxiv.org/pdf/2506.12618v2",
    "arxiv_url": "http://arxiv.org/abs/2506.12618v2",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being",
    "authors": [
      "Yutong Zhang",
      "Dora Zhao",
      "Jeffrey T. Hancock",
      "Robert Kraut",
      "Diyi Yang"
    ],
    "summary": "As large language models (LLMs)-enhanced chatbots grow increasingly expressive and socially responsive, many users are beginning to form companionship-like bonds with them, particularly with simulated AI partners designed to mimic emotionally attuned interlocutors. These emerging AI companions raise...",
    "published": "Jun 14",
    "pdf_url": "https://arxiv.org/pdf/2506.12605v4",
    "arxiv_url": "http://arxiv.org/abs/2506.12605v4",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Infini-gram mini: Exact n-gram Search at the Internet Scale with FM-Index",
    "authors": [
      "Hao Xu",
      "Jiacheng Liu",
      "Yejin Choi",
      "Noah A. Smith",
      "Hannaneh Hajishirzi"
    ],
    "summary": "Language models are trained mainly on massive text data from the Internet, and it becomes increasingly important to understand this data source. Exact-match search engines enable searching in large text corpora - counting string appearances and retrieving the enclosing documents - yet the high stora...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.12229v4",
    "arxiv_url": "http://arxiv.org/abs/2506.12229v4",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Noah A. Smith",
      "Yejin Choi"
    ]
  },
  {
    "title": "Because we have LLMs, we Can and Should Pursue Agentic Interpretability",
    "authors": [
      "Been Kim",
      "John Hewitt",
      "Neel Nanda",
      "Noah Fiedel",
      "Oyvind Tafjord"
    ],
    "summary": "The era of Large Language Models (LLMs) presents a new opportunity for interpretability--agentic interpretability: a multi-turn conversation with an LLM wherein the LLM proactively assists human understanding by developing and leveraging a mental model of the user, which in turn enables humans to de...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.12152v1",
    "arxiv_url": "http://arxiv.org/abs/2506.12152v1",
    "queried_author": "John Hewitt",
    "matching_authors": [
      "John Hewitt",
      "Neel Nanda"
    ]
  },
  {
    "title": "How Visual Representations Map to Language Feature Space in Multimodal LLMs",
    "authors": [
      "Constantin Venhoff",
      "Ashkan Khakzar",
      "Sonia Joseph",
      "Philip Torr",
      "Neel Nanda"
    ],
    "summary": "Effective multimodal reasoning depends on the alignment of visual and linguistic representations, yet the mechanisms by which vision-language models (VLMs) achieve this alignment remain poorly understood. Following the LiMBeR framework, we deliberately maintain a frozen large language model (LLM) an...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.11976v2",
    "arxiv_url": "http://arxiv.org/abs/2506.11976v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Convergent Linear Representations of Emergent Misalignment",
    "authors": [
      "Anna Soligo",
      "Edward Turner",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating crit...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.11618v2",
    "arxiv_url": "http://arxiv.org/abs/2506.11618v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Model Organisms for Emergent Misalignment",
    "authors": [
      "Edward Turner",
      "Anna Soligo",
      "Mia Taylor",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "Recent work discovered Emergent Misalignment (EM): fine-tuning large language models on narrowly harmful datasets can lead them to become broadly misaligned. A survey of experts prior to publication revealed this was highly unexpected, demonstrating critical gaps in our understanding of model alignm...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.11613v1",
    "arxiv_url": "http://arxiv.org/abs/2506.11613v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "AbsenceBench: Language Models Can't Tell What's Missing",
    "authors": [
      "Harvey Yiyun Fu",
      "Aryan Shrivastava",
      "Jared Moore",
      "Peter West",
      "Chenhao Tan",
      "Ari Holtzman"
    ],
    "summary": "Large language models (LLMs) are increasingly capable of processing long inputs and locating specific information within them, as evidenced by their performance on the Needle in a Haystack (NIAH) test. However, while models excel at recalling surprising information, they still struggle to identify c...",
    "published": "Jun 13",
    "pdf_url": "https://arxiv.org/pdf/2506.11440v1",
    "arxiv_url": "http://arxiv.org/abs/2506.11440v1",
    "queried_author": "Ari Holtzman",
    "matching_authors": [
      "Ari Holtzman"
    ]
  },
  {
    "title": "Spurious Rewards: Rethinking Training Signals in RLVR",
    "authors": [
      "Rulin Shao",
      "Shuyue Stella Li",
      "Rui Xin",
      "Scott Geng",
      "Yiping Wang",
      "Sewoong Oh",
      "Simon Shaolei Du",
      "Nathan Lambert",
      "Sewon Min",
      "Ranjay Krishna",
      "Yulia Tsvetkov",
      "Hannaneh Hajishirzi",
      "Pang Wei Koh",
      "Luke Zettlemoyer"
    ],
    "summary": "We show that reinforcement learning with verifiable rewards (RLVR) can elicit strong mathematical reasoning in certain models even with spurious rewards that have little, no, or even negative correlation with the correct answer. For example, RLVR improves MATH-500 performance for Qwen2.5-Math-7B in ...",
    "published": "Jun 12",
    "pdf_url": "https://arxiv.org/pdf/2506.10947v1",
    "arxiv_url": "http://arxiv.org/abs/2506.10947v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Sequential-Parallel Duality in Prefix Scannable Models",
    "authors": [
      "Morris Yau",
      "Sharut Gupta",
      "Valerie Engelmayer",
      "Kazuki Irie",
      "Stefanie Jegelka",
      "Jacob Andreas"
    ],
    "summary": "Modern neural sequence models are designed to meet the dual mandate of parallelizable training and fast sequential inference. Recent developments have given rise to various models, such as Gated Linear Attention (GLA) and Mamba, that achieve such ``sequential-parallel duality.'' This raises a natura...",
    "published": "Jun 12",
    "pdf_url": "https://arxiv.org/pdf/2506.10918v1",
    "arxiv_url": "http://arxiv.org/abs/2506.10918v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "When Large Language Models are Reliable for Judging Empathic Communication",
    "authors": [
      "Aakriti Kumar",
      "Nalin Poungpeth",
      "Diyi Yang",
      "Erina Farrell",
      "Bruce Lambert",
      "Matthew Groh"
    ],
    "summary": "Large language models (LLMs) excel at generating empathic responses in text-based conversations. But, how reliably do they judge the nuances of empathic communication? We investigate this question by comparing how experts, crowdworkers, and LLMs annotate empathic communication across four evaluative...",
    "published": "Jun 11",
    "pdf_url": "https://arxiv.org/pdf/2506.10150v2",
    "arxiv_url": "http://arxiv.org/abs/2506.10150v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Unsupervised Elicitation of Language Models",
    "authors": [
      "Jiaxin Wen",
      "Zachary Ankner",
      "Arushi Somani",
      "Peter Hase",
      "Samuel Marks",
      "Jacob Goldman-Wetzler",
      "Linda Petrini",
      "Henry Sleight",
      "Collin Burns",
      "He He",
      "Shi Feng",
      "Ethan Perez",
      "Jan Leike"
    ],
    "summary": "To steer pretrained language models for downstream tasks, today's post-training paradigm relies on humans to specify desired behaviors. However, for models with superhuman capabilities, it is difficult or impossible to get high-quality human supervision. To address this challenge, we introduce a new...",
    "published": "Jun 11",
    "pdf_url": "https://arxiv.org/pdf/2506.10139v1",
    "arxiv_url": "http://arxiv.org/abs/2506.10139v1",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez"
    ]
  },
  {
    "title": "Query-Focused Retrieval Heads Improve Long-Context Reasoning and Re-ranking",
    "authors": [
      "Wuwei Zhang",
      "Fangcong Yin",
      "Howard Yen",
      "Danqi Chen",
      "Xi Ye"
    ],
    "summary": "Recent work has identified retrieval heads, a subset of attention heads responsible for retrieving salient information in long-context language models (LMs), as measured by their copy-paste behavior in Needlein-a-Haystack tasks. In this paper, we introduce QRHead (Query-Focused Retrieval Head), an i...",
    "published": "Jun 11",
    "pdf_url": "https://arxiv.org/pdf/2506.09944v2",
    "arxiv_url": "http://arxiv.org/abs/2506.09944v2",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "Learning to Reason Across Parallel Samples for LLM Reasoning",
    "authors": [
      "Jianing Qi",
      "Xi Ye",
      "Hao Tang",
      "Zhigang Zhu",
      "Eunsol Choi"
    ],
    "summary": "Scaling test-time compute brings substantial performance gains for large language models (LLMs). By sampling multiple answers and heuristically aggregate their answers (e.g., either through majority voting or using verifiers to rank the answers), one can achieve consistent performance gains in math ...",
    "published": "Jun 10",
    "pdf_url": "https://arxiv.org/pdf/2506.09014v2",
    "arxiv_url": "http://arxiv.org/abs/2506.09014v2",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "CAIRe: Cultural Attribution of Images by Retrieval-Augmented Evaluation",
    "authors": [
      "Arnav Yayavaram",
      "Siddharth Yayavaram",
      "Simran Khanuja",
      "Michael Saxon",
      "Graham Neubig"
    ],
    "summary": "As text-to-image models become increasingly prevalent, ensuring their equitable performance across diverse cultural contexts is critical. Efforts to mitigate cross-cultural biases have been hampered by trade-offs, including a loss in performance, factual inaccuracies, or offensive outputs. Despite w...",
    "published": "Jun 10",
    "pdf_url": "https://arxiv.org/pdf/2506.09109v2",
    "arxiv_url": "http://arxiv.org/abs/2506.09109v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions",
    "authors": [
      "David Acuna",
      "Ximing Lu",
      "Jaehun Jung",
      "Hyunwoo Kim",
      "Amlan Kar",
      "Sanja Fidler",
      "Yejin Choi"
    ],
    "summary": "Recent research in vision-language models (VLMs) has centered around the possibility of equipping them with implicit long-form chain-of-thought reasoning -- akin to the success observed in language models -- via distillation and reinforcement learning. But what about the non-reasoning models already...",
    "published": "Jun 10",
    "pdf_url": "https://arxiv.org/pdf/2506.08927v1",
    "arxiv_url": "http://arxiv.org/abs/2506.08927v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs",
    "authors": [
      "Zeyu Leo Liu",
      "Greg Durrett",
      "Eunsol Choi"
    ],
    "summary": "Knowledge editing techniques for large language models (LLMs) can inject knowledge that is later reproducible verbatim, but they fall short on propagating that knowledge: models cannot answer questions that require reasoning with the injected knowledge. We present a hypernetwork-based approach for k...",
    "published": "Jun 10",
    "pdf_url": "https://arxiv.org/pdf/2506.08920v1",
    "arxiv_url": "http://arxiv.org/abs/2506.08920v1",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi",
      "Greg Durrett"
    ]
  },
  {
    "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?",
    "authors": [
      "Zhanke Zhou",
      "Xiao Feng",
      "Zhaocheng Zhu",
      "Jiangchao Yao",
      "Sanmi Koyejo",
      "Bo Han"
    ],
    "summary": "While existing benchmarks probe the reasoning abilities of large language models (LLMs) across diverse domains, they predominantly assess passive reasoning, providing models with all the information needed to reach a solution. By contrast, active reasoning-where an LLM must interact with external sy...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.08295v1",
    "arxiv_url": "http://arxiv.org/abs/2506.08295v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Cost-Optimal Active AI Model Evaluation",
    "authors": [
      "Anastasios N. Angelopoulos",
      "Jacob Eisenstein",
      "Jonathan Berant",
      "Alekh Agarwal",
      "Adam Fisch"
    ],
    "summary": "The development lifecycle of generative AI systems requires continual evaluation, data acquisition, and annotation, which is costly in both resources and time. In practice, rapid iteration often makes it necessary to rely on synthetic annotation data because of the low cost, despite the potential fo...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.07949v1",
    "arxiv_url": "http://arxiv.org/abs/2506.07949v1",
    "queried_author": "Jacob Eisenstein",
    "matching_authors": [
      "Jacob Eisenstein"
    ]
  },
  {
    "title": "Accelerating Diffusion Planners in Offline RL via Reward-Aware Consistency Trajectory Distillation",
    "authors": [
      "Xintong Duan",
      "Yutong He",
      "Fahim Tajwar",
      "Ruslan Salakhutdinov",
      "J. Zico Kolter",
      "Jeff Schneider"
    ],
    "summary": "Although diffusion models have achieved strong results in decision-making tasks, their slow inference speed remains a key limitation. While consistency models offer a potential solution, existing applications to decision-making either struggle with suboptimal demonstrations under behavior cloning or...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.07822v2",
    "arxiv_url": "http://arxiv.org/abs/2506.07822v2",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking",
    "authors": [
      "Silin Gao",
      "Antoine Bosselut",
      "Samy Bengio",
      "Emmanuel Abbe"
    ],
    "summary": "Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in grade school math (GSM) reasoning. In particular, they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insert...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.07751v3",
    "arxiv_url": "http://arxiv.org/abs/2506.07751v3",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Premise Selection for a Lean Hammer",
    "authors": [
      "Thomas Zhu",
      "Joshua Clune",
      "Jeremy Avigad",
      "Albert Qiaochu Jiang",
      "Sean Welleck"
    ],
    "summary": "Neural methods are transforming automated reasoning for proof assistants, yet integrating these advances into practical verification workflows remains challenging. Hammers are tools that interface with external automatic theorem provers to automate tedious reasoning steps. They have dramatically imp...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.07477v1",
    "arxiv_url": "http://arxiv.org/abs/2506.07477v1",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models",
    "authors": [
      "Mickel Liu",
      "Liwei Jiang",
      "Yancheng Liang",
      "Simon Shaolei Du",
      "Yejin Choi",
      "Tim Althoff",
      "Natasha Jaques"
    ],
    "summary": "Conventional language model (LM) safety alignment relies on a reactive, disjoint procedure: attackers exploit a static model, followed by defensive fine-tuning to patch exposed vulnerabilities. This sequential approach creates a mismatch -- attackers overfit to obsolete defenses, while defenders per...",
    "published": "Jun 09",
    "pdf_url": "https://arxiv.org/pdf/2506.07468v3",
    "arxiv_url": "http://arxiv.org/abs/2506.07468v3",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Certified Unlearning for Neural Networks",
    "authors": [
      "Anastasia Koloskova",
      "Youssef Allouah",
      "Animesh Jha",
      "Rachid Guerraoui",
      "Sanmi Koyejo"
    ],
    "summary": "We address the problem of machine unlearning, where the goal is to remove the influence of specific training data from a model upon request, motivated by privacy concerns and regulatory requirements such as the \"right to be forgotten.\" Unfortunately, existing methods rely on restrictive assumptions ...",
    "published": "Jun 08",
    "pdf_url": "https://arxiv.org/pdf/2506.06985v2",
    "arxiv_url": "http://arxiv.org/abs/2506.06985v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Causal Graph based Event Reasoning using Semantic Relation Experts",
    "authors": [
      "Mahnaz Koupaee",
      "Xueying Bai",
      "Mudan Chen",
      "Greg Durrett",
      "Nathanael Chambers",
      "Niranjan Balasubramanian"
    ],
    "summary": "Understanding how events in a scenario causally connect with each other is important for effectively modeling and reasoning about events. But event reasoning remains a difficult challenge, and despite recent advances, Large Language Models (LLMs) still struggle to accurately identify causal connecti...",
    "published": "Jun 07",
    "pdf_url": "https://arxiv.org/pdf/2506.06910v1",
    "arxiv_url": "http://arxiv.org/abs/2506.06910v1",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Transferring Linear Features Across Language Models With Model Stitching",
    "authors": [
      "Alan Chen",
      "Jack Merullo",
      "Alessandro Stolfo",
      "Ellie Pavlick"
    ],
    "summary": "In this work, we demonstrate that affine mappings between residual streams of language models is a cheap way to effectively transfer represented features between models. We apply this technique to transfer the weights of Sparse Autoencoders (SAEs) between models of different sizes to compare their r...",
    "published": "Jun 07",
    "pdf_url": "https://arxiv.org/pdf/2506.06609v3",
    "arxiv_url": "http://arxiv.org/abs/2506.06609v3",
    "queried_author": "Jack Merullo",
    "matching_authors": [
      "Jack Merullo"
    ]
  },
  {
    "title": "Precise Information Control in Long-Form Text Generation",
    "authors": [
      "Jacqueline He",
      "Howard Yen",
      "Margaret Li",
      "Shuyue Stella Li",
      "Zhiyuan Zeng",
      "Weijia Shi",
      "Yulia Tsvetkov",
      "Danqi Chen",
      "Pang Wei Koh",
      "Luke Zettlemoyer"
    ],
    "summary": "A central challenge in language models (LMs) is faithfulness hallucination: the generation of information unsubstantiated by input context. To study this problem, we propose Precise Information Control (PIC), a new task formulation that requires models to generate long-form outputs grounded in a pro...",
    "published": "Jun 06",
    "pdf_url": "https://arxiv.org/pdf/2506.06589v2",
    "arxiv_url": "http://arxiv.org/abs/2506.06589v2",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen",
      "Luke Zettlemoyer",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce",
    "authors": [
      "Yijia Shao",
      "Humishka Zope",
      "Yucheng Jiang",
      "Jiaxin Pei",
      "David Nguyen",
      "Erik Brynjolfsson",
      "Diyi Yang"
    ],
    "summary": "The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the labor market, raising concerns about job displacement, diminished human agency, and overreliance on automation. Yet, we lack a systematic understanding of the evolving landscape. In this paper, we address this gap by introduc...",
    "published": "Jun 06",
    "pdf_url": "https://arxiv.org/pdf/2506.06576v2",
    "arxiv_url": "http://arxiv.org/abs/2506.06576v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "The Optimization Paradox in Clinical AI Multi-Agent Systems",
    "authors": [
      "Suhana Bedi",
      "Iddah Mlauzi",
      "Daniel Shin",
      "Sanmi Koyejo",
      "Nigam H. Shah"
    ],
    "summary": "Multi-agent artificial intelligence systems are increasingly deployed in clinical settings, yet the relationship between component-level optimization and system-wide performance remains poorly understood. We evaluated this relationship using 2,400 real patient cases from the MIMIC-CDM dataset across...",
    "published": "Jun 06",
    "pdf_url": "https://arxiv.org/pdf/2506.06574v2",
    "arxiv_url": "http://arxiv.org/abs/2506.06574v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Cartridges: Lightweight and general-purpose long context representations via self-study",
    "authors": [
      "Sabri Eyuboglu",
      "Ryan Ehrlich",
      "Simran Arora",
      "Neel Guha",
      "Dylan Zinsley",
      "Emily Liu",
      "Will Tennien",
      "Atri Rudra",
      "James Zou",
      "Azalia Mirhoseini",
      "Christopher Re"
    ],
    "summary": "Large language models are often used to answer queries grounded in large text corpora (e.g. codebases, legal documents, or chat histories) by placing the entire corpus in the context window and leveraging in-context learning (ICL). Although current models support contexts of 100K-1M tokens, this set...",
    "published": "Jun 06",
    "pdf_url": "https://arxiv.org/pdf/2506.06266v3",
    "arxiv_url": "http://arxiv.org/abs/2506.06266v3",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "When to Trust Context: Self-Reflective Debates for Context Reliability",
    "authors": [
      "Zeqi Zhou",
      "Fang Wu",
      "Shayan Talaei",
      "Haokai Zhao",
      "Cheng Meixin",
      "Tinson Xu",
      "Amin Saberi",
      "Yejin Choi"
    ],
    "summary": "Large language models frequently encounter conflicts between their parametric knowledge and contextual input, often resulting in factual inconsistencies or hallucinations. We propose Self-Reflective Debate for Contextual Reliability (SR-DCR), a lightweight framework that integrates token-level self-...",
    "published": "Jun 06",
    "pdf_url": "https://arxiv.org/pdf/2506.06020v1",
    "arxiv_url": "http://arxiv.org/abs/2506.06020v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs",
    "authors": [
      "Michael J Ryan",
      "Omar Shaikh",
      "Aditri Bhagirath",
      "Daniel Frees",
      "William Held",
      "Diyi Yang"
    ],
    "summary": "Recent calls for pluralistic alignment of Large Language Models (LLMs) encourage adapting models to diverse user preferences. However, most prior work on personalized reward models heavily rely on additional identity information, such as demographic details or a predefined set of preference categori...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.05598v1",
    "arxiv_url": "http://arxiv.org/abs/2506.05598v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang",
      "William Held"
    ]
  },
  {
    "title": "When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration",
    "authors": [
      "Quan Shi",
      "Carlos E. Jimenez",
      "Shunyu Yao",
      "Nick Haber",
      "Diyi Yang",
      "Karthik Narasimhan"
    ],
    "summary": "Recent advancements in AI reasoning have driven substantial improvements across diverse tasks. A critical open question is whether these improvements also yields better knowledge transfer: the ability of models to communicate reasoning in ways humans can understand, apply, and learn from. To investi...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.05579v2",
    "arxiv_url": "http://arxiv.org/abs/2506.05579v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning",
    "authors": [
      "Violet Xiang",
      "Chase Blagden",
      "Rafael Rafailov",
      "Nathan Lile",
      "Sang Truong",
      "Chelsea Finn",
      "Nick Haber"
    ],
    "summary": "Large reasoning models (LRMs) achieve higher performance on challenging reasoning tasks by generating more tokens at inference time, but this verbosity often wastes computation on easy problems. Existing solutions, including supervised finetuning on shorter traces, user-controlled budgets, or RL wit...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.05256v2",
    "arxiv_url": "http://arxiv.org/abs/2506.05256v2",
    "queried_author": "Rafael Rafailov",
    "matching_authors": [
      "Rafael Rafailov"
    ]
  },
  {
    "title": "The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text",
    "authors": [
      "Nikhil Kandpal",
      "Brian Lester",
      "Colin Raffel",
      "Sebastian Majstorovic",
      "Stella Biderman",
      "Baber Abbasi",
      "Luca Soldaini",
      "Enrico Shippole",
      "A. Feder Cooper",
      "Aviya Skowron",
      "John Kirchenbauer",
      "Shayne Longpre",
      "Lintang Sutawika",
      "Alon Albalak",
      "Zhenlin Xu",
      "Guilherme Penedo",
      "Loubna Ben Allal",
      "Elie Bakouch",
      "John David Pressman",
      "Honglu Fan",
      "Dashiell Stander",
      "Guangyu Song",
      "Aaron Gokaslan",
      "Tom Goldstein",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Tyler Murray"
    ],
    "summary": "Large language models (LLMs) are typically trained on enormous quantities of unlicensed text, a practice that has led to scrutiny due to possible intellectual property infringement and ethical concerns. Training LLMs on openly licensed text presents a first step towards addressing these issues, but ...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.05209v1",
    "arxiv_url": "http://arxiv.org/abs/2506.05209v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel",
      "Luca Soldaini"
    ]
  },
  {
    "title": "Log-Linear Attention",
    "authors": [
      "Han Guo",
      "Songlin Yang",
      "Tarushii Goel",
      "Eric P. Xing",
      "Tri Dao",
      "Yoon Kim"
    ],
    "summary": "The attention mechanism in Transformers is an important primitive for accurate and scalable sequence modeling. Its quadratic-compute and linear-memory complexity however remain significant bottlenecks. Linear attention and state-space models enable linear-time, constant-memory sequence modeling and ...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.04761v2",
    "arxiv_url": "http://arxiv.org/abs/2506.04761v2",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat",
    "authors": [
      "Yuru Jiang",
      "Wenxuan Ding",
      "Shangbin Feng",
      "Greg Durrett",
      "Yulia Tsvetkov"
    ],
    "summary": "We propose SPARTA ALIGNMENT, an algorithm to collectively align multiple LLMs through competition and combat. To complement a single model's lack of diversity in generation and biases in evaluation, multiple LLMs form a \"sparta tribe\" to compete against each other in fulfilling instructions while se...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.04721v3",
    "arxiv_url": "http://arxiv.org/abs/2506.04721v3",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Line of Sight: On Linear Representations in VLLMs",
    "authors": [
      "Achyuta Rajaram",
      "Sarah Schwettmann",
      "Jacob Andreas",
      "Arthur Conmy"
    ],
    "summary": "Language models can be equipped with multimodal capabilities by fine-tuning on embeddings of visual inputs. But how do such multimodal models represent images in their hidden activations? We explore representations of image concepts within LlaVA-Next, a popular open-source VLLM. We find a diverse se...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.04706v1",
    "arxiv_url": "http://arxiv.org/abs/2506.04706v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
    "authors": [
      "Thao Nguyen",
      "Yang Li",
      "Olga Golovneva",
      "Luke Zettlemoyer",
      "Sewoong Oh",
      "Ludwig Schmidt",
      "Xian Li"
    ],
    "summary": "Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not...",
    "published": "Jun 05",
    "pdf_url": "https://arxiv.org/pdf/2506.04689v3",
    "arxiv_url": "http://arxiv.org/abs/2506.04689v3",
    "queried_author": "Ludwig Schmidt",
    "matching_authors": [
      "Ludwig Schmidt",
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation",
    "authors": [
      "Hermann Kumbong",
      "Xian Liu",
      "Tsung-Yi Lin",
      "Ming-Yu Liu",
      "Xihui Liu",
      "Ziwei Liu",
      "Daniel Y. Fu",
      "Christopher R\u00e9",
      "David W. Romero"
    ],
    "summary": "Visual Auto-Regressive modeling (VAR) has shown promise in bridging the speed and quality gap between autoregressive image models and diffusion models. VAR reformulates autoregressive modeling by decomposing an image into successive resolution scales. During inference, an image is generated by predi...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.04421v1",
    "arxiv_url": "http://arxiv.org/abs/2506.04421v1",
    "queried_author": "Christopher R\u00e9",
    "matching_authors": [
      "Christopher R\u00e9"
    ]
  },
  {
    "title": "Understanding challenges to the interpretation of disaggregated evaluations of algorithmic fairness",
    "authors": [
      "Stephen R. Pfohl",
      "Natalie Harris",
      "Chirag Nagpal",
      "David Madras",
      "Vishwali Mhasawade",
      "Olawale Salaudeen",
      "Awa Dieng",
      "Shannon Sequeira",
      "Santiago Arciniegas",
      "Lillian Sung",
      "Nnamdi Ezeanochie",
      "Heather Cole-Lewis",
      "Katherine Heller",
      "Sanmi Koyejo",
      "Alexander D'Amour"
    ],
    "summary": "Disaggregated evaluation across subgroups is critical for assessing the fairness of machine learning models, but its uncritical use can mislead practitioners. We show that equal performance across subgroups is an unreliable measure of fairness when data are representative of the relevant populations...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.04193v2",
    "arxiv_url": "http://arxiv.org/abs/2506.04193v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "OpenThoughts: Data Recipes for Reasoning Models",
    "authors": [
      "Etash Guha",
      "Ryan Marten",
      "Sedrick Keh",
      "Negin Raoof",
      "Georgios Smyrnis",
      "Hritik Bansal",
      "Marianna Nezhurina",
      "Jean Mercat",
      "Trung Vu",
      "Zayne Sprague",
      "Ashima Suvarna",
      "Benjamin Feuer",
      "Liangyu Chen",
      "Zaid Khan",
      "Eric Frankel",
      "Sachin Grover",
      "Caroline Choi",
      "Niklas Muennighoff",
      "Shiye Su",
      "Wanjia Zhao",
      "John Yang",
      "Shreyas Pimpalgaonkar",
      "Kartik Sharma",
      "Charlie Cheng-Jie Ji",
      "Yichuan Deng",
      "Sarah Pratt",
      "Vivek Ramanujan",
      "Jon Saad-Falcon",
      "Jeffrey Li",
      "Achal Dave",
      "Alon Albalak",
      "Kushal Arora",
      "Blake Wulfe",
      "Chinmay Hegde",
      "Greg Durrett",
      "Sewoong Oh",
      "Mohit Bansal",
      "Saadia Gabriel",
      "Aditya Grover",
      "Kai-Wei Chang",
      "Vaishaal Shankar",
      "Aaron Gokaslan",
      "Mike A. Merrill",
      "Tatsunori Hashimoto",
      "Yejin Choi",
      "Jenia Jitsev",
      "Reinhard Heckel",
      "Maheswaran Sathiamoorthy",
      "Alexandros G. Dimakis",
      "Ludwig Schmidt"
    ],
    "summary": "Reasoning models have made rapid progress on many benchmarks involving math, code, and science. Yet, there are still many open questions about the best training recipes for reasoning since state-of-the-art models often rely on proprietary datasets with little to no public information available. To a...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.04178v2",
    "arxiv_url": "http://arxiv.org/abs/2506.04178v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett",
      "Ludwig Schmidt",
      "Niklas Muennighoff",
      "Yejin Choi"
    ]
  },
  {
    "title": "High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning",
    "authors": [
      "Tim Franzmeyer",
      "Archie Sravankumar",
      "Lijuan Liu",
      "Yuning Mao",
      "Rui Hou",
      "Sinong Wang",
      "Jakob N. Foerster",
      "Luke Zettlemoyer",
      "Madian Khabsa"
    ],
    "summary": "Large Language Models (LLMs) currently respond to every prompt. However, they can produce incorrect answers when they lack knowledge or capability -- a problem known as hallucination. We instead propose post-training an LLM to generate content only when confident in its correctness and to otherwise ...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.04051v1",
    "arxiv_url": "http://arxiv.org/abs/2506.04051v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models",
    "authors": [
      "Alex Laitenberger",
      "Christopher D. Manning",
      "Nelson F. Liu"
    ],
    "summary": "With the rise of long-context language models (LMs) capable of processing tens of thousands of tokens in a single pass, do multi-stage retrieval-augmented generation (RAG) pipelines still offer measurable benefits over simpler, single-stage approaches? To assess this question, we conduct a controlle...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.03989v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03989v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning",
      "Nelson F. Liu"
    ]
  },
  {
    "title": "Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations",
    "authors": [
      "Vivian Nguyen",
      "Lillian Lee",
      "Cristian Danescu-Niculescu-Mizil"
    ],
    "summary": "During a conversation, there can come certain moments where its outcome hangs in the balance. In these pivotal moments, how one responds can put the conversation on substantially different trajectories leading to significantly different outcomes. Systems that can detect when such moments arise could...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.03941v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03941v1",
    "queried_author": "Lillian Lee",
    "matching_authors": [
      "Lillian Lee"
    ]
  },
  {
    "title": "Go-Browse: Training Web Agents with Structured Exploration",
    "authors": [
      "Apurva Gandhi",
      "Graham Neubig"
    ],
    "summary": "One of the fundamental problems in digital agents is their lack of understanding of their environment. For instance, a web browsing agent may get lost in unfamiliar websites, uncertain what pages must be visited to achieve its goals. To address this, we propose Go-Browse, a method for automatically ...",
    "published": "Jun 04",
    "pdf_url": "https://arxiv.org/pdf/2506.03533v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03533v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Adversarial Attacks on Robotic Vision Language Action Models",
    "authors": [
      "Eliot Krzysztof Jones",
      "Alexander Robey",
      "Andy Zou",
      "Zachary Ravichandran",
      "George J. Pappas",
      "Hamed Hassani",
      "Matt Fredrikson",
      "J. Zico Kolter"
    ],
    "summary": "The emergence of vision-language-action models (VLAs) for end-to-end control is reshaping the field of robotics by enabling the fusion of multimodal sensory inputs at the billion-parameter scale. The capabilities of VLAs stem primarily from their architectures, which are often based on frontier larg...",
    "published": "Jun 03",
    "pdf_url": "https://arxiv.org/pdf/2506.03350v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03350v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "HyperSteer: Activation Steering at Scale with Hypernetworks",
    "authors": [
      "Jiuding Sun",
      "Sidharth Baskaran",
      "Zhengxuan Wu",
      "Michael Sklar",
      "Christopher Potts",
      "Atticus Geiger"
    ],
    "summary": "Steering language models (LMs) by modifying internal activations is a popular approach for controlling text generation. Unsupervised dictionary learning methods, e.g., sparse autoencoders, can be scaled to produce many steering vectors, but lack guarantees on the individual efficacy of each vector a...",
    "published": "Jun 03",
    "pdf_url": "https://arxiv.org/pdf/2506.03292v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03292v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "Coding Agents with Multimodal Browsing are Generalist Problem Solvers",
    "authors": [
      "Aditya Bharat Soni",
      "Boxuan Li",
      "Xingyao Wang",
      "Valerie Chen",
      "Graham Neubig"
    ],
    "summary": "Modern human labor is characterized by specialization; we train for years and develop particular tools that allow us to perform well across a variety of tasks. In addition, AI agents have been specialized for domains such as software engineering, web navigation, and workflow automation. However, thi...",
    "published": "Jun 03",
    "pdf_url": "https://arxiv.org/pdf/2506.03011v1",
    "arxiv_url": "http://arxiv.org/abs/2506.03011v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Rewarding the Unlikely: Lifting GRPO Beyond Distribution Sharpening",
    "authors": [
      "Andre He",
      "Daniel Fried",
      "Sean Welleck"
    ],
    "summary": "Reinforcement learning is emerging as a primary driver for improving language model reasoning capabilities. A fundamental question is whether current reinforcement learning algorithms -- such as Group Relative Policy Optimization (GRPO), the de facto standard algorithm used to improve language model...",
    "published": "Jun 03",
    "pdf_url": "https://arxiv.org/pdf/2506.02355v2",
    "arxiv_url": "http://arxiv.org/abs/2506.02355v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models",
    "authors": [
      "Lindia Tjuatja",
      "Graham Neubig"
    ],
    "summary": "Language model evaluation is a daunting task: prompts are brittle, corpus-level perplexities are vague, and the choice of benchmarks are endless. Finding examples that show meaningful, generalizable differences between two LMs is crucial to understanding where one model succeeds and another fails. C...",
    "published": "Jun 02",
    "pdf_url": "https://arxiv.org/pdf/2506.02204v2",
    "arxiv_url": "http://arxiv.org/abs/2506.02204v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "AI Debate Aids Assessment of Controversial Claims",
    "authors": [
      "Salman Rahman",
      "Sheriff Issaka",
      "Ashima Suvarna",
      "Genglin Liu",
      "James Shiffer",
      "Jaeyoung Lee",
      "Md Rizwan Parvez",
      "Hamid Palangi",
      "Shi Feng",
      "Nanyun Peng",
      "Yejin Choi",
      "Julian Michael",
      "Liwei Jiang",
      "Saadia Gabriel"
    ],
    "summary": "As AI grows more powerful, it will increasingly shape how we understand the world. But with this influence comes the risk of amplifying misinformation and deepening social divides-especially on consequential topics where factual accuracy directly impacts well-being. Scalable Oversight aims to ensure...",
    "published": "Jun 02",
    "pdf_url": "https://arxiv.org/pdf/2506.02175v2",
    "arxiv_url": "http://arxiv.org/abs/2506.02175v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "RewardBench 2: Advancing Reward Model Evaluation",
    "authors": [
      "Saumya Malik",
      "Valentina Pyatkin",
      "Sander Land",
      "Jacob Morrison",
      "Noah A. Smith",
      "Hannaneh Hajishirzi",
      "Nathan Lambert"
    ],
    "summary": "Reward models are used throughout the post-training of language models to capture nuanced signals from preference data and provide a training target for optimization across instruction following, reasoning, safety, and more domains. The community has begun establishing best practices for evaluating ...",
    "published": "Jun 02",
    "pdf_url": "https://arxiv.org/pdf/2506.01937v1",
    "arxiv_url": "http://arxiv.org/abs/2506.01937v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Noah A. Smith"
    ]
  },
  {
    "title": "Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability",
    "authors": [
      "Genta Indra Winata",
      "David Anugraha",
      "Emmy Liu",
      "Alham Fikri Aji",
      "Shou-Yi Hung",
      "Aditya Parashar",
      "Patrick Amadeus Irawan",
      "Ruochen Zhang",
      "Zheng-Xin Yong",
      "Jan Christian Blaise Cruz",
      "Niklas Muennighoff",
      "Seungone Kim",
      "Hanyang Zhao",
      "Sudipta Kar",
      "Kezia Erina Suryoraharjo",
      "M. Farid Adilazuarda",
      "En-Shiun Annie Lee",
      "Ayu Purwarianti",
      "Derry Tanti Wijaya",
      "Monojit Choudhury"
    ],
    "summary": "High-quality datasets are fundamental to training and evaluating machine learning models, yet their creation-especially with accurate human annotations-remains a significant challenge. Many dataset paper submissions lack originality, diversity, or rigorous quality control, and these shortcomings are...",
    "published": "Jun 02",
    "pdf_url": "https://arxiv.org/pdf/2506.01789v2",
    "arxiv_url": "http://arxiv.org/abs/2506.01789v2",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff",
      "Seungone Kim"
    ]
  },
  {
    "title": "The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning",
    "authors": [
      "Xinyu Zhu",
      "Mengzhou Xia",
      "Zhepei Wei",
      "Wei-Lin Chen",
      "Danqi Chen",
      "Yu Meng"
    ],
    "summary": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach for training language models (LMs) on reasoning tasks that elicit emergent long chains of thought (CoTs). Unlike supervised learning, it updates the model using both correct and incorrect samples via policy gradients. To b...",
    "published": "Jun 02",
    "pdf_url": "https://arxiv.org/pdf/2506.01347v2",
    "arxiv_url": "http://arxiv.org/abs/2506.01347v2",
    "queried_author": "Danqi Chen",
    "matching_authors": [
      "Danqi Chen"
    ]
  },
  {
    "title": "Existing Large Language Model Unlearning Evaluations Are Inconclusive",
    "authors": [
      "Zhili Feng",
      "Yixuan Even Xu",
      "Alexander Robey",
      "Robert Kirk",
      "Xander Davies",
      "Yarin Gal",
      "Avi Schwarzschild",
      "J. Zico Kolter"
    ],
    "summary": "Machine unlearning aims to remove sensitive or undesired data from large language models. However, recent studies suggest that unlearning is often shallow, claiming that removed knowledge can easily be recovered. In this work, we critically examine standard unlearning evaluation practices and uncove...",
    "published": "May 31",
    "pdf_url": "https://arxiv.org/pdf/2506.00688v1",
    "arxiv_url": "http://arxiv.org/abs/2506.00688v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "WorldGym: World Model as An Environment for Policy Evaluation",
    "authors": [
      "Julian Quevedo",
      "Ansh Kumar Sharma",
      "Yixiang Sun",
      "Varad Suryavanshi",
      "Percy Liang",
      "Sherry Yang"
    ],
    "summary": "Evaluating robot control policies is difficult: real-world testing is costly, and handcrafted simulators require manual effort to improve in realism and generality. We propose a world-model-based policy evaluation environment (WorldGym), an autoregressive, action-conditioned video generation model w...",
    "published": "May 31",
    "pdf_url": "https://arxiv.org/pdf/2506.00613v3",
    "arxiv_url": "http://arxiv.org/abs/2506.00613v3",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences",
    "authors": [
      "Mingqian Zheng",
      "Wenjia Hu",
      "Patrick Zhao",
      "Motahhare Eslami",
      "Jena D. Hwang",
      "Faeze Brahman",
      "Carolyn Rose",
      "Maarten Sap"
    ],
    "summary": "Current LLMs are trained to refuse potentially harmful input queries regardless of whether users actually had harmful intents, causing a tradeoff between safety and user experience. Through a study of 480 participants evaluating 3,840 query-response pairs, we examine how different refusal strategies...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2506.00195v2",
    "arxiv_url": "http://arxiv.org/abs/2506.00195v2",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents",
    "authors": [
      "Kaivalya Hariharan",
      "Uzay Girit",
      "Atticus Wang",
      "Jacob Andreas"
    ],
    "summary": "Benchmarks for large language models (LLMs) have predominantly assessed short-horizon, localized reasoning. Existing long-horizon suites (e.g. SWE-bench) rely on manually curated issues, so expanding or tuning difficulty demands expensive human effort and evaluations quickly saturate. However, many ...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2506.00172v1",
    "arxiv_url": "http://arxiv.org/abs/2506.00172v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models",
    "authors": [
      "Mingjie Liu",
      "Shizhe Diao",
      "Ximing Lu",
      "Jian Hu",
      "Xin Dong",
      "Yejin Choi",
      "Jan Kautz",
      "Yi Dong"
    ],
    "summary": "Recent advances in reasoning-centric language models have highlighted reinforcement learning (RL) as a promising method for aligning models with verifiable rewards. However, it remains contentious whether RL truly expands a model's reasoning capabilities or merely amplifies high-reward outputs alrea...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2505.24864v1",
    "arxiv_url": "http://arxiv.org/abs/2505.24864v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "How much do language models memorize?",
    "authors": [
      "John X. Morris",
      "Chawin Sitawarin",
      "Chuan Guo",
      "Narine Kokhlikyan",
      "G. Edward Suh",
      "Alexander M. Rush",
      "Kamalika Chaudhuri",
      "Saeed Mahloujifar"
    ],
    "summary": "We propose a new method for estimating how much a model knows about a datapoint and use it to measure the capacity of modern language models. Prior studies of language model memorization have struggled to disentangle memorization from generalization. We formally separate memorization into two compon...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2505.24832v3",
    "arxiv_url": "http://arxiv.org/abs/2505.24832v3",
    "queried_author": "Alexander M Rush",
    "matching_authors": [
      "Alexander M Rush",
      "Alexander M. Rush"
    ]
  },
  {
    "title": "Drop Dropout on Single-Epoch Language Model Pretraining",
    "authors": [
      "Houjun Liu",
      "John Bauer",
      "Christopher D. Manning"
    ],
    "summary": "Originally, dropout was seen as a breakthrough regularization technique that reduced overfitting and improved performance in almost all applications of deep learning by reducing overfitting. Yet, single-epoch pretraining tasks common to modern LLMs yield minimal overfitting, leading to dropout not b...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2505.24788v1",
    "arxiv_url": "http://arxiv.org/abs/2505.24788v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models",
    "authors": [
      "Yike Wang",
      "Shangbin Feng",
      "Yulia Tsvetkov",
      "Hannaneh Hajishirzi"
    ],
    "summary": "Large Language Models (LLMs) are increasingly used to support scientific research, but their knowledge of scientific advancements can quickly become outdated. We introduce ScienceMeter, a new framework for evaluating scientific knowledge update methods over scientific knowledge spanning the past, pr...",
    "published": "May 30",
    "pdf_url": "https://arxiv.org/pdf/2505.24302v2",
    "arxiv_url": "http://arxiv.org/abs/2505.24302v2",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Critical Batch Size Revisited: A Simple Empirical Approach to Large-Batch Language Model Training",
    "authors": [
      "William Merrill",
      "Shane Arora",
      "Dirk Groeneveld",
      "Hannaneh Hajishirzi"
    ],
    "summary": "The right batch size is important when training language models at scale: a large batch size is necessary for fast training, but a batch size that is too large will harm token efficiency. To navigate this tradeoff, McCandlish et al. (2018) suggest that a critical batch size (CBS), below which traini...",
    "published": "May 29",
    "pdf_url": "https://arxiv.org/pdf/2505.23971v3",
    "arxiv_url": "http://arxiv.org/abs/2505.23971v3",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Scaling up the think-aloud method",
    "authors": [
      "Daniel Wurgaft",
      "Ben Prystawski",
      "Kanishk Gandhi",
      "Cedegao E. Zhang",
      "Joshua B. Tenenbaum",
      "Noah D. Goodman"
    ],
    "summary": "The think-aloud method, where participants voice their thoughts as they solve a task, is a valuable source of rich data about human reasoning processes. Yet, it has declined in popularity in contemporary cognitive science, largely because labor-intensive transcription and annotation preclude large s...",
    "published": "May 29",
    "pdf_url": "https://arxiv.org/pdf/2505.23931v1",
    "arxiv_url": "http://arxiv.org/abs/2505.23931v1",
    "queried_author": "Noah Goodman",
    "matching_authors": [
      "Noah Goodman"
    ]
  },
  {
    "title": "OMNIGUARD: An Efficient Approach for AI Safety Moderation Across Languages and Modalities",
    "authors": [
      "Sahil Verma",
      "Keegan Hines",
      "Jeff Bilmes",
      "Charlotte Siska",
      "Luke Zettlemoyer",
      "Hila Gonen",
      "Chandan Singh"
    ],
    "summary": "The emerging capabilities of large language models (LLMs) have sparked concerns about their immediate potential for harmful misuse. The core approach to mitigate these concerns is the detection of harmful queries to the model. Current detection approaches are fallible, and are particularly susceptib...",
    "published": "May 29",
    "pdf_url": "https://arxiv.org/pdf/2505.23856v2",
    "arxiv_url": "http://arxiv.org/abs/2505.23856v2",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Learning Composable Chains-of-Thought",
    "authors": [
      "Fangcong Yin",
      "Zeyu Leo Liu",
      "Liu Leqi",
      "Xi Ye",
      "Greg Durrett"
    ],
    "summary": "A common approach for teaching large language models (LLMs) to reason is to train on chain-of-thought (CoT) traces of in-distribution reasoning problems, but such annotated data is costly to obtain for every problem of interest. We want reasoning models to generalize beyond their training distributi...",
    "published": "May 28",
    "pdf_url": "https://arxiv.org/pdf/2505.22635v1",
    "arxiv_url": "http://arxiv.org/abs/2505.22635v1",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Measuring Sycophancy of Language Models in Multi-turn Dialogues",
    "authors": [
      "Jiseung Hong",
      "Grace Byun",
      "Seungone Kim",
      "Kai Shu",
      "Jinho D. Choi"
    ],
    "summary": "Large Language Models (LLMs) are expected to provide helpful and harmless responses, yet they often exhibit sycophancy--conforming to user beliefs regardless of factual accuracy or ethical soundness. Prior research on sycophancy has primarily focused on single-turn factual correctness, overlooking t...",
    "published": "May 28",
    "pdf_url": "https://arxiv.org/pdf/2505.23840v3",
    "arxiv_url": "http://arxiv.org/abs/2505.23840v3",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Latent Reasoning via Sentence Embedding Prediction",
    "authors": [
      "Hyeonbin Hwang",
      "Byeongguk Jeon",
      "Seungone Kim",
      "Jiyeon Kim",
      "Hoyeon Chang",
      "Sohee Yang",
      "Seungpil Won",
      "Dohaeng Lee",
      "Youbin Ahn",
      "Minjoon Seo"
    ],
    "summary": "Autoregressive language models (LMs) generate one token at a time, yet human reasoning operates over higher-level abstractions - sentences, propositions, and concepts. This contrast raises a central question- Can LMs likewise learn to reason over structured semantic units rather than raw token seque...",
    "published": "May 28",
    "pdf_url": "https://arxiv.org/pdf/2505.22202v2",
    "arxiv_url": "http://arxiv.org/abs/2505.22202v2",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Hardware-Efficient Attention for Fast Decoding",
    "authors": [
      "Ted Zadouri",
      "Hubert Strauss",
      "Tri Dao"
    ],
    "summary": "LLM decoding is bottlenecked for large batches and long contexts by loading the key-value (KV) cache from high-bandwidth memory, which inflates per-token latency, while the sequential nature of decoding limits parallelism. We analyze the interplay among arithmetic intensity, parallelization, and mod...",
    "published": "May 27",
    "pdf_url": "https://arxiv.org/pdf/2505.21487v1",
    "arxiv_url": "http://arxiv.org/abs/2505.21487v1",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "Words Like Knives: Backstory-Personalized Modeling and Detection of Violent Communication",
    "authors": [
      "Jocelyn Shen",
      "Akhila Yerukola",
      "Xuhui Zhou",
      "Cynthia Breazeal",
      "Maarten Sap",
      "Hae Won Park"
    ],
    "summary": "Conversational breakdowns in close relationships are deeply shaped by personal histories and emotional context, yet most NLP research treats conflict detection as a general task, overlooking the relational dynamics that influence how messages are perceived. In this work, we leverage nonviolent commu...",
    "published": "May 27",
    "pdf_url": "https://arxiv.org/pdf/2505.21451v2",
    "arxiv_url": "http://arxiv.org/abs/2505.21451v2",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Improved Representation Steering for Language Models",
    "authors": [
      "Zhengxuan Wu",
      "Qinan Yu",
      "Aryaman Arora",
      "Christopher D. Manning",
      "Christopher Potts"
    ],
    "summary": "Steering methods for language models (LMs) seek to provide fine-grained and interpretable control over model generations by variously changing model inputs, weights, or representations to adjust behavior. Recent work has shown that adjusting weights or representations is often less effective than st...",
    "published": "May 27",
    "pdf_url": "https://arxiv.org/pdf/2505.20809v1",
    "arxiv_url": "http://arxiv.org/abs/2505.20809v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning",
      "Christopher Potts"
    ]
  },
  {
    "title": "MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks",
    "authors": [
      "Suhana Bedi",
      "Hejie Cui",
      "Miguel Fuentes",
      "Alyssa Unell",
      "Michael Wornow",
      "Juan M. Banda",
      "Nikesh Kotecha",
      "Timothy Keyes",
      "Yifan Mai",
      "Mert Oez",
      "Hao Qiu",
      "Shrey Jain",
      "Leonardo Schettini",
      "Mehr Kashyap",
      "Jason Alan Fries",
      "Akshay Swaminathan",
      "Philip Chung",
      "Fateme Nateghi",
      "Asad Aali",
      "Ashwin Nayak",
      "Shivam Vedak",
      "Sneha S. Jain",
      "Birju Patel",
      "Oluseyi Fayanju",
      "Shreya Shah",
      "Ethan Goh",
      "Dong-han Yao",
      "Brian Soetikno",
      "Eduardo Reis",
      "Sergios Gatidis",
      "Vasu Divi",
      "Robson Capasso",
      "Rachna Saralkar",
      "Chia-Chun Chiang",
      "Jenelle Jindal",
      "Tho Pham",
      "Faraz Ghoddusi",
      "Steven Lin",
      "Albert S. Chiou",
      "Christy Hong",
      "Mohana Roy",
      "Michael F. Gensheimer",
      "Hinesh Patel",
      "Kevin Schulman",
      "Dev Dash",
      "Danton Char",
      "Lance Downing",
      "Francois Grolleau",
      "Kameron Black",
      "Bethel Mieso",
      "Aydin Zahedivash",
      "Wen-wai Yim",
      "Harshita Sharma",
      "Tony Lee",
      "Hannah Kirsch",
      "Jennifer Lee",
      "Nerissa Ambers",
      "Carlene Lugtu",
      "Aditya Sharma",
      "Bilal Mawji",
      "Alex Alekseyev",
      "Vicky Zhou",
      "Vikas Kakkar",
      "Jarrod Helzer",
      "Anurang Revri",
      "Yair Bannett",
      "Roxana Daneshjou",
      "Jonathan Chen",
      "Emily Alsentzer",
      "Keith Morse",
      "Nirmal Ravi",
      "Nima Aghaeepour",
      "Vanessa Kennedy",
      "Akshay Chaudhari",
      "Thomas Wang",
      "Sanmi Koyejo",
      "Matthew P. Lungren",
      "Eric Horvitz",
      "Percy Liang",
      "Mike Pfeffer",
      "Nigam H. Shah"
    ],
    "summary": "While large language models (LLMs) achieve near-perfect scores on medical licensing exams, these evaluations inadequately reflect the complexity and diversity of real-world clinical practice. We introduce MedHELM, an extensible evaluation framework for assessing LLM performance for medical tasks wit...",
    "published": "May 26",
    "pdf_url": "https://arxiv.org/pdf/2505.23802v2",
    "arxiv_url": "http://arxiv.org/abs/2505.23802v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang",
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy",
    "authors": [
      "Sebastian Antony Joseph",
      "Syed Murtaza Husain",
      "Stella S. R. Offner",
      "St\u00e9phanie Juneau",
      "Paul Torrey",
      "Adam S. Bolton",
      "Juan P. Farias",
      "Niall Gaffney",
      "Greg Durrett",
      "Junyi Jessy Li"
    ],
    "summary": "Large Language Models (LLMs) are being explored for applications in scientific research, including their capabilities to synthesize literature, answer research questions, generate research ideas, and even conduct computational experiments. Ultimately, our goal is for these to help scientists derive ...",
    "published": "May 26",
    "pdf_url": "https://arxiv.org/pdf/2505.20538v4",
    "arxiv_url": "http://arxiv.org/abs/2505.20538v4",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning",
    "authors": [
      "Jaehun Jung",
      "Seungju Han",
      "Ximing Lu",
      "Skyler Hallinan",
      "David Acuna",
      "Shrimai Prabhumoye",
      "Mostafa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Yejin Choi"
    ],
    "summary": "Effective generalization in language models depends critically on the diversity of their training data. Yet existing diversity metrics often fall short of this goal, relying on surface-level heuristics that are decoupled from model behavior. This motivates us to ask: What kind of diversity in traini...",
    "published": "May 26",
    "pdf_url": "https://arxiv.org/pdf/2505.20161v1",
    "arxiv_url": "http://arxiv.org/abs/2505.20161v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks",
    "authors": [
      "Atsunori Moteki",
      "Shoichi Masui",
      "Fan Yang",
      "Yueqi Song",
      "Yonatan Bisk",
      "Graham Neubig",
      "Ikuo Kusajima",
      "Yasuto Watanabe",
      "Hiroyuki Ishida",
      "Jun Takahashi",
      "Shan Jiang"
    ],
    "summary": "This paper proposes FieldWorkArena, a benchmark for agentic AI targeting real-world field work. With the recent increase in demand for agentic AI, they are required to monitor and report safety and health incidents, as well as manufacturing-related incidents, that may occur in real-world work enviro...",
    "published": "May 26",
    "pdf_url": "https://arxiv.org/pdf/2505.19662v2",
    "arxiv_url": "http://arxiv.org/abs/2505.19662v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Rhapsody: A Dataset for Highlight Detection in Podcasts",
    "authors": [
      "Younghan Park",
      "Anuj Diwan",
      "David Harwath",
      "Eunsol Choi"
    ],
    "summary": "Podcasts have become daily companions for half a billion users. Given the enormous amount of podcast content available, highlights provide a valuable signal that helps viewers get the gist of an episode and decide if they want to invest in listening to it in its entirety. However, identifying highli...",
    "published": "May 26",
    "pdf_url": "https://arxiv.org/pdf/2505.19429v2",
    "arxiv_url": "http://arxiv.org/abs/2505.19429v2",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "Knoll: Creating a Knowledge Ecosystem for Large Language Models",
    "authors": [
      "Dora Zhao",
      "Diyi Yang",
      "Michael S. Bernstein"
    ],
    "summary": "Large language models are designed to encode general purpose knowledge about the world from Internet data. Yet, a wealth of information falls outside this scope -- ranging from personal preferences to organizational policies, from community-specific advice to up-to-date news -- that users want model...",
    "published": "May 25",
    "pdf_url": "https://arxiv.org/pdf/2505.19335v2",
    "arxiv_url": "http://arxiv.org/abs/2505.19335v2",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Enhancing Training Data Attribution with Representational Optimization",
    "authors": [
      "Weiwei Sun",
      "Haokun Liu",
      "Nikhil Kandpal",
      "Colin Raffel",
      "Yiming Yang"
    ],
    "summary": "Training data attribution (TDA) methods aim to measure how training data impacts a model's predictions. While gradient-based attribution methods, such as influence functions, offer theoretical grounding, their computational costs make them impractical for large-scale applications. Representation-bas...",
    "published": "May 24",
    "pdf_url": "https://arxiv.org/pdf/2505.18513v2",
    "arxiv_url": "http://arxiv.org/abs/2505.18513v2",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "VideoGameBench: Can Vision-Language Models complete popular video games?",
    "authors": [
      "Alex L. Zhang",
      "Thomas L. Griffiths",
      "Karthik R. Narasimhan",
      "Ofir Press"
    ],
    "summary": "Vision-language models (VLMs) have achieved strong results on coding and math benchmarks that are challenging for humans, yet their ability to perform tasks that come naturally to humans--such as perception, spatial navigation, and memory management--remains understudied. Real video games are crafte...",
    "published": "May 23",
    "pdf_url": "https://arxiv.org/pdf/2505.18134v2",
    "arxiv_url": "http://arxiv.org/abs/2505.18134v2",
    "queried_author": "Karthik R Narasimhan",
    "matching_authors": [
      "Karthik R Narasimhan"
    ]
  },
  {
    "title": "Knot So Simple: A Minimalistic Environment for Spatial Reasoning",
    "authors": [
      "Zizhao Chen",
      "Yoav Artzi"
    ],
    "summary": "We propose KnotGym, an interactive environment for complex, spatial reasoning and manipulation. KnotGym includes goal-oriented rope manipulation tasks with varying levels of complexity, all requiring acting from pure image observations. Tasks are defined along a clear and quantifiable axis of comple...",
    "published": "May 23",
    "pdf_url": "https://arxiv.org/pdf/2505.18028v2",
    "arxiv_url": "http://arxiv.org/abs/2505.18028v2",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Inference-Time Decomposition of Activations (ITDA): A Scalable Approach to Interpreting Large Language Models",
    "authors": [
      "Patrick Leask",
      "Neel Nanda",
      "Noura Al Moubayed"
    ],
    "summary": "Sparse autoencoders (SAEs) are a popular method for decomposing Large Langage Models (LLM) activations into interpretable latents. However, due to their substantial training cost, most academic research uses open-source SAEs which are only available for a restricted set of models of up to 27B parame...",
    "published": "May 23",
    "pdf_url": "https://arxiv.org/pdf/2505.17769v2",
    "arxiv_url": "http://arxiv.org/abs/2505.17769v2",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation",
    "authors": [
      "Jihan Yao",
      "Yushi Hu",
      "Yujie Yi",
      "Bin Han",
      "Shangbin Feng",
      "Guang Yang",
      "Bingbing Wen",
      "Ranjay Krishna",
      "Lucy Lu Wang",
      "Yulia Tsvetkov",
      "Noah A. Smith",
      "Banghua Zhu"
    ],
    "summary": "Automatically evaluating multimodal generation presents a significant challenge, as automated metrics often struggle to align reliably with human evaluation, especially for complex tasks that involve multiple modalities. To address this, we present MMMG, a comprehensive and human-aligned benchmark f...",
    "published": "May 23",
    "pdf_url": "https://arxiv.org/pdf/2505.17613v1",
    "arxiv_url": "http://arxiv.org/abs/2505.17613v1",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "CHART-6: Human-Centered Evaluation of Data Visualization Understanding in Vision-Language Models",
    "authors": [
      "Arnav Verma",
      "Kushin Mukherjee",
      "Christopher Potts",
      "Elisa Kreiss",
      "Judith E. Fan"
    ],
    "summary": "Data visualizations are powerful tools for communicating patterns in quantitative data. Yet understanding any data visualization is no small feat -- succeeding requires jointly making sense of visual, numerical, and linguistic inputs arranged in a conventionalized format one has previously learned t...",
    "published": "May 22",
    "pdf_url": "https://arxiv.org/pdf/2505.17202v1",
    "arxiv_url": "http://arxiv.org/abs/2505.17202v1",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification",
    "authors": [
      "Himanshu Beniwal",
      "Youngwoo Kim",
      "Maarten Sap",
      "Soham Dan",
      "Thomas Hartvigsen"
    ],
    "summary": "As large language models (LLMs) become increasingly prevalent in global applications, ensuring that they are toxicity-free across diverse linguistic contexts remains a critical challenge. We explore \"Cross-lingual Detoxification\", a cross-lingual paradigm that mitigates toxicity, enabling detoxifica...",
    "published": "May 22",
    "pdf_url": "https://arxiv.org/pdf/2505.16722v3",
    "arxiv_url": "http://arxiv.org/abs/2505.16722v3",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS",
    "authors": [
      "Chaeeun Kim",
      "Seungone Kim"
    ],
    "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retr...",
    "published": "May 22",
    "pdf_url": "https://arxiv.org/pdf/2505.16409v1",
    "arxiv_url": "http://arxiv.org/abs/2505.16409v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions",
    "authors": [
      "Sasha Boguraev",
      "Christopher Potts",
      "Kyle Mahowald"
    ],
    "summary": "Language Models (LMs) have emerged as powerful sources of evidence for linguists seeking to develop theories of syntax. In this paper, we argue that causal interpretability methods, applied to LMs, can greatly enhance the value of such evidence by helping us characterize the abstract mechanisms that...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.16002v2",
    "arxiv_url": "http://arxiv.org/abs/2505.16002v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "Pre-training Limited Memory Language Models with Internal and External Knowledge",
    "authors": [
      "Linxi Zhao",
      "Sofian Zalouk",
      "Christian K. Belardi",
      "Justin Lovelace",
      "Jin Peng Zhou",
      "Ryan Thomas Noonan",
      "Dongyoung Go",
      "Kilian Q. Weinberger",
      "Yoav Artzi",
      "Jennifer J. Sun"
    ],
    "summary": "Neural language models are black-boxes--both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We introduce Limited Memory Language Models (LMLM), a new cla...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.15962v3",
    "arxiv_url": "http://arxiv.org/abs/2505.15962v3",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning",
    "authors": [
      "Chen Shani",
      "Liron Soffer",
      "Dan Jurafsky",
      "Yann LeCun",
      "Ravid Shwartz-Ziv"
    ],
    "summary": "Humans organize knowledge into compact conceptual categories that balance compression with semantic richness. Large Language Models (LLMs) exhibit impressive linguistic abilities, but whether they navigate this same compression-meaning trade-off remains unclear. We apply an Information Bottleneck fr...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.17117v6",
    "arxiv_url": "http://arxiv.org/abs/2505.17117v6",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents",
    "authors": [
      "Hyungjoo Chae",
      "Sunghwan Kim",
      "Junhee Cho",
      "Seungone Kim",
      "Seungjun Moon",
      "Gyeom Hwangbo",
      "Dongha Lim",
      "Minjin Kim",
      "Yeonjun Hwang",
      "Minju Gwak",
      "Dongwook Choi",
      "Minseok Kang",
      "Gwanhoon Im",
      "ByeongUng Cho",
      "Hyojun Kim",
      "Jun Hee Han",
      "Taeyoon Kwon",
      "Minju Kim",
      "Beong-woo Kwak",
      "Dongjin Kang",
      "Jinyoung Yeo"
    ],
    "summary": "Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during bot...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.15277v2",
    "arxiv_url": "http://arxiv.org/abs/2505.15277v2",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems",
    "authors": [
      "Andy K. Zhang",
      "Joey Ji",
      "Celeste Menders",
      "Riya Dulepet",
      "Thomas Qin",
      "Ron Y. Wang",
      "Junrong Wu",
      "Kyleen Liao",
      "Jiliang Li",
      "Jinghan Hu",
      "Sara Hong",
      "Nardos Demilew",
      "Shivatmica Murgai",
      "Jason Tran",
      "Nishka Kacheria",
      "Ethan Ho",
      "Denis Liu",
      "Lauren McLane",
      "Olivia Bruvik",
      "Dai-Rong Han",
      "Seungwoo Kim",
      "Akhil Vyas",
      "Cuiyuanxiu Chen",
      "Ryan Li",
      "Weiran Xu",
      "Jonathan Z. Ye",
      "Prerit Choudhary",
      "Siddharth M. Bhatia",
      "Vikram Sivashankar",
      "Yuxuan Bao",
      "Dawn Song",
      "Dan Boneh",
      "Daniel E. Ho",
      "Percy Liang"
    ],
    "summary": "AI agents have the potential to significantly alter the cybersecurity landscape. Here, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world c...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.15216v3",
    "arxiv_url": "http://arxiv.org/abs/2505.15216v3",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Mechanistic evaluation of Transformers and state space models",
    "authors": [
      "Aryaman Arora",
      "Neil Rathi",
      "Nikil Roashan Selvam",
      "R\u00f3bert Csord\u00e1s",
      "Dan Jurafsky",
      "Christopher Potts"
    ],
    "summary": "State space models (SSMs) for language modelling promise an efficient and performant alternative to quadratic-attention Transformers, yet show variable performance on recalling basic information from the context. While performance on synthetic tasks like Associative Recall (AR) can point to this def...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2505.15105v2",
    "arxiv_url": "http://arxiv.org/abs/2505.15105v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts",
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity",
    "authors": [
      "Moussa Koulako Bala Doumbouya",
      "Dan Jurafsky",
      "Christopher D. Manning"
    ],
    "summary": "Work in psychology has highlighted that the geometric model of similarity standard in deep learning is not psychologically plausible because its metric properties such as symmetry do not align with human perception of similarity. In contrast, Tversky (1977) proposed an axiomatic theory of similarity...",
    "published": "May 21",
    "pdf_url": "https://arxiv.org/pdf/2506.11035v2",
    "arxiv_url": "http://arxiv.org/abs/2506.11035v2",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning",
      "Dan Jurafsky"
    ]
  },
  {
    "title": "In-Context Learning Boosts Speech Recognition via Human-like Adaptation to Speakers and Language Varieties",
    "authors": [
      "Nathan Roll",
      "Calbert Graham",
      "Yuka Tatsumi",
      "Kim Tien Nguyen",
      "Meghan Sumner",
      "Dan Jurafsky"
    ],
    "summary": "Human listeners readily adjust to unfamiliar speakers and language varieties through exposure, but do these adaptation benefits extend to state-of-the-art spoken language models? We introduce a scalable framework that allows for in-context learning (ICL) in Phi-4 Multimodal using interleaved task pr...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14887v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14887v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas",
    "authors": [
      "Yu Ying Chiu",
      "Zhilin Wang",
      "Sharan Maiya",
      "Yejin Choi",
      "Kyle Fish",
      "Sydney Levine",
      "Evan Hubinger"
    ],
    "summary": "Detecting AI risks becomes more challenging as stronger models emerge and find novel methods such as Alignment Faking to circumvent these detection attempts. Inspired by how risky behaviors in humans (i.e., illegal activities that may hurt others) are sometimes guided by strongly-held values, we bel...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14633v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14633v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "SATBench: Benchmarking LLMs' Logical Reasoning via Automated Puzzle Generation from SAT Formulas",
    "authors": [
      "Anjiang Wei",
      "Yuheng Wu",
      "Yingjia Wan",
      "Tarun Suresh",
      "Huanmi Tan",
      "Zhanke Zhou",
      "Sanmi Koyejo",
      "Ke Wang",
      "Alex Aiken"
    ],
    "summary": "We introduce SATBench, a benchmark for evaluating the logical reasoning capabilities of large language models (LLMs) through logical puzzles derived from Boolean satisfiability (SAT) problems. Unlike prior work that focuses on inference rule-based reasoning, which often involves deducing conclusions...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14615v2",
    "arxiv_url": "http://arxiv.org/abs/2505.14615v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Agent Context Protocols Enhance Collective Inference",
    "authors": [
      "Devansh Bhardwaj",
      "Arjun Beniwal",
      "Shreyas Chaudhari",
      "Ashwin Kalyan",
      "Tanmay Rajpurohit",
      "Karthik R. Narasimhan",
      "Ameet Deshpande",
      "Vishvak Murahari"
    ],
    "summary": "AI agents have become increasingly adept at complex tasks such as coding, reasoning, and multimodal understanding. However, building generalist systems requires moving beyond individual agents to collective inference -- a paradigm where multi-agent systems with diverse, task-specialized agents compl...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14569v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14569v1",
    "queried_author": "Karthik R Narasimhan",
    "matching_authors": [
      "Karthik R Narasimhan"
    ]
  },
  {
    "title": "Reasoning Models Better Express Their Confidence",
    "authors": [
      "Dongkeun Yoon",
      "Seungone Kim",
      "Sohee Yang",
      "Sunkyoung Kim",
      "Soyeon Kim",
      "Yongil Kim",
      "Eunbi Choi",
      "Yireun Kim",
      "Minjoon Seo"
    ],
    "summary": "Despite their strengths, large language models (LLMs) often fail to communicate their confidence accurately, making it difficult to assess when they might be wrong and limiting their reliability. In this work, we demonstrate that reasoning models that engage in extended chain-of-thought (CoT) reason...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14489v2",
    "arxiv_url": "http://arxiv.org/abs/2505.14489v2",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Creative Preference Optimization",
    "authors": [
      "Mete Ismayilzada",
      "Antonio Laverghetta",
      "Simone A. Luchini",
      "Reet Patel",
      "Antoine Bosselut",
      "Lonneke van der Plas",
      "Roger Beaty"
    ],
    "summary": "While Large Language Models (LLMs) have demonstrated impressive performance across natural language generation tasks, their ability to generate truly creative content-characterized by novelty, diversity, surprise, and quality-remains limited. Existing methods for enhancing LLM creativity often focus...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14442v2",
    "arxiv_url": "http://arxiv.org/abs/2505.14442v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "Rank-K: Test-Time Reasoning for Listwise Reranking",
    "authors": [
      "Eugene Yang",
      "Andrew Yates",
      "Kathryn Ricci",
      "Orion Weller",
      "Vivek Chari",
      "Benjamin Van Durme",
      "Dawn Lawrie"
    ],
    "summary": "Retrieve-and-rerank is a popular retrieval pipeline because of its ability to make slow but effective rerankers efficient enough at query time by reducing the number of comparisons. Recent works in neural rerankers take advantage of large language models for their capability in reasoning between que...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14432v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14432v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation",
    "authors": [
      "Peter Baile Chen",
      "Yi Zhang",
      "Dan Roth",
      "Samuel Madden",
      "Jacob Andreas",
      "Michael Cafarella"
    ],
    "summary": "While humans naturally learn and adapt from past experiences, large language models (LLMs) and their agentic counterparts struggle to retain reasoning from previous tasks and apply them in future contexts. To address this limitation, we propose a novel framework, log-augmented generation (LAG) that ...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14398v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14398v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Towards eliciting latent knowledge from LLMs with mechanistic interpretability",
    "authors": [
      "Bartosz Cywi\u0144ski",
      "Emil Ryd",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "summary": "As language models become more powerful and sophisticated, it is crucial that they remain trustworthy and reliable. There is concerning preliminary evidence that models may attempt to deceive or keep secrets from their operators. To explore the ability of current techniques to elicit such hidden kno...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.14352v1",
    "arxiv_url": "http://arxiv.org/abs/2505.14352v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "ELEPHANT: Measuring and understanding social sycophancy in LLMs",
    "authors": [
      "Myra Cheng",
      "Sunny Yu",
      "Cinoo Lee",
      "Pranav Khadpe",
      "Lujain Ibrahim",
      "Dan Jurafsky"
    ],
    "summary": "LLMs are known to exhibit sycophancy: agreeing with and flattering users, even at the cost of correctness. Prior work measures sycophancy only as direct agreement with users' explicitly stated beliefs that can be compared to a ground truth. This fails to capture broader forms of sycophancy such as a...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.13995v2",
    "arxiv_url": "http://arxiv.org/abs/2505.13995v2",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation",
    "authors": [
      "Amitayush Thakur",
      "Jasper Lee",
      "George Tsoukalas",
      "Meghana Sistla",
      "Matthew Zhao",
      "Stefan Zetzsche",
      "Greg Durrett",
      "Yisong Yue",
      "Swarat Chaudhuri"
    ],
    "summary": "We introduce ${\\rm C{\\small LEVER}}$, a high-quality, curated benchmark of 161 problems for end-to-end verified code generation in Lean. Each problem consists of (1) the task of generating a specification that matches a held-out ground-truth specification, and (2) the task of generating a Lean imple...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.13938v4",
    "arxiv_url": "http://arxiv.org/abs/2505.13938v4",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Do Language Models Use Their Depth Efficiently?",
    "authors": [
      "R\u00f3bert Csord\u00e1s",
      "Christopher D. Manning",
      "Christopher Potts"
    ],
    "summary": "Modern LLMs are increasingly deep, and depth correlates with performance, albeit with diminishing returns. However, do these models use their depth efficiently? Do they compose more features to create higher-order computations that are impossible in shallow models, or do they merely spread the same ...",
    "published": "May 20",
    "pdf_url": "https://arxiv.org/pdf/2505.13898v3",
    "arxiv_url": "http://arxiv.org/abs/2505.13898v3",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning",
      "Christopher Potts"
    ]
  },
  {
    "title": "Mean Flows for One-step Generative Modeling",
    "authors": [
      "Zhengyang Geng",
      "Mingyang Deng",
      "Xingjian Bai",
      "J. Zico Kolter",
      "Kaiming He"
    ],
    "summary": "We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is d...",
    "published": "May 19",
    "pdf_url": "https://arxiv.org/pdf/2505.13447v1",
    "arxiv_url": "http://arxiv.org/abs/2505.13447v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models",
    "authors": [
      "Liyan Tang",
      "Grace Kim",
      "Xinyu Zhao",
      "Thom Lake",
      "Wenxuan Ding",
      "Fangcong Yin",
      "Prasann Singhal",
      "Manya Wadhwa",
      "Zeyu Leo Liu",
      "Zayne Sprague",
      "Ramya Namuduri",
      "Bodun Hu",
      "Juan Diego Rodriguez",
      "Puyuan Peng",
      "Greg Durrett"
    ],
    "summary": "Chart understanding presents a unique challenge for large vision-language models (LVLMs), as it requires the integration of sophisticated textual and visual reasoning capabilities. However, current LVLMs exhibit a notable imbalance between these skills, falling short on visual reasoning that is diff...",
    "published": "May 19",
    "pdf_url": "https://arxiv.org/pdf/2505.13444v2",
    "arxiv_url": "http://arxiv.org/abs/2505.13444v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks",
    "authors": [
      "Yixuan Xu",
      "Antoni-Joan Solergibert i Llaquet",
      "Antoine Bosselut",
      "Imanol Schlag"
    ],
    "summary": "Large language models are known to memorize parts of their training data, posing risk of copyright violations. To systematically examine this risk, we pretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing web-scale data with public domain books used to simulate copyrighted content a...",
    "published": "May 19",
    "pdf_url": "https://arxiv.org/pdf/2505.13171v2",
    "arxiv_url": "http://arxiv.org/abs/2505.13171v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "DreamGen: Unlocking Generalization in Robot Learning through Video World Models",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Zongyu Lin",
      "Jiannan Xiang",
      "Johan Bjorck",
      "Yu Fang",
      "Fengyuan Hu",
      "Spencer Huang",
      "Kaushil Kundalia",
      "Yen-Chen Lin",
      "Loic Magne",
      "Ajay Mandlekar",
      "Avnish Narayan",
      "You Liang Tan",
      "Guanzhi Wang",
      "Jing Wang",
      "Qi Wang",
      "Yinzhen Xu",
      "Xiaohui Zeng",
      "Kaiyuan Zheng",
      "Ruijie Zheng",
      "Ming-Yu Liu",
      "Luke Zettlemoyer",
      "Dieter Fox",
      "Jan Kautz",
      "Scott Reed",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "summary": "We introduce DreamGen, a simple yet highly effective 4-stage pipeline for training robot policies that generalize across behaviors and environments through neural trajectories - synthetic robot data generated from video world models. DreamGen leverages state-of-the-art image-to-video generative mode...",
    "published": "May 19",
    "pdf_url": "https://arxiv.org/pdf/2505.12705v2",
    "arxiv_url": "http://arxiv.org/abs/2505.12705v2",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer"
    ]
  },
  {
    "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models",
    "authors": [
      "A. Feder Cooper",
      "Aaron Gokaslan",
      "Ahmed Ahmed",
      "Amy B. Cyphert",
      "Christopher De Sa",
      "Mark A. Lemley",
      "Daniel E. Ho",
      "Percy Liang"
    ],
    "summary": "Plaintiffs and defendants in copyright lawsuits over generative AI often make sweeping, opposing claims about the extent to which large language models (LLMs) have memorized plaintiffs' protected expression in their training data. Drawing on both machine learning and copyright law, we show that thes...",
    "published": "May 18",
    "pdf_url": "https://arxiv.org/pdf/2505.12546v4",
    "arxiv_url": "http://arxiv.org/abs/2505.12546v4",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors",
    "authors": [
      "Jing Huang",
      "Junyi Tao",
      "Thomas Icard",
      "Diyi Yang",
      "Christopher Potts"
    ],
    "summary": "Interpretability research now offers a variety of techniques for identifying abstract internal mechanisms in neural networks. Can such techniques be used to predict how models will behave on out-of-distribution examples? In this work, we provide a positive answer to this question. Through a diverse ...",
    "published": "May 17",
    "pdf_url": "https://arxiv.org/pdf/2505.11770v2",
    "arxiv_url": "http://arxiv.org/abs/2505.11770v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts",
      "Diyi Yang"
    ]
  },
  {
    "title": "Creating General User Models from Computer Use",
    "authors": [
      "Omar Shaikh",
      "Shardul Sapkota",
      "Shan Rizvi",
      "Eric Horvitz",
      "Joon Sung Park",
      "Diyi Yang",
      "Michael S. Bernstein"
    ],
    "summary": "Human-computer interaction has long imagined technology that understands us-from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific apps, and incapable of the flexible reasoning required to fulfill t...",
    "published": "May 16",
    "pdf_url": "https://arxiv.org/pdf/2505.10831v3",
    "arxiv_url": "http://arxiv.org/abs/2505.10831v3",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think",
    "authors": [
      "Seongyun Lee",
      "Seungone Kim",
      "Minju Seo",
      "Yongrae Jo",
      "Dongyoung Go",
      "Hyeonbin Hwang",
      "Jinho Park",
      "Xiang Yue",
      "Sean Welleck",
      "Graham Neubig",
      "Moontae Lee",
      "Minjoon Seo"
    ],
    "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of modern large language models, but our understanding of the reasoning strategies underlying these capabilities remains limited. While some prior works have attempted to categorize CoTs using predefined strategy types, such a...",
    "published": "May 15",
    "pdf_url": "https://arxiv.org/pdf/2505.10185v1",
    "arxiv_url": "http://arxiv.org/abs/2505.10185v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Sean Welleck",
      "Seungone Kim"
    ]
  },
  {
    "title": "Measurement to Meaning: A Validity-Centered Framework for AI Evaluation",
    "authors": [
      "Olawale Salaudeen",
      "Anka Reuel",
      "Ahmed Ahmed",
      "Suhana Bedi",
      "Zachary Robertson",
      "Sudharsan Sundar",
      "Ben Domingue",
      "Angelina Wang",
      "Sanmi Koyejo"
    ],
    "summary": "While the capabilities and utility of AI systems have advanced, rigorous norms for evaluating these systems have lagged. Grand claims, such as models achieving general reasoning capabilities, are supported with model performance on narrow benchmarks, like performance on graduate-level exam questions...",
    "published": "May 13",
    "pdf_url": "https://arxiv.org/pdf/2505.10573v4",
    "arxiv_url": "http://arxiv.org/abs/2505.10573v4",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering",
    "authors": [
      "Rushi Qiang",
      "Yuchen Zhuang",
      "Yinghao Li",
      "Dingu Sagar V K",
      "Rongzhi Zhang",
      "Changhao Li",
      "Ian Shu-Hei Wong",
      "Sherry Yang",
      "Percy Liang",
      "Chao Zhang",
      "Bo Dai"
    ],
    "summary": "We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement learning, evaluating, and improving autonomous large language model (LLM) agents in iterative machine learning engineering (MLE) workflows. Unlike existing benchmarks that primarily rely on static datasets or single-attemp...",
    "published": "May 12",
    "pdf_url": "https://arxiv.org/pdf/2505.07782v1",
    "arxiv_url": "http://arxiv.org/abs/2505.07782v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs",
    "authors": [
      "Jeffrey Basoah",
      "Daniel Chechelnitsky",
      "Tao Long",
      "Katharina Reinecke",
      "Chrysoula Zerva",
      "Kaitlyn Zhou",
      "Mark D\u00edaz",
      "Maarten Sap"
    ],
    "summary": "As large language models (LLMs) increasingly adapt and personalize to diverse sets of users, there is an increased risk of systems appropriating sociolects, i.e., language styles or dialects that are associated with specific minoritized lived experiences (e.g., African American English, Queer slang)...",
    "published": "May 08",
    "pdf_url": "https://arxiv.org/pdf/2505.05660v3",
    "arxiv_url": "http://arxiv.org/abs/2505.05660v3",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Reasoning Models Don't Always Say What They Think",
    "authors": [
      "Yanda Chen",
      "Joe Benton",
      "Ansh Radhakrishnan",
      "Jonathan Uesato",
      "Carson Denison",
      "John Schulman",
      "Arushi Somani",
      "Peter Hase",
      "Misha Wagner",
      "Fabien Roger",
      "Vlad Mikulik",
      "Samuel R. Bowman",
      "Jan Leike",
      "Jared Kaplan",
      "Ethan Perez"
    ],
    "summary": "Chain-of-thought (CoT) offers a potential boon for AI safety as it allows monitoring a model's CoT to try to understand its intentions and reasoning processes. However, the effectiveness of such monitoring hinges on CoTs faithfully representing models' actual reasoning processes. We evaluate CoT fai...",
    "published": "May 08",
    "pdf_url": "https://arxiv.org/pdf/2505.05410v1",
    "arxiv_url": "http://arxiv.org/abs/2505.05410v1",
    "queried_author": "Ethan Perez",
    "matching_authors": [
      "Ethan Perez",
      "Jared Kaplan"
    ]
  },
  {
    "title": "Crosslingual Reasoning through Test-Time Scaling",
    "authors": [
      "Zheng-Xin Yong",
      "M. Farid Adilazuarda",
      "Jonibek Mansurov",
      "Ruochen Zhang",
      "Niklas Muennighoff",
      "Carsten Eickhoff",
      "Genta Indra Winata",
      "Julia Kreutzer",
      "Stephen H. Bach",
      "Alham Fikri Aji"
    ],
    "summary": "Reasoning capabilities of large language models are primarily studied for English, even when pretrained models are multilingual. In this work, we investigate to what extent English reasoning finetuning with long chain-of-thoughts (CoTs) can generalize across languages. First, we find that scaling up...",
    "published": "May 08",
    "pdf_url": "https://arxiv.org/pdf/2505.05408v1",
    "arxiv_url": "http://arxiv.org/abs/2505.05408v1",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff"
    ]
  },
  {
    "title": "Do MLLMs Capture How Interfaces Guide User Behavior? A Benchmark for Multimodal UI/UX Design Understanding",
    "authors": [
      "Jaehyun Jeon",
      "Min Soo Kim",
      "Jang Han Yoon",
      "Sumin Shim",
      "Yejin Choi",
      "Hanbin Kim",
      "Youngjae Yu"
    ],
    "summary": "User interface (UI) design goes beyond visuals, guiding user behavior and overall user experience (UX). Strategically crafted interfaces, for example, can boost sign-ups and drive business sales, underscoring the shift toward UI/UX as a unified design concept. While recent studies have explored UI q...",
    "published": "May 08",
    "pdf_url": "https://arxiv.org/pdf/2505.05026v3",
    "arxiv_url": "http://arxiv.org/abs/2505.05026v3",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Osiris: A Lightweight Open-Source Hallucination Detection System",
    "authors": [
      "Alex Shan",
      "John Bauer",
      "Christopher D. Manning"
    ],
    "summary": "Retrieval-Augmented Generation (RAG) systems have gained widespread adoption by application builders because they leverage sources of truth to enable Large Language Models (LLMs) to generate more factually sound responses. However, hallucinations, instances of LLM responses that are unfaithful to th...",
    "published": "May 07",
    "pdf_url": "https://arxiv.org/pdf/2505.04844v1",
    "arxiv_url": "http://arxiv.org/abs/2505.04844v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "A Reasoning-Focused Legal Retrieval Benchmark",
    "authors": [
      "Lucia Zheng",
      "Neel Guha",
      "Javokhir Arifov",
      "Sarah Zhang",
      "Michal Skreta",
      "Christopher D. Manning",
      "Peter Henderson",
      "Daniel E. Ho"
    ],
    "summary": "As the legal community increasingly examines the use of large language models (LLMs) for various legal applications, legal AI developers have turned to retrieval-augmented LLMs (\"RAG\" systems) to improve system performance and robustness. An obstacle to the development of specialized RAG systems is ...",
    "published": "May 06",
    "pdf_url": "https://arxiv.org/pdf/2505.03970v1",
    "arxiv_url": "http://arxiv.org/abs/2505.03970v1",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "BLAB: Brutally Long Audio Bench",
    "authors": [
      "Orevaoghene Ahia",
      "Martijn Bartelds",
      "Kabir Ahuja",
      "Hila Gonen",
      "Valentin Hofmann",
      "Siddhant Arora",
      "Shuyue Stella Li",
      "Vishal Puttagunta",
      "Mofetoluwa Adeyemi",
      "Charishma Buchireddy",
      "Ben Walls",
      "Noah Bennett",
      "Shinji Watanabe",
      "Noah A. Smith",
      "Yulia Tsvetkov",
      "Sachin Kumar"
    ],
    "summary": "Developing large audio language models (LMs) capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations. Recent work on audio LMs has pr...",
    "published": "May 05",
    "pdf_url": "https://arxiv.org/pdf/2505.03054v2",
    "arxiv_url": "http://arxiv.org/abs/2505.03054v2",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "Teaching Models to Understand (but not Generate) High-risk Data",
    "authors": [
      "Ryan Wang",
      "Matthew Finlayson",
      "Luca Soldaini",
      "Swabha Swayamdipta",
      "Robin Jia"
    ],
    "summary": "Language model developers typically filter out high-risk content -- such as toxic or copyrighted text -- from their pre-training data to prevent models from generating similar outputs. However, removing such data altogether limits models' ability to recognize and appropriately respond to harmful or ...",
    "published": "May 05",
    "pdf_url": "https://arxiv.org/pdf/2505.03052v2",
    "arxiv_url": "http://arxiv.org/abs/2505.03052v2",
    "queried_author": "Luca Soldaini",
    "matching_authors": [
      "Luca Soldaini"
    ]
  },
  {
    "title": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback",
    "authors": [
      "Hao Zhu",
      "Phil Cuvin",
      "Xinkai Yu",
      "Charlotte Ka Yee Yan",
      "Jason Zhang",
      "Diyi Yang"
    ],
    "summary": "Agents are predominantly evaluated and optimized via task success metrics, which are coarse, rely on manual design from experts, and fail to reward intermediate emergent behaviors. We propose **AutoLibra**, a framework for agent evaluation, that transforms open-ended human feedback *e.g.* \"If you fi...",
    "published": "May 05",
    "pdf_url": "https://arxiv.org/pdf/2505.02820v3",
    "arxiv_url": "http://arxiv.org/abs/2505.02820v3",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "Can LLM-Simulated Practice and Feedback Upskill Human Counselors? A Randomized Study with 90+ Novice Counselors",
    "authors": [
      "Ryan Louie",
      "Ifdita Hasan Orney",
      "Juan Pablo Pacheco",
      "Raj Sanjay Shah",
      "Emma Brunskill",
      "Diyi Yang"
    ],
    "summary": "Training more counselors, from clinical students to peer supporters, can help meet the demand for accessible mental health support; however, current training approaches remain resource-intensive and difficult to scale effectively. Large Language Models (LLMs) offer promising solutions for growing co...",
    "published": "May 05",
    "pdf_url": "https://arxiv.org/pdf/2505.02428v1",
    "arxiv_url": "http://arxiv.org/abs/2505.02428v1",
    "queried_author": "Diyi Yang",
    "matching_authors": [
      "Diyi Yang"
    ]
  },
  {
    "title": "PoseX: AI Defeats Physics Approaches on Protein-Ligand Cross Docking",
    "authors": [
      "Yize Jiang",
      "Xinze Li",
      "Yuanyuan Zhang",
      "Jin Han",
      "Youjun Xu",
      "Ayush Pandit",
      "Zaixi Zhang",
      "Mengdi Wang",
      "Mengyang Wang",
      "Chong Liu",
      "Guang Yang",
      "Yejin Choi",
      "Wu-Jun Li",
      "Tianfan Fu",
      "Fang Wu",
      "Junhong Liu"
    ],
    "summary": "Existing protein-ligand docking studies typically focus on the self-docking scenario, which is less practical in real applications. Moreover, some studies involve heavy frameworks requiring extensive training, posing challenges for convenient and efficient assessment of docking methods. To fill thes...",
    "published": "May 03",
    "pdf_url": "https://arxiv.org/pdf/2505.01700v2",
    "arxiv_url": "http://arxiv.org/abs/2505.01700v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "SWE-smith: Scaling Data for Software Engineering Agents",
    "authors": [
      "John Yang",
      "Kilian Lieret",
      "Carlos E. Jimenez",
      "Alexander Wettig",
      "Kabir Khandpur",
      "Yanzhe Zhang",
      "Binyuan Hui",
      "Ofir Press",
      "Ludwig Schmidt",
      "Diyi Yang"
    ],
    "summary": "Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex,...",
    "published": "Apr 30",
    "pdf_url": "https://arxiv.org/pdf/2504.21798v2",
    "arxiv_url": "http://arxiv.org/abs/2504.21798v2",
    "queried_author": "Alexander Wettig",
    "matching_authors": [
      "Alexander Wettig",
      "Diyi Yang",
      "Ludwig Schmidt"
    ]
  },
  {
    "title": "Base Models Beat Aligned Models at Randomness and Creativity",
    "authors": [
      "Peter West",
      "Christopher Potts"
    ],
    "summary": "Alignment has quickly become a default ingredient in LLM development, with techniques such as reinforcement learning from human feedback making models act safely, follow instructions, and perform ever-better on complex tasks. While these techniques are certainly useful, we propose that they should n...",
    "published": "Apr 30",
    "pdf_url": "https://arxiv.org/pdf/2505.00047v2",
    "arxiv_url": "http://arxiv.org/abs/2505.00047v2",
    "queried_author": "Christopher Potts",
    "matching_authors": [
      "Christopher Potts"
    ]
  },
  {
    "title": "The Leaderboard Illusion",
    "authors": [
      "Shivalika Singh",
      "Yiyang Nan",
      "Alex Wang",
      "Daniel D'Souza",
      "Sayash Kapoor",
      "Ahmet \u00dcst\u00fcn",
      "Sanmi Koyejo",
      "Yuntian Deng",
      "Shayne Longpre",
      "Noah A. Smith",
      "Beyza Ermis",
      "Marzieh Fadaee",
      "Sara Hooker"
    ],
    "summary": "Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify syst...",
    "published": "Apr 29",
    "pdf_url": "https://arxiv.org/pdf/2504.20879v2",
    "arxiv_url": "http://arxiv.org/abs/2504.20879v2",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith",
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Cooking Up Creativity: Enhancing LLM Creativity through Structured Recombination",
    "authors": [
      "Moran Mizrahi",
      "Chen Shani",
      "Gabriel Stanovsky",
      "Dan Jurafsky",
      "Dafna Shahaf"
    ],
    "summary": "Large Language Models (LLMs) excel at many tasks, yet they struggle to produce truly creative, diverse ideas. In this paper, we introduce a novel approach that enhances LLM creativity. We apply LLMs for translating between natural language and structured representations, and perform the core creativ...",
    "published": "Apr 29",
    "pdf_url": "https://arxiv.org/pdf/2504.20643v2",
    "arxiv_url": "http://arxiv.org/abs/2504.20643v2",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
    "authors": [
      "Rulin Shao",
      "Rui Qiao",
      "Varsha Kishore",
      "Niklas Muennighoff",
      "Xi Victoria Lin",
      "Daniela Rus",
      "Bryan Kian Hsiang Low",
      "Sewon Min",
      "Wen-tau Yih",
      "Pang Wei Koh",
      "Luke Zettlemoyer"
    ],
    "summary": "We present ReasonIR-8B, the first retriever specifically trained for general reasoning tasks. Existing retrievers have shown limited gains on reasoning tasks, in part because existing training datasets focus on short factual queries tied to documents that straightforwardly answer them. We develop a ...",
    "published": "Apr 29",
    "pdf_url": "https://arxiv.org/pdf/2504.20595v1",
    "arxiv_url": "http://arxiv.org/abs/2504.20595v1",
    "queried_author": "Luke Zettlemoyer",
    "matching_authors": [
      "Luke Zettlemoyer",
      "Niklas Muennighoff",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage",
    "authors": [
      "Rui Xin",
      "Niloofar Mireshghallah",
      "Shuyue Stella Li",
      "Michael Duan",
      "Hyunwoo Kim",
      "Yejin Choi",
      "Yulia Tsvetkov",
      "Sewoong Oh",
      "Pang Wei Koh"
    ],
    "summary": "Sanitizing sensitive text data typically involves removing personally identifiable information (PII) or generating synthetic data under the assumption that these methods adequately protect privacy; however, their effectiveness is often only assessed by measuring the leakage of explicit identifiers b...",
    "published": "Apr 28",
    "pdf_url": "https://arxiv.org/pdf/2504.21035v2",
    "arxiv_url": "http://arxiv.org/abs/2504.21035v2",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh",
      "Yejin Choi"
    ]
  },
  {
    "title": "RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning",
    "authors": [
      "Zihan Wang",
      "Kangrui Wang",
      "Qineng Wang",
      "Pingyue Zhang",
      "Linjie Li",
      "Zhengyuan Yang",
      "Xing Jin",
      "Kefan Yu",
      "Minh Nhat Nguyen",
      "Licheng Liu",
      "Eli Gottlieb",
      "Yiping Lu",
      "Kyunghyun Cho",
      "Jiajun Wu",
      "Li Fei-Fei",
      "Lijuan Wang",
      "Yejin Choi",
      "Manling Li"
    ],
    "summary": "Training large language models (LLMs) as interactive agents presents unique challenges including long-horizon decision making and interacting with stochastic environment feedback. While reinforcement learning (RL) has enabled progress in static tasks, multi-turn agent RL training remains underexplor...",
    "published": "Apr 24",
    "pdf_url": "https://arxiv.org/pdf/2504.20073v2",
    "arxiv_url": "http://arxiv.org/abs/2504.20073v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Safety Pretraining: Toward the Next Generation of Safe AI",
    "authors": [
      "Pratyush Maini",
      "Sachin Goyal",
      "Dylan Sam",
      "Alex Robey",
      "Yash Savani",
      "Yiding Jiang",
      "Andy Zou",
      "Matt Fredrikson",
      "Zacharcy C. Lipton",
      "J. Zico Kolter"
    ],
    "summary": "As large language models (LLMs) are increasingly deployed in high-stakes settings, the risk of generating harmful or toxic content remains a central challenge. Post-hoc alignment methods are brittle: once unsafe patterns are learned during pretraining, they are hard to remove. In this work, we prese...",
    "published": "Apr 23",
    "pdf_url": "https://arxiv.org/pdf/2504.16980v2",
    "arxiv_url": "http://arxiv.org/abs/2504.16980v2",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Understanding the Skill Gap in Recurrent Language Models: The Role of the Gather-and-Aggregate Mechanism",
    "authors": [
      "Aviv Bick",
      "Eric Xing",
      "Albert Gu"
    ],
    "summary": "State-space models (SSMs) offer efficient alternatives to Transformers for long sequences, but their fixed-size recurrent state limits capability on algorithmic tasks, such as retrieving past context. In this work, we examine how in-context retrieval operates in Transformer- and SSM-based language m...",
    "published": "Apr 22",
    "pdf_url": "https://arxiv.org/pdf/2504.18574v2",
    "arxiv_url": "http://arxiv.org/abs/2504.18574v2",
    "queried_author": "Albert Gu",
    "matching_authors": [
      "Albert Gu"
    ]
  },
  {
    "title": "LongPerceptualThoughts: Distilling System-2 Reasoning for System-1 Perception",
    "authors": [
      "Yuan-Hong Liao",
      "Sven Elflein",
      "Liu He",
      "Laura Leal-Taix\u00e9",
      "Yejin Choi",
      "Sanja Fidler",
      "David Acuna"
    ],
    "summary": "Recent reasoning models through test-time scaling have demonstrated that long chain-of-thoughts can unlock substantial performance boosts in hard reasoning tasks such as math and code. However, the benefit of such long thoughts for system-2 reasoning is relatively less explored in other domains such...",
    "published": "Apr 21",
    "pdf_url": "https://arxiv.org/pdf/2504.15362v1",
    "arxiv_url": "http://arxiv.org/abs/2504.15362v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation",
    "authors": [
      "Anirudh Khatry",
      "Robert Zhang",
      "Jia Pan",
      "Ziteng Wang",
      "Qiaochu Chen",
      "Greg Durrett",
      "Isil Dillig"
    ],
    "summary": "C-to-Rust transpilation is essential for modernizing legacy C code while enhancing safety and interoperability with modern Rust ecosystems. However, no dataset currently exists for evaluating whether a system can transpile C into safe Rust that passes a set of test cases. We introduce CRUST-Bench, a...",
    "published": "Apr 21",
    "pdf_url": "https://arxiv.org/pdf/2504.15254v3",
    "arxiv_url": "http://arxiv.org/abs/2504.15254v3",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "EvalAgent: Discovering Implicit Evaluation Criteria from the Web",
    "authors": [
      "Manya Wadhwa",
      "Zayne Sprague",
      "Chaitanya Malaviya",
      "Philippe Laban",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "summary": "Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs). For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a mode...",
    "published": "Apr 21",
    "pdf_url": "https://arxiv.org/pdf/2504.15219v2",
    "arxiv_url": "http://arxiv.org/abs/2504.15219v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
    "authors": [
      "Marc Finzi",
      "Sanyam Kapoor",
      "Diego Granziol",
      "Anming Gu",
      "Christopher De Sa",
      "J. Zico Kolter",
      "Andrew Gordon Wilson"
    ],
    "summary": "Why do larger language models generalize better? To investigate this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type...",
    "published": "Apr 21",
    "pdf_url": "https://arxiv.org/pdf/2504.15208v1",
    "arxiv_url": "http://arxiv.org/abs/2504.15208v1",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Pairwise or Pointwise? Evaluating Feedback Protocols for Bias in LLM-Based Evaluation",
    "authors": [
      "Tuhina Tripathi",
      "Manya Wadhwa",
      "Greg Durrett",
      "Scott Niekum"
    ],
    "summary": "Large Language Models (LLMs) are widely used as proxies for human labelers in both training (Reinforcement Learning from AI Feedback) and large-scale response evaluation (LLM-as-a-judge). Alignment and evaluation are critical components in the development of reliable LLMs, and the choice of feedback...",
    "published": "Apr 20",
    "pdf_url": "https://arxiv.org/pdf/2504.14716v2",
    "arxiv_url": "http://arxiv.org/abs/2504.14716v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data",
    "authors": [
      "Tong Chen",
      "Faeze Brahman",
      "Jiacheng Liu",
      "Niloofar Mireshghallah",
      "Weijia Shi",
      "Pang Wei Koh",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "summary": "Language models (LMs) can memorize and reproduce segments from their pretraining data verbatim even in non-adversarial settings, raising concerns about copyright, plagiarism, privacy, and creativity. We introduce Paraphrase Preference Optimization (ParaPO), a post-training method that fine-tunes LMs...",
    "published": "Apr 20",
    "pdf_url": "https://arxiv.org/pdf/2504.14452v2",
    "arxiv_url": "http://arxiv.org/abs/2504.14452v2",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "SOTOPIA-S4: a user-friendly system for flexible, customizable, and large-scale social simulation",
    "authors": [
      "Xuhui Zhou",
      "Zhe Su",
      "Sophie Feng",
      "Jiaxu Zhou",
      "Jen-tse Huang",
      "Hsien-Te Kao",
      "Spencer Lynch",
      "Svitlana Volkova",
      "Tongshuang Sherry Wu",
      "Anita Woolley",
      "Hao Zhu",
      "Maarten Sap"
    ],
    "summary": "Social simulation through large language model (LLM) agents is a promising approach to explore and validate hypotheses related to social science questions and LLM agents behavior. We present SOTOPIA-S4, a fast, flexible, and scalable social simulation system that addresses the technical barriers of ...",
    "published": "Apr 19",
    "pdf_url": "https://arxiv.org/pdf/2504.16122v1",
    "arxiv_url": "http://arxiv.org/abs/2504.16122v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
    "authors": [
      "Yixuan Even Xu",
      "Yash Savani",
      "Fei Fang",
      "J. Zico Kolter"
    ],
    "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as the leading approach for enhancing reasoning capabilities in large language models. However, it faces a fundamental compute and memory asymmetry: rollout generation is embarrassingly parallel and memory-light, whereas policy update...",
    "published": "Apr 18",
    "pdf_url": "https://arxiv.org/pdf/2504.13818v3",
    "arxiv_url": "http://arxiv.org/abs/2504.13818v3",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "A Framework for Objective-Driven Dynamical Stochastic Fields",
    "authors": [
      "Yibo Jacky Zhang",
      "Sanmi Koyejo"
    ],
    "summary": "Fields offer a versatile approach for describing complex systems composed of interacting and dynamic components. In particular, some of these dynamical and stochastic systems may exhibit goal-directed behaviors aimed at achieving specific objectives, which we refer to as $\\textit{intelligent fields}...",
    "published": "Apr 18",
    "pdf_url": "https://arxiv.org/pdf/2504.16115v2",
    "arxiv_url": "http://arxiv.org/abs/2504.16115v2",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Scaling sparse feature circuit finding for in-context learning",
    "authors": [
      "Dmitrii Kharlapenko",
      "Stepan Shabalin",
      "Fazl Barez",
      "Arthur Conmy",
      "Neel Nanda"
    ],
    "summary": "Sparse autoencoders (SAEs) are a popular tool for interpreting large language model activations, but their utility in addressing open questions in interpretability remains unclear. In this work, we demonstrate their effectiveness by using SAEs to deepen our understanding of the mechanism behind in-c...",
    "published": "Apr 18",
    "pdf_url": "https://arxiv.org/pdf/2504.13756v1",
    "arxiv_url": "http://arxiv.org/abs/2504.13756v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Antidistillation Sampling",
    "authors": [
      "Yash Savani",
      "Asher Trockman",
      "Zhili Feng",
      "Yixuan Even Xu",
      "Avi Schwarzschild",
      "Alexander Robey",
      "Marc Finzi",
      "J. Zico Kolter"
    ],
    "summary": "Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. An...",
    "published": "Apr 17",
    "pdf_url": "https://arxiv.org/pdf/2504.13146v5",
    "arxiv_url": "http://arxiv.org/abs/2504.13146v5",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations",
    "authors": [
      "Yiyou Sun",
      "Yu Gai",
      "Lijie Chen",
      "Abhilasha Ravichander",
      "Yejin Choi",
      "Dawn Song"
    ],
    "summary": "Large language models (LLMs) frequently generate hallucinations-content that deviates from factual accuracy or provided context-posing challenges for diagnosis due to the complex interplay of underlying causes. This paper introduces a subsequence association framework to systematically trace and und...",
    "published": "Apr 17",
    "pdf_url": "https://arxiv.org/pdf/2504.12691v1",
    "arxiv_url": "http://arxiv.org/abs/2504.12691v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Memorization vs. Reasoning: Updating LLMs with New Knowledge",
    "authors": [
      "Aochong Oliver Li",
      "Tanya Goyal"
    ],
    "summary": "Large language models (LLMs) encode vast amounts of pre-trained knowledge in their parameters, but updating them as real-world information evolves remains a challenge. Existing methodologies and benchmarks primarily target entity substitutions, failing to capture the full breadth of complex real-wor...",
    "published": "Apr 16",
    "pdf_url": "https://arxiv.org/pdf/2504.12523v1",
    "arxiv_url": "http://arxiv.org/abs/2504.12523v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "Dense Backpropagation Improves Training for Sparse Mixture-of-Experts",
    "authors": [
      "Ashwinee Panda",
      "Vatsal Baherwani",
      "Zain Sarwar",
      "Benjamin Therien",
      "Sambit Sahu",
      "Tom Goldstein",
      "Supriyo Chakraborty"
    ],
    "summary": "Mixture of Experts (MoE) pretraining is more scalable than dense Transformer pretraining, because MoEs learn to route inputs to a sparse set of their feedforward parameters. However, this means that MoEs only receive a sparse backward update, leading to training instability and suboptimal performanc...",
    "published": "Apr 16",
    "pdf_url": "https://arxiv.org/pdf/2504.12463v3",
    "arxiv_url": "http://arxiv.org/abs/2504.12463v3",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "On Linear Representations and Pretraining Data Frequency in Language Models",
    "authors": [
      "Jack Merullo",
      "Noah A. Smith",
      "Sarah Wiegreffe",
      "Yanai Elazar"
    ],
    "summary": "Pretraining data has a direct impact on the behaviors and quality of language models (LMs), but we only understand the most basic principles of this relationship. While most work focuses on pretraining data's effect on downstream task behavior, we investigate its relationship to LM representations. ...",
    "published": "Apr 16",
    "pdf_url": "https://arxiv.org/pdf/2504.12459v1",
    "arxiv_url": "http://arxiv.org/abs/2504.12459v1",
    "queried_author": "Jack Merullo",
    "matching_authors": [
      "Jack Merullo",
      "Noah A. Smith"
    ]
  },
  {
    "title": "Position: The Most Expensive Part of an LLM should be its Training Data",
    "authors": [
      "Nikhil Kandpal",
      "Colin Raffel"
    ],
    "summary": "Training a state-of-the-art Large Language Model (LLM) is an increasingly expensive endeavor due to growing computational, hardware, energy, and engineering demands. Yet, an often-overlooked (and seldom paid) expense is the human labor behind these models' training data. Every LLM is built on an unf...",
    "published": "Apr 16",
    "pdf_url": "https://arxiv.org/pdf/2504.12427v1",
    "arxiv_url": "http://arxiv.org/abs/2504.12427v1",
    "queried_author": "Colin Raffel",
    "matching_authors": [
      "Colin Raffel"
    ]
  },
  {
    "title": "Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning",
    "authors": [
      "Syeda Nahida Akter",
      "Shrimai Prabhumoye",
      "Matvei Novikov",
      "Seungju Han",
      "Ying Lin",
      "Evelina Bakhturina",
      "Eric Nyberg",
      "Yejin Choi",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning -- where rules and correctness are well-defined -- generalizing these methods to broader reaso...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.13941v2",
    "arxiv_url": "http://arxiv.org/abs/2504.13941v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "DataDecide: How to Predict Best Pretraining Data with Small Experiments",
    "authors": [
      "Ian Magnusson",
      "Nguyen Tai",
      "Ben Bogin",
      "David Heineman",
      "Jena D. Hwang",
      "Luca Soldaini",
      "Akshita Bhagia",
      "Jiacheng Liu",
      "Dirk Groeneveld",
      "Oyvind Tafjord",
      "Noah A. Smith",
      "Pang Wei Koh",
      "Jesse Dodge"
    ],
    "summary": "Because large language models are expensive to pretrain on different datasets, using smaller-scale experiments to decide on data is crucial for reducing costs. Which benchmarks and methods of making decisions from observed performance at small scale most accurately predict the datasets that yield th...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.11393v2",
    "arxiv_url": "http://arxiv.org/abs/2504.11393v2",
    "queried_author": "Ian Magnusson",
    "matching_authors": [
      "Ian Magnusson",
      "Jesse Dodge",
      "Luca Soldaini",
      "Noah A. Smith",
      "Pang Wei Koh"
    ]
  },
  {
    "title": "RankAlign: A Ranking View of the Generator-Validator Gap in Large Language Models",
    "authors": [
      "Juan Diego Rodriguez",
      "Wenxuan Ding",
      "Katrin Erk",
      "Greg Durrett"
    ],
    "summary": "Although large language models (LLMs) have become more capable and accurate across many tasks, some fundamental sources of unreliability remain in their behavior. One key limitation is their inconsistency at reporting the same information when prompts are changed. In this paper, we consider the disc...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.11381v2",
    "arxiv_url": "http://arxiv.org/abs/2504.11381v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents",
    "authors": [
      "Salman Rahman",
      "Liwei Jiang",
      "James Shiffer",
      "Genglin Liu",
      "Sheriff Issaka",
      "Md Rizwan Parvez",
      "Hamid Palangi",
      "Kai-Wei Chang",
      "Yejin Choi",
      "Saadia Gabriel"
    ],
    "summary": "Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-te...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.13203v2",
    "arxiv_url": "http://arxiv.org/abs/2504.13203v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Looking beyond the next token",
    "authors": [
      "Abitha Thankaraj",
      "Yiding Jiang",
      "J. Zico Kolter",
      "Yonatan Bisk"
    ],
    "summary": "The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well ...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.11336v2",
    "arxiv_url": "http://arxiv.org/abs/2504.11336v2",
    "queried_author": "J Zico Kolter",
    "matching_authors": [
      "J Zico Kolter"
    ]
  },
  {
    "title": "Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective",
    "authors": [
      "Qiaosi Wang",
      "Xuhui Zhou",
      "Maarten Sap",
      "Jodi Forlizzi",
      "Hong Shen"
    ],
    "summary": "The last couple of years have witnessed emerging research that appropriates Theory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM capabilities as an indication of LLM's social intelligence. However, this approach has a number of limitations. Drawing on existing psychology and AI lite...",
    "published": "Apr 15",
    "pdf_url": "https://arxiv.org/pdf/2504.10839v1",
    "arxiv_url": "http://arxiv.org/abs/2504.10839v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "MIEB: Massive Image Embedding Benchmark",
    "authors": [
      "Chenghao Xiao",
      "Isaac Chung",
      "Imene Kerboua",
      "Jamie Stirling",
      "Xin Zhang",
      "M\u00e1rton Kardos",
      "Roman Solomatin",
      "Noura Al Moubayed",
      "Kenneth Enevoldsen",
      "Niklas Muennighoff"
    ],
    "summary": "Image representations are often evaluated through disjointed, task-specific protocols, leading to a fragmented understanding of model capabilities. For instance, it is unclear whether an image embedding model adept at clustering images is equally good at retrieving relevant images given a piece of t...",
    "published": "Apr 14",
    "pdf_url": "https://arxiv.org/pdf/2504.10471v1",
    "arxiv_url": "http://arxiv.org/abs/2504.10471v1",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff"
    ]
  },
  {
    "title": "M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models",
    "authors": [
      "Junxiong Wang",
      "Wen-Ding Li",
      "Daniele Paliotta",
      "Daniel Ritter",
      "Alexander M. Rush",
      "Tri Dao"
    ],
    "summary": "Effective reasoning is crucial to solving complex mathematical problems. Recent large language models (LLMs) have boosted performance by scaling test-time computation through long chain-of-thought reasoning. However, transformer-based models are inherently limited in extending context length due to ...",
    "published": "Apr 14",
    "pdf_url": "https://arxiv.org/pdf/2504.10449v3",
    "arxiv_url": "http://arxiv.org/abs/2504.10449v3",
    "queried_author": "Alexander M Rush",
    "matching_authors": [
      "Alexander M Rush",
      "Alexander M. Rush",
      "Tri Dao"
    ]
  },
  {
    "title": "VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge",
    "authors": [
      "Yueqi Song",
      "Tianyue Ou",
      "Yibo Kong",
      "Zecheng Li",
      "Graham Neubig",
      "Xiang Yue"
    ],
    "summary": "Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing ...",
    "published": "Apr 14",
    "pdf_url": "https://arxiv.org/pdf/2504.10342v3",
    "arxiv_url": "http://arxiv.org/abs/2504.10342v3",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects",
    "authors": [
      "Isabel O. Gallegos",
      "Chen Shani",
      "Weiyan Shi",
      "Federico Bianchi",
      "Izzy Gainsburg",
      "Dan Jurafsky",
      "Robb Willer"
    ],
    "summary": "As generative artificial intelligence (AI) enables the creation and dissemination of information at massive scale and speed, it is increasingly important to understand how people perceive AI-generated content. One prominent policy proposal requires explicitly labeling AI-generated content to increas...",
    "published": "Apr 14",
    "pdf_url": "https://arxiv.org/pdf/2504.09865v2",
    "arxiv_url": "http://arxiv.org/abs/2504.09865v2",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "On Language Models' Sensitivity to Suspicious Coincidences",
    "authors": [
      "Sriram Padmanabhan",
      "Kanishka Misra",
      "Kyle Mahowald",
      "Eunsol Choi"
    ],
    "summary": "Humans are sensitive to suspicious coincidences when generalizing inductively over data, as they make assumptions as to how the data was sampled. This results in smaller, more specific hypotheses being favored over more general ones. For instance, when provided the set {Austin, Dallas, Houston}, one...",
    "published": "Apr 13",
    "pdf_url": "https://arxiv.org/pdf/2504.09387v1",
    "arxiv_url": "http://arxiv.org/abs/2504.09387v1",
    "queried_author": "Eunsol Choi",
    "matching_authors": [
      "Eunsol Choi"
    ]
  },
  {
    "title": "QUDsim: Quantifying Discourse Similarities in LLM-Generated Text",
    "authors": [
      "Ramya Namuduri",
      "Yating Wu",
      "Anshun Asher Zheng",
      "Manya Wadhwa",
      "Greg Durrett",
      "Junyi Jessy Li"
    ],
    "summary": "As large language models become increasingly capable at various writing tasks, their weakness at generating unique and creative content becomes a major liability. Although LLMs have the ability to generate text covering diverse topics, there is an overall sense of repetitiveness across texts that we...",
    "published": "Apr 12",
    "pdf_url": "https://arxiv.org/pdf/2504.09373v2",
    "arxiv_url": "http://arxiv.org/abs/2504.09373v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Out of Style: RAG's Fragility to Linguistic Variation",
    "authors": [
      "Tianyu Cao",
      "Neel Bhandari",
      "Akhila Yerukola",
      "Akari Asai",
      "Maarten Sap"
    ],
    "summary": "Despite the impressive performance of Retrieval-augmented Generation (RAG) systems across various NLP benchmarks, their robustness in handling real-world user-LLM interaction queries remains largely underexplored. This presents a critical gap for practical deployment, where user queries exhibit grea...",
    "published": "Apr 11",
    "pdf_url": "https://arxiv.org/pdf/2504.08231v1",
    "arxiv_url": "http://arxiv.org/abs/2504.08231v1",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory",
    "authors": [
      "Mirac Suzgun",
      "Mert Yuksekgonul",
      "Federico Bianchi",
      "Dan Jurafsky",
      "James Zou"
    ],
    "summary": "Despite their impressive performance on complex tasks, current language models (LMs) typically operate in a vacuum: Each input query is processed separately, without retaining insights from previous attempts. Here, we present Dynamic Cheatsheet (DC), a lightweight framework that endows a black-box L...",
    "published": "Apr 10",
    "pdf_url": "https://arxiv.org/pdf/2504.07952v1",
    "arxiv_url": "http://arxiv.org/abs/2504.07952v1",
    "queried_author": "Dan Jurafsky",
    "matching_authors": [
      "Dan Jurafsky"
    ]
  },
  {
    "title": "Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with Question Answering",
    "authors": [
      "Patrick Fernandes",
      "Sweta Agrawal",
      "Emmanouil Zaranis",
      "Andr\u00e9 F. T. Martins",
      "Graham Neubig"
    ],
    "summary": "Despite the steady progress in machine translation evaluation, existing automatic metrics struggle to capture how well meaning is preserved beyond sentence boundaries. We posit that reliance on a single intrinsic quality score, trained to mimic human judgments, might be insufficient for evaluating t...",
    "published": "Apr 10",
    "pdf_url": "https://arxiv.org/pdf/2504.07583v3",
    "arxiv_url": "http://arxiv.org/abs/2504.07583v3",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "LoRI: Reducing Cross-Task Interference in Multi-Task Low-Rank Adaptation",
    "authors": [
      "Juzheng Zhang",
      "Jiacheng You",
      "Ashwinee Panda",
      "Tom Goldstein"
    ],
    "summary": "Low-Rank Adaptation (LoRA) has emerged as a popular parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), yet it still incurs notable overhead and suffers from parameter interference in multi-task scenarios. We propose LoRA with Reduced Interference (LoRI), a simple yet eff...",
    "published": "Apr 10",
    "pdf_url": "https://arxiv.org/pdf/2504.07448v2",
    "arxiv_url": "http://arxiv.org/abs/2504.07448v2",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training Tokens",
    "authors": [
      "Jiacheng Liu",
      "Taylor Blanton",
      "Yanai Elazar",
      "Sewon Min",
      "YenSung Chen",
      "Arnavi Chheda-Kothary",
      "Huy Tran",
      "Byron Bischoff",
      "Eric Marsh",
      "Michael Schmitz",
      "Cassidy Trier",
      "Aaron Sarnat",
      "Jenna James",
      "Jon Borchardt",
      "Bailey Kuehl",
      "Evie Cheng",
      "Karen Farley",
      "Sruthi Sreeram",
      "Taira Anderson",
      "David Albright",
      "Carissa Schoenick",
      "Luca Soldaini",
      "Dirk Groeneveld",
      "Rock Yuren Pang",
      "Pang Wei Koh",
      "Noah A. Smith",
      "Sophie Lebrecht",
      "Yejin Choi",
      "Hannaneh Hajishirzi",
      "Ali Farhadi",
      "Jesse Dodge"
    ],
    "summary": "We present OLMoTrace, the first system that traces the outputs of language models back to their full, multi-trillion-token training data in real time. OLMoTrace finds and shows verbatim matches between segments of language model output and documents in the training text corpora. Powered by an extend...",
    "published": "Apr 09",
    "pdf_url": "https://arxiv.org/pdf/2504.07096v2",
    "arxiv_url": "http://arxiv.org/abs/2504.07096v2",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi",
      "Jesse Dodge",
      "Luca Soldaini",
      "Noah A. Smith",
      "Pang Wei Koh",
      "Yejin Choi"
    ]
  },
  {
    "title": "Self-Steering Language Models",
    "authors": [
      "Gabriel Grand",
      "Joshua B. Tenenbaum",
      "Vikash K. Mansinghka",
      "Alexander K. Lew",
      "Jacob Andreas"
    ],
    "summary": "While test-time reasoning enables language models (LMs) to tackle complex tasks, searching or planning in natural language can be slow, costly, and error-prone. But even when LMs struggle to emulate the precise reasoning steps needed to solve a problem, they often excel at describing its abstract st...",
    "published": "Apr 09",
    "pdf_url": "https://arxiv.org/pdf/2504.07081v2",
    "arxiv_url": "http://arxiv.org/abs/2504.07081v2",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "SkillWeaver: Web Agents can Self-Improve by Discovering and Honing Skills",
    "authors": [
      "Boyuan Zheng",
      "Michael Y. Fatemi",
      "Xiaolong Jin",
      "Zora Zhiruo Wang",
      "Apurva Gandhi",
      "Yueqi Song",
      "Yu Gu",
      "Jayanth Srinivasa",
      "Gaowen Liu",
      "Graham Neubig",
      "Yu Su"
    ],
    "summary": "To survive and thrive in complex environments, humans have evolved sophisticated self-improvement mechanisms through environment exploration, hierarchical abstraction of experiences into reuseable skills, and collaborative construction of an ever-growing skill repertoire. Despite recent advancements...",
    "published": "Apr 09",
    "pdf_url": "https://arxiv.org/pdf/2504.07079v1",
    "arxiv_url": "http://arxiv.org/abs/2504.07079v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Inducing Programmatic Skills for Agentic Tasks",
    "authors": [
      "Zora Zhiruo Wang",
      "Apurva Gandhi",
      "Graham Neubig",
      "Daniel Fried"
    ],
    "summary": "To succeed in common digital tasks such as web navigation, agents must carry out a variety of specialized tasks such as searching for products or planning a travel route. To tackle these tasks, agents can bootstrap themselves by learning task-specific skills online through interaction with the web e...",
    "published": "Apr 09",
    "pdf_url": "https://arxiv.org/pdf/2504.06821v2",
    "arxiv_url": "http://arxiv.org/abs/2504.06821v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Lugha-Llama: Adapting Large Language Models for African Languages",
    "authors": [
      "Happy Buzaaba",
      "Alexander Wettig",
      "David Ifeoluwa Adelani",
      "Christiane Fellbaum"
    ],
    "summary": "Large language models (LLMs) have achieved impressive results in a wide range of natural language applications. However, they often struggle to recognize low-resource languages, in particular African languages, which are not well represented in large training corpora. In this paper, we consider how ...",
    "published": "Apr 09",
    "pdf_url": "https://arxiv.org/pdf/2504.06536v1",
    "arxiv_url": "http://arxiv.org/abs/2504.06536v1",
    "queried_author": "Alexander Wettig",
    "matching_authors": [
      "Alexander Wettig"
    ]
  },
  {
    "title": "Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling Opt-Outs",
    "authors": [
      "Dongyang Fan",
      "Vinko Sabol\u010dec",
      "Matin Ansaripour",
      "Ayush Kumar Tarun",
      "Martin Jaggi",
      "Antoine Bosselut",
      "Imanol Schlag"
    ],
    "summary": "The increasing adoption of web crawling opt-outs by copyright holders of online content raises critical questions about the impact of data compliance on large language model (LLM) performance. However, little is known about how these restrictions (and the resultant filtering of pretraining datasets)...",
    "published": "Apr 08",
    "pdf_url": "https://arxiv.org/pdf/2504.06219v2",
    "arxiv_url": "http://arxiv.org/abs/2504.06219v2",
    "queried_author": "Antoine Bosselut",
    "matching_authors": [
      "Antoine Bosselut"
    ]
  },
  {
    "title": "M-Prometheus: A Suite of Open Multilingual LLM Judges",
    "authors": [
      "Jos\u00e9 Pombal",
      "Dongkeun Yoon",
      "Patrick Fernandes",
      "Ian Wu",
      "Seungone Kim",
      "Ricardo Rei",
      "Graham Neubig",
      "Andr\u00e9 F. T. Martins"
    ],
    "summary": "The use of language models for automatically evaluating long-form text (LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are optimized exclusively for English, with strategies for enhancing their multilingual evaluation capabilities remaining largely unexplored in the current lit...",
    "published": "Apr 07",
    "pdf_url": "https://arxiv.org/pdf/2504.04953v2",
    "arxiv_url": "http://arxiv.org/abs/2504.04953v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig",
      "Seungone Kim"
    ]
  },
  {
    "title": "Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use",
    "authors": [
      "Anna Goldie",
      "Azalia Mirhoseini",
      "Hao Zhou",
      "Irene Cai",
      "Christopher D. Manning"
    ],
    "summary": "Reinforcement learning has been shown to improve the performance of large language models. However, traditional approaches like RLHF or RLAIF treat the problem as single-step. As focus shifts toward more complex reasoning and agentic tasks, language models must take multiple steps of text generation...",
    "published": "Apr 07",
    "pdf_url": "https://arxiv.org/pdf/2504.04736v2",
    "arxiv_url": "http://arxiv.org/abs/2504.04736v2",
    "queried_author": "Christopher D Manning",
    "matching_authors": [
      "Christopher D Manning"
    ]
  },
  {
    "title": "Steering off Course: Reliability Challenges in Steering Language Models",
    "authors": [
      "Patrick Queiroz Da Silva",
      "Hari Sethuraman",
      "Dheeraj Rajagopal",
      "Hannaneh Hajishirzi",
      "Sachin Kumar"
    ],
    "summary": "Steering methods for language models (LMs) have gained traction as lightweight alternatives to fine-tuning, enabling targeted modifications to model activations. However, prior studies primarily report results on a few models, leaving critical gaps in understanding the robustness of these methods. I...",
    "published": "Apr 06",
    "pdf_url": "https://arxiv.org/pdf/2504.04635v1",
    "arxiv_url": "http://arxiv.org/abs/2504.04635v1",
    "queried_author": "Hannaneh Hajishirzi",
    "matching_authors": [
      "Hannaneh Hajishirzi"
    ]
  },
  {
    "title": "Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning",
    "authors": [
      "Ximing Lu",
      "Seungju Han",
      "David Acuna",
      "Hyunwoo Kim",
      "Jaehun Jung",
      "Shrimai Prabhumoye",
      "Niklas Muennighoff",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Yejin Choi"
    ],
    "summary": "Large reasoning models exhibit remarkable reasoning capabilities via long, elaborate reasoning trajectories. Supervised fine-tuning on such reasoning traces, also known as distillation, can be a cost-effective way to boost reasoning capabilities of student models. However, empirical observations rev...",
    "published": "Apr 06",
    "pdf_url": "https://arxiv.org/pdf/2504.04383v2",
    "arxiv_url": "http://arxiv.org/abs/2504.04383v2",
    "queried_author": "Niklas Muennighoff",
    "matching_authors": [
      "Niklas Muennighoff",
      "Yejin Choi"
    ]
  },
  {
    "title": "PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages",
    "authors": [
      "Priyanshu Kumar",
      "Devansh Jain",
      "Akhila Yerukola",
      "Liwei Jiang",
      "Himanshu Beniwal",
      "Thomas Hartvigsen",
      "Maarten Sap"
    ],
    "summary": "Truly multilingual safety moderation efforts for Large Language Models (LLMs) have been hindered by a narrow focus on a small set of languages (e.g., English, Chinese) as well as a limited scope of safety definition, resulting in significant gaps in moderation capabilities. To bridge these gaps, we ...",
    "published": "Apr 06",
    "pdf_url": "https://arxiv.org/pdf/2504.04377v2",
    "arxiv_url": "http://arxiv.org/abs/2504.04377v2",
    "queried_author": "Maarten Sap",
    "matching_authors": [
      "Maarten Sap"
    ]
  },
  {
    "title": "Identifying and Evaluating Inactive Heads in Pretrained LLMs",
    "authors": [
      "Pedro Sandoval-Segura",
      "Xijun Wang",
      "Ashwinee Panda",
      "Micah Goldblum",
      "Ronen Basri",
      "Tom Goldstein",
      "David Jacobs"
    ],
    "summary": "Attention is foundational to large language models (LLMs), enabling different heads to have diverse focus on relevant input tokens. However, learned behaviors like attention sinks, where the first token receives the most attention despite limited semantic importance, suggest some heads may be inacti...",
    "published": "Apr 04",
    "pdf_url": "https://arxiv.org/pdf/2504.03889v3",
    "arxiv_url": "http://arxiv.org/abs/2504.03889v3",
    "queried_author": "Ashwinee Panda",
    "matching_authors": [
      "Ashwinee Panda"
    ]
  },
  {
    "title": "Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models",
    "authors": [
      "NVIDIA",
      ":",
      "Aaron Blakeman",
      "Aarti Basant",
      "Abhinav Khattar",
      "Adithya Renduchintala",
      "Akhiad Bercovich",
      "Aleksander Ficek",
      "Alexis Bjorlin",
      "Ali Taghibakhshi",
      "Amala Sanjay Deshmukh",
      "Ameya Sunil Mahabaleshwarkar",
      "Andrew Tao",
      "Anna Shors",
      "Ashwath Aithal",
      "Ashwin Poojary",
      "Ayush Dattagupta",
      "Balaram Buddharaju",
      "Bobby Chen",
      "Boris Ginsburg",
      "Boxin Wang",
      "Brandon Norick",
      "Brian Butterfield",
      "Bryan Catanzaro",
      "Carlo del Mundo",
      "Chengyu Dong",
      "Christine Harvey",
      "Christopher Parisien",
      "Dan Su",
      "Daniel Korzekwa",
      "Danny Yin",
      "Daria Gitman",
      "David Mosallanezhad",
      "Deepak Narayanan",
      "Denys Fridman",
      "Dima Rekesh",
      "Ding Ma",
      "Dmytro Pykhtar",
      "Dong Ahn",
      "Duncan Riach",
      "Dusan Stosic",
      "Eileen Long",
      "Elad Segal",
      "Ellie Evans",
      "Eric Chung",
      "Erick Galinkin",
      "Evelina Bakhturina",
      "Ewa Dobrowolska",
      "Fei Jia",
      "Fuxiao Liu",
      "Gargi Prasad",
      "Gerald Shen",
      "Guilin Liu",
      "Guo Chen",
      "Haifeng Qian",
      "Helen Ngo",
      "Hongbin Liu",
      "Hui Li",
      "Igor Gitman",
      "Ilia Karmanov",
      "Ivan Moshkov",
      "Izik Golan",
      "Jan Kautz",
      "Jane Polak Scowcroft",
      "Jared Casper",
      "Jarno Seppanen",
      "Jason Lu",
      "Jason Sewall",
      "Jiaqi Zeng",
      "Jiaxuan You",
      "Jimmy Zhang",
      "Jing Zhang",
      "Jining Huang",
      "Jinze Xue",
      "Jocelyn Huang",
      "Joey Conway",
      "John Kamalu",
      "Jon Barker",
      "Jonathan Cohen",
      "Joseph Jennings",
      "Jupinder Parmar",
      "Karan Sapra",
      "Kari Briski",
      "Kateryna Chumachenko",
      "Katherine Luna",
      "Keshav Santhanam",
      "Kezhi Kong",
      "Kirthi Sivamani",
      "Krzysztof Pawelec",
      "Kumar Anik",
      "Kunlun Li",
      "Lawrence McAfee",
      "Leon Derczynski",
      "Lindsey Pavao",
      "Luis Vega",
      "Lukas Voegtle",
      "Maciej Bala",
      "Maer Rodrigues de Melo",
      "Makesh Narsimhan Sreedhar",
      "Marcin Chochowski",
      "Markus Kliegl",
      "Marta Stepniewska-Dziubinska",
      "Matthieu Le",
      "Matvei Novikov",
      "Mehrzad Samadi",
      "Michael Andersch",
      "Michael Evans",
      "Miguel Martinez",
      "Mike Chrzanowski",
      "Mike Ranzinger",
      "Mikolaj Blaz",
      "Misha Smelyanskiy",
      "Mohamed Fawzy",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Nayeon Lee",
      "Nima Tajbakhsh",
      "Ning Xu",
      "Oleg Rybakov",
      "Oleksii Kuchaiev",
      "Olivier Delalleau",
      "Osvald Nitski",
      "Parth Chadha",
      "Pasha Shamis",
      "Paulius Micikevicius",
      "Pavlo Molchanov",
      "Peter Dykas",
      "Philipp Fischer",
      "Pierre-Yves Aquilanti",
      "Piotr Bialecki",
      "Prasoon Varshney",
      "Pritam Gundecha",
      "Przemek Tredak",
      "Rabeeh Karimi",
      "Rahul Kandu",
      "Ran El-Yaniv",
      "Raviraj Joshi",
      "Roger Waleffe",
      "Ruoxi Zhang",
      "Sabrina Kavanaugh",
      "Sahil Jain",
      "Samuel Kriman",
      "Sangkug Lym",
      "Sanjeev Satheesh",
      "Saurav Muralidharan",
      "Sean Narenthiran",
      "Selvaraj Anandaraj",
      "Seonmyeong Bak",
      "Sergey Kashirsky",
      "Seungju Han",
      "Shantanu Acharya",
      "Shaona Ghosh",
      "Sharath Turuvekere Sreenivas",
      "Sharon Clay",
      "Shelby Thomas",
      "Shrimai Prabhumoye",
      "Shubham Pachori",
      "Shubham Toshniwal",
      "Shyamala Prayaga",
      "Siddhartha Jain",
      "Sirshak Das",
      "Slawek Kierat",
      "Somshubra Majumdar",
      "Song Han",
      "Soumye Singhal",
      "Sriharsha Niverty",
      "Stefania Alborghetti",
      "Suseella Panguluri",
      "Swetha Bhendigeri",
      "Syeda Nahida Akter",
      "Szymon Migacz",
      "Tal Shiri",
      "Terry Kong",
      "Timo Roman",
      "Tomer Ronen",
      "Trisha Saar",
      "Tugrul Konuk",
      "Tuomas Rintamaki",
      "Tyler Poon",
      "Ushnish De",
      "Vahid Noroozi",
      "Varun Singh",
      "Vijay Korthikanti",
      "Vitaly Kurin",
      "Wasi Uddin Ahmad",
      "Wei Du",
      "Wei Ping",
      "Wenliang Dai",
      "Wonmin Byeon",
      "Xiaowei Ren",
      "Yao Xu",
      "Yejin Choi",
      "Yian Zhang",
      "Ying Lin",
      "Yoshi Suhara",
      "Zhiding Yu",
      "Zhiqi Li",
      "Zhiyu Li",
      "Zhongbo Zhu",
      "Zhuolin Yang",
      "Zijia Chen"
    ],
    "summary": "As inference-time scaling becomes critical for enhanced reasoning capabilities, it is increasingly becoming important to build models that are efficient to infer. We introduce Nemotron-H, a family of 8B and 56B/47B hybrid Mamba-Transformer models designed to reduce inference cost for a given accurac...",
    "published": "Apr 04",
    "pdf_url": "https://arxiv.org/pdf/2504.03624v4",
    "arxiv_url": "http://arxiv.org/abs/2504.03624v4",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Sample, Don't Search: Rethinking Test-Time Alignment for Language Models",
    "authors": [
      "Gon\u00e7alo Faria",
      "Noah A. Smith"
    ],
    "summary": "Increasing test-time computation has emerged as a promising direction for improving language model performance, particularly in scenarios where model finetuning is impractical or impossible due to computational constraints or private model weights. However, existing test-time search methods using a ...",
    "published": "Apr 04",
    "pdf_url": "https://arxiv.org/pdf/2504.03790v2",
    "arxiv_url": "http://arxiv.org/abs/2504.03790v2",
    "queried_author": "Noah A. Smith",
    "matching_authors": [
      "Noah A. Smith"
    ]
  },
  {
    "title": "Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning",
    "authors": [
      "Julian Minder",
      "Cl\u00e9ment Dumas",
      "Caden Juang",
      "Bilal Chugtai",
      "Neel Nanda"
    ],
    "summary": "Model diffing is the study of how fine-tuning changes a model's representations and internal algorithms. Many behaviors of interest are introduced during fine-tuning, and model diffing offers a promising lens to interpret such behaviors. Crosscoders are a recent model diffing method that learns a sh...",
    "published": "Apr 03",
    "pdf_url": "https://arxiv.org/pdf/2504.02922v3",
    "arxiv_url": "http://arxiv.org/abs/2504.02922v3",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda"
    ]
  },
  {
    "title": "Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?",
    "authors": [
      "Celine Lee",
      "Alexander M. Rush",
      "Keyon Vafa"
    ],
    "summary": "Large language models (LLMs) often benefit from verbalized reasoning at inference time, but it remains unclear which aspects of task difficulty these extra reasoning tokens address. To investigate this question, we formalize a framework using deterministic finite automata (DFAs). DFAs offer a formal...",
    "published": "Apr 02",
    "pdf_url": "https://arxiv.org/pdf/2504.01935v1",
    "arxiv_url": "http://arxiv.org/abs/2504.01935v1",
    "queried_author": "Alexander M Rush",
    "matching_authors": [
      "Alexander M Rush",
      "Alexander M. Rush"
    ]
  },
  {
    "title": "An Approach to Technical AGI Safety and Security",
    "authors": [
      "Rohin Shah",
      "Alex Irpan",
      "Alexander Matt Turner",
      "Anna Wang",
      "Arthur Conmy",
      "David Lindner",
      "Jonah Brown-Cohen",
      "Lewis Ho",
      "Neel Nanda",
      "Raluca Ada Popa",
      "Rishub Jain",
      "Rory Greig",
      "Samuel Albanie",
      "Scott Emmons",
      "Sebastian Farquhar",
      "S\u00e9bastien Krier",
      "Senthooran Rajamanoharan",
      "Sophie Bridgers",
      "Tobi Ijitoye",
      "Tom Everitt",
      "Victoria Krakovna",
      "Vikrant Varma",
      "Vladimir Mikulik",
      "Zachary Kenton",
      "Dave Orr",
      "Shane Legg",
      "Noah Goodman",
      "Allan Dafoe",
      "Four Flynn",
      "Anca Dragan"
    ],
    "summary": "Artificial General Intelligence (AGI) promises transformative benefits but also presents significant risks. We develop an approach to address the risk of harms consequential enough to significantly harm humanity. We identify four areas of risk: misuse, misalignment, mistakes, and structural risks. O...",
    "published": "Apr 02",
    "pdf_url": "https://arxiv.org/pdf/2504.01849v1",
    "arxiv_url": "http://arxiv.org/abs/2504.01849v1",
    "queried_author": "Neel Nanda",
    "matching_authors": [
      "Neel Nanda",
      "Noah Goodman"
    ]
  },
  {
    "title": "YourBench: Easy Custom Evaluation Sets for Everyone",
    "authors": [
      "Sumuk Shashidhar",
      "Cl\u00e9mentine Fourrier",
      "Alina Lozovskia",
      "Thomas Wolf",
      "Gokhan Tur",
      "Dilek Hakkani-T\u00fcr"
    ],
    "summary": "Evaluating large language models (LLMs) effectively remains a critical bottleneck, as traditional static benchmarks suffer from saturation and contamination, while human evaluations are costly and slow. This hinders timely or domain-specific assessment, crucial for real-world applications. We introd...",
    "published": "Apr 02",
    "pdf_url": "https://arxiv.org/pdf/2504.01833v1",
    "arxiv_url": "http://arxiv.org/abs/2504.01833v1",
    "queried_author": "Cl\u00e9mentine Fourrier",
    "matching_authors": [
      "Cl\u00e9mentine Fourrier"
    ]
  },
  {
    "title": "ThinkPrune: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning",
    "authors": [
      "Bairu Hou",
      "Yang Zhang",
      "Jiabao Ji",
      "Yujian Liu",
      "Kaizhi Qian",
      "Jacob Andreas",
      "Shiyu Chang"
    ],
    "summary": "We present ThinkPrune, a simple yet effective method for pruning the thinking length for long-thinking LLMs, which has been found to often produce inefficient and redundant thinking processes. Existing preliminary explorations of reducing thinking length primarily focus on forcing the thinking proce...",
    "published": "Apr 02",
    "pdf_url": "https://arxiv.org/pdf/2504.01296v1",
    "arxiv_url": "http://arxiv.org/abs/2504.01296v1",
    "queried_author": "Jacob Andreas",
    "matching_authors": [
      "Jacob Andreas"
    ]
  },
  {
    "title": "Is the Top Still Spinning? Evaluating Subjectivity in Narrative Understanding",
    "authors": [
      "Melanie Subbiah",
      "Akankshya Mishra",
      "Grace Kim",
      "Liyan Tang",
      "Greg Durrett",
      "Kathleen McKeown"
    ],
    "summary": "Determining faithfulness of a claim to a source document is an important problem across many domains. This task is generally treated as a binary judgment of whether the claim is supported or unsupported in relation to the source. In many cases, though, whether a claim is supported can be ambiguous. ...",
    "published": "Apr 01",
    "pdf_url": "https://arxiv.org/pdf/2504.01132v2",
    "arxiv_url": "http://arxiv.org/abs/2504.01132v2",
    "queried_author": "Greg Durrett",
    "matching_authors": [
      "Greg Durrett"
    ]
  },
  {
    "title": "Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?",
    "authors": [
      "Olawale Salaudeen",
      "Nicole Chiou",
      "Shiny Weng",
      "Sanmi Koyejo"
    ],
    "summary": "Spurious correlations, unstable statistical shortcuts a model can exploit, are expected to degrade performance out-of-distribution (OOD). However, across many popular OOD generalization benchmarks, vanilla empirical risk minimization (ERM) often achieves the highest OOD accuracy. Moreover, gains in ...",
    "published": "Mar 31",
    "pdf_url": "https://arxiv.org/pdf/2504.00186v3",
    "arxiv_url": "http://arxiv.org/abs/2504.00186v3",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  }
]