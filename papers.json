[
  {
    "title": "Zero-shot Multimodal Document Retrieval via Cross-modal Question Generation",
    "authors": [
      "Yejin Choi",
      "Jaewoo Park",
      "Janghan Yoon",
      "Saejin Kim",
      "Jaehyun Jeon",
      "Youngjae Yu"
    ],
    "summary": "Rapid advances in Multimodal Large Language Models (MLLMs) have expanded information retrieval beyond purely textual inputs, enabling retrieval from complex real world documents that combine text and visuals. However, most documents are private either owned by individuals or confined within corporat...",
    "published": "Aug 23",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2508.17079v1",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "High-Dimensional Markov-switching Ordinary Differential Processes",
    "authors": [
      "Katherine Tsai",
      "Mladen Kolar",
      "Sanmi Koyejo"
    ],
    "summary": "We investigate the parameter recovery of Markov-switching ordinary differential processes from discrete observations, where the differential equations are nonlinear additive models. This framework has been widely applied in biological systems, control systems, and other domains; however, limited res...",
    "published": "Dec 30",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2501.00087v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Towards Visual Text Design Transfer Across Languages",
    "authors": [
      "Yejin Choi",
      "Jiwan Chung",
      "Sumin Shim",
      "Giyeong Oh",
      "Youngjae Yu"
    ],
    "summary": "Visual text design plays a critical role in conveying themes, emotions, and atmospheres in multimodal formats such as film posters and album covers. Translating these visual and textual elements across languages extends the concept of translation beyond mere text, requiring the adaptation of aesthet...",
    "published": "Oct 24",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2410.18823v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education",
    "authors": [
      "Seungyoon Kim",
      "Seungone Kim"
    ],
    "summary": "Large language model (LLM)-based evaluation pipelines have demonstrated their capability to robustly evaluate machine-generated text. Extending this methodology to assess human-written text could significantly benefit educational settings by providing direct feedback to enhance writing skills, altho...",
    "published": "Jul 24",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2407.17022v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "In-Context Learning of Energy Functions",
    "authors": [
      "Rylan Schaeffer",
      "Mikail Khona",
      "Sanmi Koyejo"
    ],
    "summary": "In-context learning is a powerful capability of certain machine learning models that arguably underpins the success of today's frontier AI models. However, in-context learning is critically limited to settings where the in-context distribution of interest $p_\u03b8^{ICL}( x|\\mathcal{D})$ can be straightf...",
    "published": "Jun 18",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2406.12785v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "miniCodeProps: a Minimal Benchmark for Proving Code Properties",
    "authors": [
      "Evan Lohn",
      "Sean Welleck"
    ],
    "summary": "AI agents have shown initial promise in automating mathematical theorem proving in proof assistants such as Lean. The same proof assistants can be used to verify the correctness of code by pairing code with specifications and proofs that the specifications hold. Automating the writing of code, speci...",
    "published": "Jun 16",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2406.11915v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "Causally Inspired Regularization Enables Domain General Representations",
    "authors": [
      "Olawale Salaudeen",
      "Sanmi Koyejo"
    ],
    "summary": "Given a causal graph representing the data-generating process shared across different domains/distributions, enforcing sufficient graph-implied conditional independencies can identify domain-general (non-spurious) feature representations. For the standard input-output predictive setting, we categori...",
    "published": "Apr 25",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2404.16277v1",
    "queried_author": "Sanmi Koyejo",
    "matching_authors": [
      "Sanmi Koyejo"
    ]
  },
  {
    "title": "Disentangling Length from Quality in Direct Preference Optimization",
    "authors": [
      "Ryan Park",
      "Rafael Rafailov",
      "Stefano Ermon",
      "Chelsea Finn"
    ],
    "summary": "Reinforcement Learning from Human Feedback (RLHF) has been a crucial component in the recent success of Large Language Models. However, RLHF is know to exploit biases in human preferences, such as verbosity. A well-formatted and eloquent answer is often more highly rated by users, even when it is le...",
    "published": "Mar 28",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2403.19159v2",
    "queried_author": "Rafael Rafailov",
    "matching_authors": [
      "Rafael Rafailov"
    ]
  },
  {
    "title": "Few-Shot Recalibration of Language Models",
    "authors": [
      "Xiang Lisa Li",
      "Urvashi Khandelwal",
      "Kelvin Guu"
    ],
    "summary": "Recent work has uncovered promising ways to extract well-calibrated confidence estimates from language models (LMs), where the model's confidence score reflects how likely it is to be correct. However, while LMs may appear well-calibrated over broad distributions, this often hides significant miscal...",
    "published": "Mar 27",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2403.18286v1",
    "queried_author": "Xiang Lisa Li",
    "matching_authors": [
      "Xiang Lisa Li"
    ]
  },
  {
    "title": "Language models scale reliably with over-training and on downstream tasks",
    "authors": [
      "Samir Yitzhak Gadre",
      "Georgios Smyrnis",
      "Vaishaal Shankar",
      "Suchin Gururangan",
      "Mitchell Wortsman",
      "Rulin Shao",
      "Jean Mercat",
      "Alex Fang",
      "Jeffrey Li",
      "Sedrick Keh",
      "Rui Xin",
      "Marianna Nezhurina",
      "Igor Vasiljevic",
      "Jenia Jitsev",
      "Luca Soldaini",
      "Alexandros G. Dimakis",
      "Gabriel Ilharco",
      "Pang Wei Koh",
      "Shuran Song",
      "Thomas Kollar",
      "Yair Carmon",
      "Achal Dave",
      "Reinhard Heckel",
      "Niklas Muennighoff",
      "Ludwig Schmidt"
    ],
    "summary": "Scaling laws are useful guides for derisking expensive training runs, as they predict performance of large models using cheaper, small-scale experiments. However, there remain gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is ...",
    "published": "Mar 13",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2403.08540v2",
    "queried_author": "Samir Yitzhak Gadre",
    "matching_authors": [
      "Samir Yitzhak Gadre"
    ]
  },
  {
    "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
    "authors": [
      "Albert Gu",
      "Tri Dao"
    ],
    "summary": "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state ...",
    "published": "Dec 01",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2312.00752v2",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "A Material Lens on Coloniality in NLP",
    "authors": [
      "William Held",
      "Camille Harris",
      "Michael Best",
      "Diyi Yang"
    ],
    "summary": "Coloniality, the continuation of colonial harms beyond \"official\" colonization, has pervasive effects across society and scientific fields. Natural Language Processing (NLP) is no exception to this broad phenomenon. In this work, we argue that coloniality is implicitly embedded in and amplified by N...",
    "published": "Nov 14",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2311.08391v1",
    "queried_author": "William Held",
    "matching_authors": [
      "William Held"
    ]
  },
  {
    "title": "FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning",
    "authors": [
      "Tri Dao"
    ],
    "summary": "Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the ma...",
    "published": "Jul 17",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2307.08691v1",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "CB2: Collaborative Natural Language Interaction Research Platform",
    "authors": [
      "Jacob Sharf",
      "Mustafa Omer Gul",
      "Yoav Artzi"
    ],
    "summary": "CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at h...",
    "published": "Mar 14",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2303.08127v3",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Shapley Head Pruning: Identifying and Removing Interference in Multilingual Transformers",
    "authors": [
      "William Held",
      "Diyi Yang"
    ],
    "summary": "Multilingual transformer-based models demonstrate remarkable zero and few-shot transfer across languages by learning and reusing language-agnostic features. However, as a fixed-size model acquires more languages, its performance across all languages degrades, a phenomenon termed interference. Often ...",
    "published": "Oct 11",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2210.05709v1",
    "queried_author": "William Held",
    "matching_authors": [
      "William Held"
    ]
  },
  {
    "title": "Mind the Gap! Injecting Commonsense Knowledge for Abstractive Dialogue Summarization",
    "authors": [
      "Seungone Kim",
      "Se June Joo",
      "Hyungjoo Chae",
      "Chaehyeong Kim",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "summary": "In this paper, we propose to leverage the unique characteristics of dialogues sharing commonsense knowledge across participants, to resolve the difficulties in summarizing them. We present SICK, a framework that uses commonsense inferences as additional context. Compared to previous work that solely...",
    "published": "Sep 02",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2209.00930v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "Can Language Models perform Abductive Commonsense Reasoning?",
    "authors": [
      "Seungone Kim"
    ],
    "summary": "Abductive Reasoning is a task of inferring the most plausible hypothesis given a set of observations. In literature, the community has approached to solve this challenge by classifying/generating a likely hypothesis that does not contradict with a past observation and future observation. Some of the...",
    "published": "Jul 07",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2207.05155v1",
    "queried_author": "Seungone Kim",
    "matching_authors": [
      "Seungone Kim"
    ]
  },
  {
    "title": "When to Use Multi-Task Learning vs Intermediate Fine-Tuning for Pre-Trained Encoder Transfer Learning",
    "authors": [
      "Orion Weller",
      "Kevin Seppi",
      "Matt Gardner"
    ],
    "summary": "Transfer learning (TL) in natural language processing (NLP) has seen a surge of interest in recent years, as pre-trained models have shown an impressive ability to transfer to novel tasks. Three main strategies have emerged for making use of multiple supervised datasets during fine-tuning: training ...",
    "published": "May 17",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2205.08124v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "CoWs on Pasture: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation",
    "authors": [
      "Samir Yitzhak Gadre",
      "Mitchell Wortsman",
      "Gabriel Ilharco",
      "Ludwig Schmidt",
      "Shuran Song"
    ],
    "summary": "For robots to be generally useful, they must be able to find arbitrary objects described by people (i.e., be language-driven) even without expensive navigation training on in-domain data (i.e., perform zero-shot inference). We explore these capabilities in a unified setting: language-driven zero-sho...",
    "published": "Mar 20",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2203.10421v2",
    "queried_author": "Samir Yitzhak Gadre",
    "matching_authors": [
      "Samir Yitzhak Gadre"
    ]
  },
  {
    "title": "Focus on what matters: Applying Discourse Coherence Theory to Cross Document Coreference",
    "authors": [
      "William Held",
      "Dan Iter",
      "Dan Jurafsky"
    ],
    "summary": "Performing event and entity coreference resolution across documents vastly increases the number of candidate mentions, making it intractable to do the full $n^2$ pairwise comparisons. Existing approaches simplify by considering coreference only within document clusters, but this fails to handle inte...",
    "published": "Oct 11",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2110.05362v1",
    "queried_author": "William Held",
    "matching_authors": [
      "William Held"
    ]
  },
  {
    "title": "Visual Adversarial Imitation Learning using Variational Models",
    "authors": [
      "Rafael Rafailov",
      "Tianhe Yu",
      "Aravind Rajeswaran",
      "Chelsea Finn"
    ],
    "summary": "Reward function specification, which requires considerable human effort and iteration, remains a major impediment for learning behaviors through deep reinforcement learning. In contrast, providing visual demonstrations of desired behaviors often presents an easier and more natural way to teach agent...",
    "published": "Jul 16",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2107.08829v2",
    "queried_author": "Rafael Rafailov",
    "matching_authors": [
      "Rafael Rafailov"
    ]
  },
  {
    "title": "Act the Part: Learning Interaction Strategies for Articulated Object Part Discovery",
    "authors": [
      "Samir Yitzhak Gadre",
      "Kiana Ehsani",
      "Shuran Song"
    ],
    "summary": "People often use physical intuition when manipulating articulated objects, irrespective of object semantics. Motivated by this observation, we identify an important embodied task where an agent must play with objects to recover their parts. To this end, we introduce Act the Part (AtP) to learn how t...",
    "published": "May 03",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2105.01047v1",
    "queried_author": "Samir Yitzhak Gadre",
    "matching_authors": [
      "Samir Yitzhak Gadre"
    ]
  },
  {
    "title": "Exploring the Relationship Between Algorithm Performance, Vocabulary, and Run-Time in Text Classification",
    "authors": [
      "Wilson Fearn",
      "Orion Weller",
      "Kevin Seppi"
    ],
    "summary": "Text classification is a significant branch of natural language processing, and has many applications including document classification and sentiment analysis. Unsurprisingly, those who do text classification are concerned with the run-time of their algorithms, many of which depend on the size of th...",
    "published": "Apr 08",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2104.03848v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    "authors": [
      "Xiang Lisa Li",
      "Percy Liang"
    ],
    "summary": "Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tu...",
    "published": "Jan 01",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2101.00190v1",
    "queried_author": "Xiang Lisa Li",
    "matching_authors": [
      "Xiang Lisa Li"
    ]
  },
  {
    "title": "Offline Reinforcement Learning from Images with Latent Space Models",
    "authors": [
      "Rafael Rafailov",
      "Tianhe Yu",
      "Aravind Rajeswaran",
      "Chelsea Finn"
    ],
    "summary": "Offline reinforcement learning (RL) refers to the problem of learning policies from a static dataset of environment interactions. Offline RL enables extensive use and re-use of historical datasets, while also alleviating safety concerns associated with online exploration, thereby expanding the real-...",
    "published": "Dec 21",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2012.11547v1",
    "queried_author": "Rafael Rafailov",
    "matching_authors": [
      "Rafael Rafailov"
    ]
  },
  {
    "title": "Evaluating Factuality in Generation with Dependency-level Entailment",
    "authors": [
      "Tanya Goyal",
      "Greg Durrett"
    ],
    "summary": "Despite significant progress in text generation models, a serious limitation is their tendency to produce text that is factually inconsistent with information in the input. Recent work has studied whether textual entailment systems can be used to identify factual errors; however, these sentence-leve...",
    "published": "Oct 12",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2010.05478v2",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "MLE-guided parameter search for task loss minimization in neural sequence modeling",
    "authors": [
      "Sean Welleck",
      "Kyunghyun Cho"
    ],
    "summary": "Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses. These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empi...",
    "published": "Jun 04",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2006.03158v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "Neural Syntactic Preordering for Controlled Paraphrase Generation",
    "authors": [
      "Tanya Goyal",
      "Greg Durrett"
    ],
    "summary": "Paraphrasing natural language sentences is a multifaceted process: it might involve replacing individual words or short phrases, local rearrangement of content, or high-level restructuring like topicalization or passivization. Past approaches struggle to cover this space of paraphrase possibilities ...",
    "published": "May 05",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2005.02013v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "ExpBERT: Representation Engineering with Natural Language Explanations",
    "authors": [
      "Shikhar Murty",
      "Pang Wei Koh",
      "Percy Liang"
    ],
    "summary": "Suppose we want to specify the inductive bias that married couples typically go on honeymoons for the task of extracting pairs of spouses from text. In this paper, we allow model developers to specify these types of inductive biases as natural language explanations. We use BERT fine-tuned on MultiNL...",
    "published": "May 05",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/2005.01932v1",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Specializing Word Embeddings (for Parsing) by Information Bottleneck",
    "authors": [
      "Xiang Lisa Li",
      "Jason Eisner"
    ],
    "summary": "Pre-trained word embeddings like ELMo and BERT contain rich syntactic and semantic information, resulting in state-of-the-art performance on various tasks. We propose a very fast variational information bottleneck (VIB) method to nonlinearly compress these embeddings, keeping only the information th...",
    "published": "Oct 01",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1910.00163v1",
    "queried_author": "Xiang Lisa Li",
    "matching_authors": [
      "Xiang Lisa Li"
    ]
  },
  {
    "title": "Humor Detection: A Transformer Gets the Last Laugh",
    "authors": [
      "Orion Weller",
      "Kevin Seppi"
    ],
    "summary": "Much previous work has been done in attempting to identify humor in text. In this paper we extend that capability by proposing a new task: assessing whether or not a joke is humorous. We present a novel way of approaching this problem by building a model that learns to identify humorous jokes based ...",
    "published": "Aug 31",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1909.00252v1",
    "queried_author": "Orion Weller",
    "matching_authors": [
      "Orion Weller"
    ]
  },
  {
    "title": "Embedding time expressions for deep temporal ordering models",
    "authors": [
      "Tanya Goyal",
      "Greg Durrett"
    ],
    "summary": "Data-driven models have demonstrated state-of-the-art performance in inferring the temporal ordering of events in text. However, these models often overlook explicit temporal signals, such as dates and time windows. Rule-based methods can be used to identify the temporal links between these time exp...",
    "published": "Jun 19",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1906.08287v1",
    "queried_author": "Tanya Goyal",
    "matching_authors": [
      "Tanya Goyal"
    ]
  },
  {
    "title": "Sequential Graph Dependency Parser",
    "authors": [
      "Sean Welleck",
      "Kyunghyun Cho"
    ],
    "summary": "We propose a method for non-projective dependency parsing by incrementally predicting a set of edges. Since the edges do not have a pre-specified order, we propose a set-based learning method. Our method blends graph, transition, and easy-first parsing, including a prior state of the parser as a spe...",
    "published": "May 27",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1905.10930v2",
    "queried_author": "Sean Welleck",
    "matching_authors": [
      "Sean Welleck"
    ]
  },
  {
    "title": "Stronger Data Poisoning Attacks Break Data Sanitization Defenses",
    "authors": [
      "Pang Wei Koh",
      "Jacob Steinhardt",
      "Percy Liang"
    ],
    "summary": "Machine learning models trained on data from the outside world can be corrupted by data poisoning attacks that inject malicious points into the models' training sets. A common defense against these attacks is data sanitization: first filter out anomalous training points before training the model. In...",
    "published": "Nov 02",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1811.00741v2",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Dialogue Natural Language Inference",
    "authors": [
      "Sean Welleck",
      "Jason Weston",
      "Arthur Szlam",
      "Kyunghyun Cho"
    ],
    "summary": "Consistency is a long standing issue faced by dialogue models. In this paper, we frame the consistency of dialogue agents as natural language inference (NLI) and create a new natural language inference dataset called Dialogue NLI. We propose a method which demonstrates that a model trained on Dialog...",
    "published": "Nov 01",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1811.00671v2",
    "queried_author": "Sean J Welleck",
    "matching_authors": [
      "Sean J Welleck"
    ]
  },
  {
    "title": "Saliency-based Sequential Image Attention with Multiset Prediction",
    "authors": [
      "Sean Welleck",
      "Jialin Mao",
      "Kyunghyun Cho",
      "Zheng Zhang"
    ],
    "summary": "Humans process visual scenes selectively and sequentially using attention. Central to models of human visual attention is the saliency map. We propose a hierarchical visual architecture that operates on a saliency map and uses a novel attention mechanism to sequentially focus on salient regions and ...",
    "published": "Nov 14",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1711.05165v1",
    "queried_author": "Sean J Welleck",
    "matching_authors": [
      "Sean J Welleck"
    ]
  },
  {
    "title": "Gaussian Quadrature for Kernel Features",
    "authors": [
      "Tri Dao",
      "Christopher De Sa",
      "Christopher R\u00e9"
    ],
    "summary": "Kernel methods have recently attracted resurgent interest, showing performance competitive with deep neural networks in tasks such as speech recognition. The random Fourier features map is a technique commonly used to scale up kernel machines, but employing the randomized feature map means that $O(\u03b5...",
    "published": "Sep 08",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1709.02605v3",
    "queried_author": "Tri Dao",
    "matching_authors": [
      "Tri Dao"
    ]
  },
  {
    "title": "Zero-Shot Activity Recognition with Verb Attribute Induction",
    "authors": [
      "Rowan Zellers",
      "Yejin Choi"
    ],
    "summary": "In this paper, we investigate large-scale zero-shot activity recognition by modeling the visual and linguistic attributes of action verbs. For example, the verb \"salute\" has several properties, such as being a light movement, a social act, and short in duration. We use these attributes as the intern...",
    "published": "Jul 29",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1707.09468v2",
    "queried_author": "Yejin Choi",
    "matching_authors": [
      "Yejin Choi"
    ]
  },
  {
    "title": "Mapping Instructions and Visual Observations to Actions with Reinforcement Learning",
    "authors": [
      "Dipendra Misra",
      "John Langford",
      "Yoav Artzi"
    ],
    "summary": "We propose to directly map raw visual observations and text input to actions for instruction execution. While existing approaches assume access to structured environment representations or use a pipeline of separately trained models, we learn a single model to jointly reason about linguistic and vis...",
    "published": "Apr 28",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1704.08795v2",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Understanding Black-box Predictions via Influence Functions",
    "authors": [
      "Pang Wei Koh",
      "Percy Liang"
    ],
    "summary": "How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a g...",
    "published": "Mar 14",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1703.04730v3",
    "queried_author": "Pang Wei Koh",
    "matching_authors": [
      "Pang Wei Koh"
    ]
  },
  {
    "title": "Neural Machine Translation and Sequence-to-sequence Models: A Tutorial",
    "authors": [
      "Graham Neubig"
    ],
    "summary": "This tutorial introduces a new and powerful set of techniques variously called \"neural machine translation\" or \"neural sequence-to-sequence models\". These techniques have been used in a number of tasks regarding the handling of human language, and can be a powerful tool in the toolbox of anyone who ...",
    "published": "Mar 05",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1703.01619v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Lexicons and Minimum Risk Training for Neural Machine Translation: NAIST-CMU at WAT2016",
    "authors": [
      "Graham Neubig"
    ],
    "summary": "This year, the Nara Institute of Science and Technology (NAIST)/Carnegie Mellon University (CMU) submission to the Japanese-English translation track of the 2016 Workshop on Asian Translation was based on attentional neural machine translation (NMT) models. In addition to the standard NMT model, we ...",
    "published": "Oct 20",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1610.06542v1",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Generalizing and Hybridizing Count-based and Neural Language Models",
    "authors": [
      "Graham Neubig",
      "Chris Dyer"
    ],
    "summary": "Language models (LMs) are statistical models that calculate probabilities over sequences of words or other discrete symbols. Currently two major paradigms for language modeling exist: count-based n-gram models, which have advantages of scalability and test-time speed, and neural LMs, which often ach...",
    "published": "Jun 01",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1606.00499v2",
    "queried_author": "Graham Neubig",
    "matching_authors": [
      "Graham Neubig"
    ]
  },
  {
    "title": "Learning Executable Semantic Parsers for Natural Language Understanding",
    "authors": [
      "Percy Liang"
    ],
    "summary": "For building question answering systems and natural language interfaces, semantic parsing has emerged as an important and powerful paradigm. Semantic parsers map natural language into logical forms, the classic representation for many important linguistic phenomena. The modern twist is that we are i...",
    "published": "Mar 22",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1603.06677v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Efficient AUC Optimization for Information Ranking Applications",
    "authors": [
      "Sean J. Welleck"
    ],
    "summary": "Adequate evaluation of an information retrieval system to estimate future performance is a crucial task. Area under the ROC curve (AUC) is widely used to evaluate the generalization of a retrieval system. However, the objective function optimized in many retrieval systems is the error rate and not t...",
    "published": "Nov 16",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1511.05202v3",
    "queried_author": "Sean J Welleck",
    "matching_authors": [
      "Sean J Welleck"
    ]
  },
  {
    "title": "Cornell SPF: Cornell Semantic Parsing Framework",
    "authors": [
      "Yoav Artzi"
    ],
    "summary": "The Cornell Semantic Parsing Framework (SPF) is a learning and inference framework for mapping natural language to formal representation of its meaning.",
    "published": "Nov 13",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1311.3011v2",
    "queried_author": "Yoav Artzi",
    "matching_authors": [
      "Yoav Artzi"
    ]
  },
  {
    "title": "Lambda Dependency-Based Compositional Semantics",
    "authors": [
      "Percy Liang"
    ],
    "summary": "This short note presents a new formal language, lambda dependency-based compositional semantics (lambda DCS) for representing logical forms in semantic parsing. By eliminating variables and making existential quantification implicit, lambda DCS logical forms are generally more compact than those in ...",
    "published": "Sep 17",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1309.4408v2",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  },
  {
    "title": "Learning Dependency-Based Compositional Semantics",
    "authors": [
      "Percy Liang",
      "Michael I. Jordan",
      "Dan Klein"
    ],
    "summary": "Suppose we want to build a system that answers a natural language question by representing its semantics as a logical form and computing the answer given a structured database of facts. The core part of such a system is the semantic parser that maps questions to logical forms. Semantic parsers are t...",
    "published": "Sep 30",
    "pdf_url": null,
    "arxiv_url": "http://arxiv.org/abs/1109.6841v1",
    "queried_author": "Percy Liang",
    "matching_authors": [
      "Percy Liang"
    ]
  }
]